{
  "best_metric": 1.8532612323760986,
  "best_model_checkpoint": "./psych-llm/n0.80_r0.50/checkpoint-7000",
  "epoch": 5.10875,
  "eval_steps": 500,
  "global_step": 17500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00025,
      "grad_norm": 447.1632080078125,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 10.6453,
      "step": 5
    },
    {
      "epoch": 0.0005,
      "grad_norm": 393.0840148925781,
      "learning_rate": 5.000000000000001e-07,
      "loss": 10.3219,
      "step": 10
    },
    {
      "epoch": 0.00075,
      "grad_norm": 469.486083984375,
      "learning_rate": 7.5e-07,
      "loss": 10.2438,
      "step": 15
    },
    {
      "epoch": 0.001,
      "grad_norm": 147.88072204589844,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 9.6362,
      "step": 20
    },
    {
      "epoch": 0.00125,
      "grad_norm": 103.54637145996094,
      "learning_rate": 1.25e-06,
      "loss": 8.83,
      "step": 25
    },
    {
      "epoch": 0.0015,
      "grad_norm": 66.10501861572266,
      "learning_rate": 1.5e-06,
      "loss": 8.1637,
      "step": 30
    },
    {
      "epoch": 0.00175,
      "grad_norm": 53.387672424316406,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 7.4782,
      "step": 35
    },
    {
      "epoch": 0.002,
      "grad_norm": 32.90509796142578,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 7.2786,
      "step": 40
    },
    {
      "epoch": 0.00225,
      "grad_norm": 23.044471740722656,
      "learning_rate": 2.25e-06,
      "loss": 7.0693,
      "step": 45
    },
    {
      "epoch": 0.0025,
      "grad_norm": 22.980989456176758,
      "learning_rate": 2.5e-06,
      "loss": 6.9445,
      "step": 50
    },
    {
      "epoch": 0.00275,
      "grad_norm": 31.767786026000977,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 7.1376,
      "step": 55
    },
    {
      "epoch": 0.003,
      "grad_norm": 31.056930541992188,
      "learning_rate": 3e-06,
      "loss": 6.8254,
      "step": 60
    },
    {
      "epoch": 0.00325,
      "grad_norm": 21.81525421142578,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 6.7655,
      "step": 65
    },
    {
      "epoch": 0.0035,
      "grad_norm": 26.280298233032227,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 6.5496,
      "step": 70
    },
    {
      "epoch": 0.00375,
      "grad_norm": 21.317584991455078,
      "learning_rate": 3.75e-06,
      "loss": 6.4026,
      "step": 75
    },
    {
      "epoch": 0.004,
      "grad_norm": 50.23967742919922,
      "learning_rate": 4.000000000000001e-06,
      "loss": 6.3874,
      "step": 80
    },
    {
      "epoch": 0.00425,
      "grad_norm": 31.67230224609375,
      "learning_rate": 4.250000000000001e-06,
      "loss": 6.1612,
      "step": 85
    },
    {
      "epoch": 0.0045,
      "grad_norm": 27.084077835083008,
      "learning_rate": 4.5e-06,
      "loss": 6.1066,
      "step": 90
    },
    {
      "epoch": 0.00475,
      "grad_norm": 35.03662872314453,
      "learning_rate": 4.75e-06,
      "loss": 5.9279,
      "step": 95
    },
    {
      "epoch": 0.005,
      "grad_norm": 26.371042251586914,
      "learning_rate": 5e-06,
      "loss": 5.8421,
      "step": 100
    },
    {
      "epoch": 0.00525,
      "grad_norm": 24.40435218811035,
      "learning_rate": 5.25e-06,
      "loss": 5.692,
      "step": 105
    },
    {
      "epoch": 0.0055,
      "grad_norm": 27.6442928314209,
      "learning_rate": 5.500000000000001e-06,
      "loss": 5.6972,
      "step": 110
    },
    {
      "epoch": 0.00575,
      "grad_norm": 31.99692726135254,
      "learning_rate": 5.750000000000001e-06,
      "loss": 5.4842,
      "step": 115
    },
    {
      "epoch": 0.006,
      "grad_norm": 28.48246192932129,
      "learning_rate": 6e-06,
      "loss": 5.526,
      "step": 120
    },
    {
      "epoch": 0.00625,
      "grad_norm": 30.765291213989258,
      "learning_rate": 6.25e-06,
      "loss": 5.299,
      "step": 125
    },
    {
      "epoch": 0.0065,
      "grad_norm": 33.182491302490234,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 5.5212,
      "step": 130
    },
    {
      "epoch": 0.00675,
      "grad_norm": 27.388097763061523,
      "learning_rate": 6.750000000000001e-06,
      "loss": 5.1929,
      "step": 135
    },
    {
      "epoch": 0.007,
      "grad_norm": 29.182554244995117,
      "learning_rate": 7.000000000000001e-06,
      "loss": 5.2153,
      "step": 140
    },
    {
      "epoch": 0.00725,
      "grad_norm": 32.35918045043945,
      "learning_rate": 7.25e-06,
      "loss": 5.2997,
      "step": 145
    },
    {
      "epoch": 0.0075,
      "grad_norm": 30.79673957824707,
      "learning_rate": 7.5e-06,
      "loss": 5.2273,
      "step": 150
    },
    {
      "epoch": 0.00775,
      "grad_norm": 32.47551345825195,
      "learning_rate": 7.75e-06,
      "loss": 5.1856,
      "step": 155
    },
    {
      "epoch": 0.008,
      "grad_norm": 27.202035903930664,
      "learning_rate": 8.000000000000001e-06,
      "loss": 5.1551,
      "step": 160
    },
    {
      "epoch": 0.00825,
      "grad_norm": 27.798416137695312,
      "learning_rate": 8.25e-06,
      "loss": 5.2828,
      "step": 165
    },
    {
      "epoch": 0.0085,
      "grad_norm": 32.54912185668945,
      "learning_rate": 8.500000000000002e-06,
      "loss": 5.0499,
      "step": 170
    },
    {
      "epoch": 0.00875,
      "grad_norm": 25.226329803466797,
      "learning_rate": 8.75e-06,
      "loss": 4.8826,
      "step": 175
    },
    {
      "epoch": 0.009,
      "grad_norm": 22.379230499267578,
      "learning_rate": 9e-06,
      "loss": 4.9271,
      "step": 180
    },
    {
      "epoch": 0.00925,
      "grad_norm": 27.160533905029297,
      "learning_rate": 9.25e-06,
      "loss": 4.8201,
      "step": 185
    },
    {
      "epoch": 0.0095,
      "grad_norm": 25.78364372253418,
      "learning_rate": 9.5e-06,
      "loss": 4.7164,
      "step": 190
    },
    {
      "epoch": 0.00975,
      "grad_norm": 36.904117584228516,
      "learning_rate": 9.750000000000002e-06,
      "loss": 4.6144,
      "step": 195
    },
    {
      "epoch": 0.01,
      "grad_norm": 24.054590225219727,
      "learning_rate": 1e-05,
      "loss": 4.6787,
      "step": 200
    },
    {
      "epoch": 0.01025,
      "grad_norm": 26.781715393066406,
      "learning_rate": 1.025e-05,
      "loss": 4.5948,
      "step": 205
    },
    {
      "epoch": 0.0105,
      "grad_norm": 24.929508209228516,
      "learning_rate": 1.05e-05,
      "loss": 4.7683,
      "step": 210
    },
    {
      "epoch": 0.01075,
      "grad_norm": 25.546064376831055,
      "learning_rate": 1.075e-05,
      "loss": 4.3959,
      "step": 215
    },
    {
      "epoch": 0.011,
      "grad_norm": 25.498403549194336,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 4.4162,
      "step": 220
    },
    {
      "epoch": 0.01125,
      "grad_norm": 28.500993728637695,
      "learning_rate": 1.125e-05,
      "loss": 4.2116,
      "step": 225
    },
    {
      "epoch": 0.0115,
      "grad_norm": 30.596593856811523,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 4.219,
      "step": 230
    },
    {
      "epoch": 0.01175,
      "grad_norm": 30.314800262451172,
      "learning_rate": 1.175e-05,
      "loss": 4.1848,
      "step": 235
    },
    {
      "epoch": 0.012,
      "grad_norm": 24.988479614257812,
      "learning_rate": 1.2e-05,
      "loss": 3.8766,
      "step": 240
    },
    {
      "epoch": 0.01225,
      "grad_norm": 30.146968841552734,
      "learning_rate": 1.225e-05,
      "loss": 4.0478,
      "step": 245
    },
    {
      "epoch": 0.0125,
      "grad_norm": 18.22612762451172,
      "learning_rate": 1.25e-05,
      "loss": 3.6543,
      "step": 250
    },
    {
      "epoch": 0.01275,
      "grad_norm": 21.985103607177734,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 3.3765,
      "step": 255
    },
    {
      "epoch": 0.013,
      "grad_norm": 20.483150482177734,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.2813,
      "step": 260
    },
    {
      "epoch": 0.01325,
      "grad_norm": 20.010128021240234,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 3.347,
      "step": 265
    },
    {
      "epoch": 0.0135,
      "grad_norm": 24.145925521850586,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 3.2102,
      "step": 270
    },
    {
      "epoch": 0.01375,
      "grad_norm": 34.200862884521484,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 3.9423,
      "step": 275
    },
    {
      "epoch": 0.014,
      "grad_norm": 27.109994888305664,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 4.5235,
      "step": 280
    },
    {
      "epoch": 0.01425,
      "grad_norm": 26.70270347595215,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 4.3314,
      "step": 285
    },
    {
      "epoch": 0.0145,
      "grad_norm": 26.894912719726562,
      "learning_rate": 1.45e-05,
      "loss": 3.9456,
      "step": 290
    },
    {
      "epoch": 0.01475,
      "grad_norm": 19.619775772094727,
      "learning_rate": 1.475e-05,
      "loss": 4.0339,
      "step": 295
    },
    {
      "epoch": 0.015,
      "grad_norm": 22.124292373657227,
      "learning_rate": 1.5e-05,
      "loss": 3.8453,
      "step": 300
    },
    {
      "epoch": 0.01525,
      "grad_norm": 31.506624221801758,
      "learning_rate": 1.525e-05,
      "loss": 3.2121,
      "step": 305
    },
    {
      "epoch": 0.0155,
      "grad_norm": 29.058773040771484,
      "learning_rate": 1.55e-05,
      "loss": 3.6908,
      "step": 310
    },
    {
      "epoch": 0.01575,
      "grad_norm": 25.406343460083008,
      "learning_rate": 1.575e-05,
      "loss": 3.6232,
      "step": 315
    },
    {
      "epoch": 0.016,
      "grad_norm": 26.51880645751953,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.1679,
      "step": 320
    },
    {
      "epoch": 0.01625,
      "grad_norm": 18.575468063354492,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 3.3232,
      "step": 325
    },
    {
      "epoch": 0.0165,
      "grad_norm": 25.255964279174805,
      "learning_rate": 1.65e-05,
      "loss": 3.3921,
      "step": 330
    },
    {
      "epoch": 0.01675,
      "grad_norm": 23.47039031982422,
      "learning_rate": 1.675e-05,
      "loss": 3.8439,
      "step": 335
    },
    {
      "epoch": 0.017,
      "grad_norm": 27.083219528198242,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 3.9227,
      "step": 340
    },
    {
      "epoch": 0.01725,
      "grad_norm": 24.603866577148438,
      "learning_rate": 1.725e-05,
      "loss": 3.6069,
      "step": 345
    },
    {
      "epoch": 0.0175,
      "grad_norm": 26.268457412719727,
      "learning_rate": 1.75e-05,
      "loss": 3.6879,
      "step": 350
    },
    {
      "epoch": 0.01775,
      "grad_norm": 22.360227584838867,
      "learning_rate": 1.775e-05,
      "loss": 3.1699,
      "step": 355
    },
    {
      "epoch": 0.018,
      "grad_norm": 19.707462310791016,
      "learning_rate": 1.8e-05,
      "loss": 3.2355,
      "step": 360
    },
    {
      "epoch": 0.01825,
      "grad_norm": 22.946557998657227,
      "learning_rate": 1.825e-05,
      "loss": 3.6148,
      "step": 365
    },
    {
      "epoch": 0.0185,
      "grad_norm": 21.653972625732422,
      "learning_rate": 1.85e-05,
      "loss": 4.0096,
      "step": 370
    },
    {
      "epoch": 0.01875,
      "grad_norm": 26.36066436767578,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 3.6355,
      "step": 375
    },
    {
      "epoch": 0.019,
      "grad_norm": 19.893648147583008,
      "learning_rate": 1.9e-05,
      "loss": 3.9387,
      "step": 380
    },
    {
      "epoch": 0.01925,
      "grad_norm": 19.428985595703125,
      "learning_rate": 1.925e-05,
      "loss": 3.7642,
      "step": 385
    },
    {
      "epoch": 0.0195,
      "grad_norm": 22.175262451171875,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 3.7499,
      "step": 390
    },
    {
      "epoch": 0.01975,
      "grad_norm": 21.136173248291016,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 3.4236,
      "step": 395
    },
    {
      "epoch": 0.02,
      "grad_norm": 17.637451171875,
      "learning_rate": 2e-05,
      "loss": 3.5233,
      "step": 400
    },
    {
      "epoch": 0.02025,
      "grad_norm": 23.674680709838867,
      "learning_rate": 2.025e-05,
      "loss": 3.762,
      "step": 405
    },
    {
      "epoch": 0.0205,
      "grad_norm": 18.89753532409668,
      "learning_rate": 2.05e-05,
      "loss": 3.6189,
      "step": 410
    },
    {
      "epoch": 0.02075,
      "grad_norm": 19.365835189819336,
      "learning_rate": 2.075e-05,
      "loss": 3.2601,
      "step": 415
    },
    {
      "epoch": 0.021,
      "grad_norm": 29.438030242919922,
      "learning_rate": 2.1e-05,
      "loss": 3.6527,
      "step": 420
    },
    {
      "epoch": 0.02125,
      "grad_norm": 16.316364288330078,
      "learning_rate": 2.125e-05,
      "loss": 3.5372,
      "step": 425
    },
    {
      "epoch": 0.0215,
      "grad_norm": 20.209890365600586,
      "learning_rate": 2.15e-05,
      "loss": 3.114,
      "step": 430
    },
    {
      "epoch": 0.02175,
      "grad_norm": 20.753145217895508,
      "learning_rate": 2.175e-05,
      "loss": 3.4041,
      "step": 435
    },
    {
      "epoch": 0.022,
      "grad_norm": 21.726606369018555,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.7939,
      "step": 440
    },
    {
      "epoch": 0.02225,
      "grad_norm": 28.492137908935547,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 3.9092,
      "step": 445
    },
    {
      "epoch": 0.0225,
      "grad_norm": 23.560693740844727,
      "learning_rate": 2.25e-05,
      "loss": 3.8889,
      "step": 450
    },
    {
      "epoch": 0.02275,
      "grad_norm": 23.3264217376709,
      "learning_rate": 2.275e-05,
      "loss": 3.543,
      "step": 455
    },
    {
      "epoch": 0.023,
      "grad_norm": 14.448101997375488,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.7144,
      "step": 460
    },
    {
      "epoch": 0.02325,
      "grad_norm": 18.83498191833496,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 3.3635,
      "step": 465
    },
    {
      "epoch": 0.0235,
      "grad_norm": 20.177339553833008,
      "learning_rate": 2.35e-05,
      "loss": 3.5518,
      "step": 470
    },
    {
      "epoch": 0.02375,
      "grad_norm": 15.383326530456543,
      "learning_rate": 2.375e-05,
      "loss": 3.2469,
      "step": 475
    },
    {
      "epoch": 0.024,
      "grad_norm": 23.064809799194336,
      "learning_rate": 2.4e-05,
      "loss": 3.1887,
      "step": 480
    },
    {
      "epoch": 0.02425,
      "grad_norm": 19.00737953186035,
      "learning_rate": 2.425e-05,
      "loss": 3.3957,
      "step": 485
    },
    {
      "epoch": 0.0245,
      "grad_norm": 25.276138305664062,
      "learning_rate": 2.45e-05,
      "loss": 3.7154,
      "step": 490
    },
    {
      "epoch": 0.02475,
      "grad_norm": 15.674966812133789,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 3.2525,
      "step": 495
    },
    {
      "epoch": 0.025,
      "grad_norm": 25.482322692871094,
      "learning_rate": 2.5e-05,
      "loss": 3.2489,
      "step": 500
    },
    {
      "epoch": 0.025,
      "eval_loss": 3.16823673248291,
      "eval_runtime": 5.3959,
      "eval_samples_per_second": 189.773,
      "eval_steps_per_second": 23.722,
      "step": 500
    },
    {
      "epoch": 0.02525,
      "grad_norm": 13.730792045593262,
      "learning_rate": 2.525e-05,
      "loss": 3.2284,
      "step": 505
    },
    {
      "epoch": 0.0255,
      "grad_norm": 18.53779411315918,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.4297,
      "step": 510
    },
    {
      "epoch": 0.02575,
      "grad_norm": 16.441965103149414,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 3.6094,
      "step": 515
    },
    {
      "epoch": 0.026,
      "grad_norm": 18.960479736328125,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.1458,
      "step": 520
    },
    {
      "epoch": 0.02625,
      "grad_norm": 23.17528533935547,
      "learning_rate": 2.625e-05,
      "loss": 3.7074,
      "step": 525
    },
    {
      "epoch": 0.0265,
      "grad_norm": 18.164548873901367,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 3.2348,
      "step": 530
    },
    {
      "epoch": 0.02675,
      "grad_norm": 25.556135177612305,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 3.2624,
      "step": 535
    },
    {
      "epoch": 0.027,
      "grad_norm": 23.903444290161133,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.3169,
      "step": 540
    },
    {
      "epoch": 0.02725,
      "grad_norm": 17.02336311340332,
      "learning_rate": 2.725e-05,
      "loss": 3.1938,
      "step": 545
    },
    {
      "epoch": 0.0275,
      "grad_norm": 20.386333465576172,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.2334,
      "step": 550
    },
    {
      "epoch": 0.02775,
      "grad_norm": 16.258934020996094,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 3.4621,
      "step": 555
    },
    {
      "epoch": 0.028,
      "grad_norm": 22.591299057006836,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.168,
      "step": 560
    },
    {
      "epoch": 0.02825,
      "grad_norm": 19.91252899169922,
      "learning_rate": 2.825e-05,
      "loss": 3.6123,
      "step": 565
    },
    {
      "epoch": 0.0285,
      "grad_norm": 18.336185455322266,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 3.2803,
      "step": 570
    },
    {
      "epoch": 0.02875,
      "grad_norm": 26.29666519165039,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 3.5238,
      "step": 575
    },
    {
      "epoch": 0.029,
      "grad_norm": 17.259788513183594,
      "learning_rate": 2.9e-05,
      "loss": 3.2946,
      "step": 580
    },
    {
      "epoch": 0.02925,
      "grad_norm": 16.281240463256836,
      "learning_rate": 2.925e-05,
      "loss": 3.2277,
      "step": 585
    },
    {
      "epoch": 0.0295,
      "grad_norm": 13.099390983581543,
      "learning_rate": 2.95e-05,
      "loss": 2.8173,
      "step": 590
    },
    {
      "epoch": 0.02975,
      "grad_norm": 18.284284591674805,
      "learning_rate": 2.975e-05,
      "loss": 3.2688,
      "step": 595
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.572471618652344,
      "learning_rate": 3e-05,
      "loss": 3.0335,
      "step": 600
    },
    {
      "epoch": 0.03025,
      "grad_norm": 19.757028579711914,
      "learning_rate": 3.025e-05,
      "loss": 3.1525,
      "step": 605
    },
    {
      "epoch": 0.0305,
      "grad_norm": 16.943674087524414,
      "learning_rate": 3.05e-05,
      "loss": 3.3256,
      "step": 610
    },
    {
      "epoch": 0.03075,
      "grad_norm": 22.745615005493164,
      "learning_rate": 3.075e-05,
      "loss": 3.1128,
      "step": 615
    },
    {
      "epoch": 0.031,
      "grad_norm": 13.474013328552246,
      "learning_rate": 3.1e-05,
      "loss": 3.0479,
      "step": 620
    },
    {
      "epoch": 0.03125,
      "grad_norm": 16.583988189697266,
      "learning_rate": 3.125e-05,
      "loss": 3.3118,
      "step": 625
    },
    {
      "epoch": 0.0315,
      "grad_norm": 20.98947525024414,
      "learning_rate": 3.15e-05,
      "loss": 3.3518,
      "step": 630
    },
    {
      "epoch": 0.03175,
      "grad_norm": 12.593634605407715,
      "learning_rate": 3.175e-05,
      "loss": 3.2545,
      "step": 635
    },
    {
      "epoch": 0.032,
      "grad_norm": 16.146915435791016,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.1298,
      "step": 640
    },
    {
      "epoch": 0.03225,
      "grad_norm": 21.016651153564453,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 3.1579,
      "step": 645
    },
    {
      "epoch": 0.0325,
      "grad_norm": 17.349895477294922,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.7263,
      "step": 650
    },
    {
      "epoch": 0.03275,
      "grad_norm": 16.220230102539062,
      "learning_rate": 3.275e-05,
      "loss": 2.6818,
      "step": 655
    },
    {
      "epoch": 0.033,
      "grad_norm": 15.305487632751465,
      "learning_rate": 3.3e-05,
      "loss": 2.9893,
      "step": 660
    },
    {
      "epoch": 0.03325,
      "grad_norm": 15.42573356628418,
      "learning_rate": 3.325e-05,
      "loss": 3.0704,
      "step": 665
    },
    {
      "epoch": 0.0335,
      "grad_norm": 13.83908748626709,
      "learning_rate": 3.35e-05,
      "loss": 3.1612,
      "step": 670
    },
    {
      "epoch": 0.03375,
      "grad_norm": 18.126928329467773,
      "learning_rate": 3.375000000000001e-05,
      "loss": 3.4048,
      "step": 675
    },
    {
      "epoch": 0.034,
      "grad_norm": 13.152591705322266,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.3683,
      "step": 680
    },
    {
      "epoch": 0.03425,
      "grad_norm": 15.962855339050293,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 2.877,
      "step": 685
    },
    {
      "epoch": 0.0345,
      "grad_norm": 16.12810707092285,
      "learning_rate": 3.45e-05,
      "loss": 3.1563,
      "step": 690
    },
    {
      "epoch": 0.03475,
      "grad_norm": 12.70783805847168,
      "learning_rate": 3.475e-05,
      "loss": 3.1991,
      "step": 695
    },
    {
      "epoch": 0.035,
      "grad_norm": 11.630819320678711,
      "learning_rate": 3.5e-05,
      "loss": 3.3058,
      "step": 700
    },
    {
      "epoch": 0.03525,
      "grad_norm": 13.080916404724121,
      "learning_rate": 3.525e-05,
      "loss": 3.1466,
      "step": 705
    },
    {
      "epoch": 0.0355,
      "grad_norm": 12.88009262084961,
      "learning_rate": 3.55e-05,
      "loss": 3.0758,
      "step": 710
    },
    {
      "epoch": 0.03575,
      "grad_norm": 12.826565742492676,
      "learning_rate": 3.575e-05,
      "loss": 2.948,
      "step": 715
    },
    {
      "epoch": 0.036,
      "grad_norm": 19.24765968322754,
      "learning_rate": 3.6e-05,
      "loss": 3.3599,
      "step": 720
    },
    {
      "epoch": 0.03625,
      "grad_norm": 12.082503318786621,
      "learning_rate": 3.625e-05,
      "loss": 3.1783,
      "step": 725
    },
    {
      "epoch": 0.0365,
      "grad_norm": 22.238943099975586,
      "learning_rate": 3.65e-05,
      "loss": 3.2119,
      "step": 730
    },
    {
      "epoch": 0.03675,
      "grad_norm": 14.754201889038086,
      "learning_rate": 3.675e-05,
      "loss": 3.1892,
      "step": 735
    },
    {
      "epoch": 0.037,
      "grad_norm": 9.540770530700684,
      "learning_rate": 3.7e-05,
      "loss": 3.1783,
      "step": 740
    },
    {
      "epoch": 0.03725,
      "grad_norm": 14.041386604309082,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 3.0353,
      "step": 745
    },
    {
      "epoch": 0.0375,
      "grad_norm": 12.554057121276855,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.3432,
      "step": 750
    },
    {
      "epoch": 0.03775,
      "grad_norm": 12.580382347106934,
      "learning_rate": 3.775e-05,
      "loss": 3.0164,
      "step": 755
    },
    {
      "epoch": 0.038,
      "grad_norm": 14.991781234741211,
      "learning_rate": 3.8e-05,
      "loss": 2.922,
      "step": 760
    },
    {
      "epoch": 0.03825,
      "grad_norm": 18.298324584960938,
      "learning_rate": 3.825e-05,
      "loss": 3.0614,
      "step": 765
    },
    {
      "epoch": 0.0385,
      "grad_norm": 14.259676933288574,
      "learning_rate": 3.85e-05,
      "loss": 3.0133,
      "step": 770
    },
    {
      "epoch": 0.03875,
      "grad_norm": 15.605317115783691,
      "learning_rate": 3.875e-05,
      "loss": 3.2169,
      "step": 775
    },
    {
      "epoch": 0.039,
      "grad_norm": 18.514253616333008,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 2.9409,
      "step": 780
    },
    {
      "epoch": 0.03925,
      "grad_norm": 11.095348358154297,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 2.8746,
      "step": 785
    },
    {
      "epoch": 0.0395,
      "grad_norm": 14.39372730255127,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.3124,
      "step": 790
    },
    {
      "epoch": 0.03975,
      "grad_norm": 11.916172981262207,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 2.9505,
      "step": 795
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.120771408081055,
      "learning_rate": 4e-05,
      "loss": 2.8696,
      "step": 800
    },
    {
      "epoch": 0.04025,
      "grad_norm": 12.360589981079102,
      "learning_rate": 4.025e-05,
      "loss": 3.079,
      "step": 805
    },
    {
      "epoch": 0.0405,
      "grad_norm": 17.70954132080078,
      "learning_rate": 4.05e-05,
      "loss": 2.9172,
      "step": 810
    },
    {
      "epoch": 0.04075,
      "grad_norm": 12.31125545501709,
      "learning_rate": 4.075e-05,
      "loss": 2.8638,
      "step": 815
    },
    {
      "epoch": 0.041,
      "grad_norm": 11.60138988494873,
      "learning_rate": 4.1e-05,
      "loss": 3.1809,
      "step": 820
    },
    {
      "epoch": 0.04125,
      "grad_norm": 12.872469902038574,
      "learning_rate": 4.125e-05,
      "loss": 3.1651,
      "step": 825
    },
    {
      "epoch": 0.0415,
      "grad_norm": 11.832828521728516,
      "learning_rate": 4.15e-05,
      "loss": 3.32,
      "step": 830
    },
    {
      "epoch": 0.04175,
      "grad_norm": 11.575400352478027,
      "learning_rate": 4.175e-05,
      "loss": 3.2341,
      "step": 835
    },
    {
      "epoch": 0.042,
      "grad_norm": 15.051175117492676,
      "learning_rate": 4.2e-05,
      "loss": 2.9949,
      "step": 840
    },
    {
      "epoch": 0.04225,
      "grad_norm": 16.951269149780273,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 3.1607,
      "step": 845
    },
    {
      "epoch": 0.0425,
      "grad_norm": 12.61552906036377,
      "learning_rate": 4.25e-05,
      "loss": 3.1256,
      "step": 850
    },
    {
      "epoch": 0.04275,
      "grad_norm": 14.61375617980957,
      "learning_rate": 4.275e-05,
      "loss": 3.1065,
      "step": 855
    },
    {
      "epoch": 0.043,
      "grad_norm": 17.487157821655273,
      "learning_rate": 4.3e-05,
      "loss": 2.9157,
      "step": 860
    },
    {
      "epoch": 0.04325,
      "grad_norm": 12.38883113861084,
      "learning_rate": 4.325e-05,
      "loss": 3.3972,
      "step": 865
    },
    {
      "epoch": 0.0435,
      "grad_norm": 16.8228702545166,
      "learning_rate": 4.35e-05,
      "loss": 3.2282,
      "step": 870
    },
    {
      "epoch": 0.04375,
      "grad_norm": 14.538878440856934,
      "learning_rate": 4.375e-05,
      "loss": 2.8525,
      "step": 875
    },
    {
      "epoch": 0.044,
      "grad_norm": 11.784419059753418,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.0,
      "step": 880
    },
    {
      "epoch": 0.04425,
      "grad_norm": 11.908695220947266,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 2.8267,
      "step": 885
    },
    {
      "epoch": 0.0445,
      "grad_norm": 10.849026679992676,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 2.9168,
      "step": 890
    },
    {
      "epoch": 0.04475,
      "grad_norm": 15.522600173950195,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 3.2295,
      "step": 895
    },
    {
      "epoch": 0.045,
      "grad_norm": 9.591025352478027,
      "learning_rate": 4.5e-05,
      "loss": 3.052,
      "step": 900
    },
    {
      "epoch": 0.04525,
      "grad_norm": 14.066436767578125,
      "learning_rate": 4.525e-05,
      "loss": 2.9297,
      "step": 905
    },
    {
      "epoch": 0.0455,
      "grad_norm": 16.87202262878418,
      "learning_rate": 4.55e-05,
      "loss": 2.8885,
      "step": 910
    },
    {
      "epoch": 0.04575,
      "grad_norm": 14.86794662475586,
      "learning_rate": 4.575e-05,
      "loss": 2.9549,
      "step": 915
    },
    {
      "epoch": 0.046,
      "grad_norm": 12.373844146728516,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.8968,
      "step": 920
    },
    {
      "epoch": 0.04625,
      "grad_norm": 11.113422393798828,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 3.0957,
      "step": 925
    },
    {
      "epoch": 0.0465,
      "grad_norm": 9.863625526428223,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 2.7949,
      "step": 930
    },
    {
      "epoch": 0.04675,
      "grad_norm": 11.430973052978516,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 2.8387,
      "step": 935
    },
    {
      "epoch": 0.047,
      "grad_norm": 12.128803253173828,
      "learning_rate": 4.7e-05,
      "loss": 2.7354,
      "step": 940
    },
    {
      "epoch": 0.04725,
      "grad_norm": 10.390954971313477,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 2.9455,
      "step": 945
    },
    {
      "epoch": 0.0475,
      "grad_norm": 12.928345680236816,
      "learning_rate": 4.75e-05,
      "loss": 2.6651,
      "step": 950
    },
    {
      "epoch": 0.04775,
      "grad_norm": 12.042078971862793,
      "learning_rate": 4.775e-05,
      "loss": 2.9355,
      "step": 955
    },
    {
      "epoch": 0.048,
      "grad_norm": 12.133624076843262,
      "learning_rate": 4.8e-05,
      "loss": 2.9792,
      "step": 960
    },
    {
      "epoch": 0.04825,
      "grad_norm": 14.726768493652344,
      "learning_rate": 4.825e-05,
      "loss": 3.159,
      "step": 965
    },
    {
      "epoch": 0.0485,
      "grad_norm": 11.841034889221191,
      "learning_rate": 4.85e-05,
      "loss": 2.8102,
      "step": 970
    },
    {
      "epoch": 0.04875,
      "grad_norm": 9.74732780456543,
      "learning_rate": 4.875e-05,
      "loss": 2.8351,
      "step": 975
    },
    {
      "epoch": 0.049,
      "grad_norm": 12.484190940856934,
      "learning_rate": 4.9e-05,
      "loss": 2.8854,
      "step": 980
    },
    {
      "epoch": 0.04925,
      "grad_norm": 14.044052124023438,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 2.8428,
      "step": 985
    },
    {
      "epoch": 0.0495,
      "grad_norm": 18.848398208618164,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 2.8691,
      "step": 990
    },
    {
      "epoch": 0.04975,
      "grad_norm": 10.456954956054688,
      "learning_rate": 4.975e-05,
      "loss": 2.5533,
      "step": 995
    },
    {
      "epoch": 0.05,
      "grad_norm": 14.589685440063477,
      "learning_rate": 5e-05,
      "loss": 2.8753,
      "step": 1000
    },
    {
      "epoch": 0.05,
      "eval_loss": 2.6115779876708984,
      "eval_runtime": 5.2979,
      "eval_samples_per_second": 193.284,
      "eval_steps_per_second": 24.161,
      "step": 1000
    },
    {
      "epoch": 0.05025,
      "grad_norm": 13.911405563354492,
      "learning_rate": 4.9999991456367865e-05,
      "loss": 2.9733,
      "step": 1005
    },
    {
      "epoch": 0.0505,
      "grad_norm": 9.421202659606934,
      "learning_rate": 4.9999965825477314e-05,
      "loss": 2.8328,
      "step": 1010
    },
    {
      "epoch": 0.05075,
      "grad_norm": 9.788396835327148,
      "learning_rate": 4.9999923107345846e-05,
      "loss": 2.9568,
      "step": 1015
    },
    {
      "epoch": 0.051,
      "grad_norm": 9.911169052124023,
      "learning_rate": 4.999986330200268e-05,
      "loss": 2.8706,
      "step": 1020
    },
    {
      "epoch": 0.05125,
      "grad_norm": 9.953176498413086,
      "learning_rate": 4.9999786409488677e-05,
      "loss": 2.9299,
      "step": 1025
    },
    {
      "epoch": 0.0515,
      "grad_norm": 9.780198097229004,
      "learning_rate": 4.999969242985639e-05,
      "loss": 2.9208,
      "step": 1030
    },
    {
      "epoch": 0.05175,
      "grad_norm": 12.188369750976562,
      "learning_rate": 4.9999581363170075e-05,
      "loss": 3.002,
      "step": 1035
    },
    {
      "epoch": 0.052,
      "grad_norm": 9.955321311950684,
      "learning_rate": 4.999945320950562e-05,
      "loss": 2.6082,
      "step": 1040
    },
    {
      "epoch": 0.05225,
      "grad_norm": 9.725008964538574,
      "learning_rate": 4.999930796895063e-05,
      "loss": 2.8881,
      "step": 1045
    },
    {
      "epoch": 0.0525,
      "grad_norm": 8.095696449279785,
      "learning_rate": 4.999914564160437e-05,
      "loss": 2.7714,
      "step": 1050
    },
    {
      "epoch": 0.05275,
      "grad_norm": 12.456018447875977,
      "learning_rate": 4.999896622757779e-05,
      "loss": 3.0191,
      "step": 1055
    },
    {
      "epoch": 0.053,
      "grad_norm": 10.125799179077148,
      "learning_rate": 4.999876972699352e-05,
      "loss": 2.7901,
      "step": 1060
    },
    {
      "epoch": 0.05325,
      "grad_norm": 8.661890983581543,
      "learning_rate": 4.9998556139985875e-05,
      "loss": 2.8704,
      "step": 1065
    },
    {
      "epoch": 0.0535,
      "grad_norm": 10.435989379882812,
      "learning_rate": 4.999832546670082e-05,
      "loss": 2.8267,
      "step": 1070
    },
    {
      "epoch": 0.05375,
      "grad_norm": 9.544222831726074,
      "learning_rate": 4.9998077707296033e-05,
      "loss": 2.8027,
      "step": 1075
    },
    {
      "epoch": 0.054,
      "grad_norm": 12.099740028381348,
      "learning_rate": 4.999781286194085e-05,
      "loss": 2.4841,
      "step": 1080
    },
    {
      "epoch": 0.05425,
      "grad_norm": 11.954202651977539,
      "learning_rate": 4.9997530930816295e-05,
      "loss": 2.6007,
      "step": 1085
    },
    {
      "epoch": 0.0545,
      "grad_norm": 9.632878303527832,
      "learning_rate": 4.9997231914115064e-05,
      "loss": 2.9741,
      "step": 1090
    },
    {
      "epoch": 0.05475,
      "grad_norm": 10.118671417236328,
      "learning_rate": 4.999691581204152e-05,
      "loss": 3.125,
      "step": 1095
    },
    {
      "epoch": 0.055,
      "grad_norm": 13.2472562789917,
      "learning_rate": 4.9996582624811725e-05,
      "loss": 2.8226,
      "step": 1100
    },
    {
      "epoch": 0.05525,
      "grad_norm": 7.599873065948486,
      "learning_rate": 4.9996232352653414e-05,
      "loss": 2.858,
      "step": 1105
    },
    {
      "epoch": 0.0555,
      "grad_norm": 10.126389503479004,
      "learning_rate": 4.999586499580599e-05,
      "loss": 2.7389,
      "step": 1110
    },
    {
      "epoch": 0.05575,
      "grad_norm": 8.999175071716309,
      "learning_rate": 4.999548055452054e-05,
      "loss": 2.8332,
      "step": 1115
    },
    {
      "epoch": 0.056,
      "grad_norm": 9.998907089233398,
      "learning_rate": 4.9995079029059824e-05,
      "loss": 2.626,
      "step": 1120
    },
    {
      "epoch": 0.05625,
      "grad_norm": 11.221318244934082,
      "learning_rate": 4.999466041969828e-05,
      "loss": 3.0788,
      "step": 1125
    },
    {
      "epoch": 0.0565,
      "grad_norm": 9.940736770629883,
      "learning_rate": 4.999422472672202e-05,
      "loss": 2.7977,
      "step": 1130
    },
    {
      "epoch": 0.05675,
      "grad_norm": 10.412025451660156,
      "learning_rate": 4.9993771950428846e-05,
      "loss": 3.0244,
      "step": 1135
    },
    {
      "epoch": 0.057,
      "grad_norm": 9.478289604187012,
      "learning_rate": 4.999330209112822e-05,
      "loss": 2.6279,
      "step": 1140
    },
    {
      "epoch": 0.05725,
      "grad_norm": 10.408604621887207,
      "learning_rate": 4.9992815149141294e-05,
      "loss": 2.9275,
      "step": 1145
    },
    {
      "epoch": 0.0575,
      "grad_norm": 8.01443862915039,
      "learning_rate": 4.9992311124800875e-05,
      "loss": 2.7949,
      "step": 1150
    },
    {
      "epoch": 0.05775,
      "grad_norm": 10.43582534790039,
      "learning_rate": 4.9991790018451465e-05,
      "loss": 2.6012,
      "step": 1155
    },
    {
      "epoch": 0.058,
      "grad_norm": 8.683859825134277,
      "learning_rate": 4.999125183044924e-05,
      "loss": 2.6117,
      "step": 1160
    },
    {
      "epoch": 0.05825,
      "grad_norm": 11.563600540161133,
      "learning_rate": 4.999069656116203e-05,
      "loss": 2.5034,
      "step": 1165
    },
    {
      "epoch": 0.0585,
      "grad_norm": 9.464829444885254,
      "learning_rate": 4.999012421096938e-05,
      "loss": 2.9673,
      "step": 1170
    },
    {
      "epoch": 0.05875,
      "grad_norm": 17.084308624267578,
      "learning_rate": 4.998953478026247e-05,
      "loss": 2.6901,
      "step": 1175
    },
    {
      "epoch": 0.059,
      "grad_norm": 10.057402610778809,
      "learning_rate": 4.998892826944418e-05,
      "loss": 2.9445,
      "step": 1180
    },
    {
      "epoch": 0.05925,
      "grad_norm": 9.858302116394043,
      "learning_rate": 4.998830467892904e-05,
      "loss": 2.5521,
      "step": 1185
    },
    {
      "epoch": 0.0595,
      "grad_norm": 10.542922019958496,
      "learning_rate": 4.998766400914329e-05,
      "loss": 2.9349,
      "step": 1190
    },
    {
      "epoch": 0.05975,
      "grad_norm": 14.825095176696777,
      "learning_rate": 4.998700626052481e-05,
      "loss": 2.7389,
      "step": 1195
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.888687133789062,
      "learning_rate": 4.9986331433523156e-05,
      "loss": 2.9253,
      "step": 1200
    },
    {
      "epoch": 0.06025,
      "grad_norm": 9.20370101928711,
      "learning_rate": 4.998563952859957e-05,
      "loss": 2.6606,
      "step": 1205
    },
    {
      "epoch": 0.0605,
      "grad_norm": 11.878527641296387,
      "learning_rate": 4.9984930546226975e-05,
      "loss": 3.0782,
      "step": 1210
    },
    {
      "epoch": 0.06075,
      "grad_norm": 10.595283508300781,
      "learning_rate": 4.998420448688994e-05,
      "loss": 2.5799,
      "step": 1215
    },
    {
      "epoch": 0.061,
      "grad_norm": 10.02472972869873,
      "learning_rate": 4.9983461351084735e-05,
      "loss": 2.7261,
      "step": 1220
    },
    {
      "epoch": 0.06125,
      "grad_norm": 11.916641235351562,
      "learning_rate": 4.998270113931927e-05,
      "loss": 2.8042,
      "step": 1225
    },
    {
      "epoch": 0.0615,
      "grad_norm": 10.731977462768555,
      "learning_rate": 4.9981923852113145e-05,
      "loss": 2.6257,
      "step": 1230
    },
    {
      "epoch": 0.06175,
      "grad_norm": 11.240436553955078,
      "learning_rate": 4.998112948999764e-05,
      "loss": 2.6412,
      "step": 1235
    },
    {
      "epoch": 0.062,
      "grad_norm": 12.285614967346191,
      "learning_rate": 4.9980318053515686e-05,
      "loss": 2.7121,
      "step": 1240
    },
    {
      "epoch": 0.06225,
      "grad_norm": 10.595625877380371,
      "learning_rate": 4.997948954322189e-05,
      "loss": 2.7899,
      "step": 1245
    },
    {
      "epoch": 0.0625,
      "grad_norm": 8.728857040405273,
      "learning_rate": 4.997864395968252e-05,
      "loss": 2.4442,
      "step": 1250
    },
    {
      "epoch": 0.06275,
      "grad_norm": 12.173172950744629,
      "learning_rate": 4.9977781303475556e-05,
      "loss": 2.6459,
      "step": 1255
    },
    {
      "epoch": 0.063,
      "grad_norm": 9.665485382080078,
      "learning_rate": 4.997690157519059e-05,
      "loss": 2.8164,
      "step": 1260
    },
    {
      "epoch": 0.06325,
      "grad_norm": 9.585158348083496,
      "learning_rate": 4.9976004775428924e-05,
      "loss": 2.8593,
      "step": 1265
    },
    {
      "epoch": 0.0635,
      "grad_norm": 8.111990928649902,
      "learning_rate": 4.99750909048035e-05,
      "loss": 2.5012,
      "step": 1270
    },
    {
      "epoch": 0.06375,
      "grad_norm": 8.404292106628418,
      "learning_rate": 4.997415996393894e-05,
      "loss": 2.4977,
      "step": 1275
    },
    {
      "epoch": 0.064,
      "grad_norm": 10.249238014221191,
      "learning_rate": 4.997321195347154e-05,
      "loss": 2.4659,
      "step": 1280
    },
    {
      "epoch": 0.06425,
      "grad_norm": 11.050687789916992,
      "learning_rate": 4.9972246874049254e-05,
      "loss": 2.95,
      "step": 1285
    },
    {
      "epoch": 0.0645,
      "grad_norm": 8.821859359741211,
      "learning_rate": 4.99712647263317e-05,
      "loss": 2.674,
      "step": 1290
    },
    {
      "epoch": 0.06475,
      "grad_norm": 12.05510425567627,
      "learning_rate": 4.997026551099017e-05,
      "loss": 2.9334,
      "step": 1295
    },
    {
      "epoch": 0.065,
      "grad_norm": 11.575113296508789,
      "learning_rate": 4.996924922870762e-05,
      "loss": 2.974,
      "step": 1300
    },
    {
      "epoch": 0.06525,
      "grad_norm": 13.190825462341309,
      "learning_rate": 4.996821588017867e-05,
      "loss": 2.9904,
      "step": 1305
    },
    {
      "epoch": 0.0655,
      "grad_norm": 10.866863250732422,
      "learning_rate": 4.99671654661096e-05,
      "loss": 2.7618,
      "step": 1310
    },
    {
      "epoch": 0.06575,
      "grad_norm": 8.43796443939209,
      "learning_rate": 4.9966097987218365e-05,
      "loss": 2.7526,
      "step": 1315
    },
    {
      "epoch": 0.066,
      "grad_norm": 10.841958045959473,
      "learning_rate": 4.996501344423456e-05,
      "loss": 2.5767,
      "step": 1320
    },
    {
      "epoch": 0.06625,
      "grad_norm": 8.808076858520508,
      "learning_rate": 4.9963911837899494e-05,
      "loss": 2.9014,
      "step": 1325
    },
    {
      "epoch": 0.0665,
      "grad_norm": 8.713201522827148,
      "learning_rate": 4.996279316896606e-05,
      "loss": 2.8762,
      "step": 1330
    },
    {
      "epoch": 0.06675,
      "grad_norm": 10.97002124786377,
      "learning_rate": 4.996165743819889e-05,
      "loss": 2.6931,
      "step": 1335
    },
    {
      "epoch": 0.067,
      "grad_norm": 8.855646133422852,
      "learning_rate": 4.996050464637423e-05,
      "loss": 2.8563,
      "step": 1340
    },
    {
      "epoch": 0.06725,
      "grad_norm": 8.672481536865234,
      "learning_rate": 4.9959334794280014e-05,
      "loss": 2.5152,
      "step": 1345
    },
    {
      "epoch": 0.0675,
      "grad_norm": 10.076024055480957,
      "learning_rate": 4.995814788271582e-05,
      "loss": 2.652,
      "step": 1350
    },
    {
      "epoch": 0.06775,
      "grad_norm": 8.191134452819824,
      "learning_rate": 4.995694391249288e-05,
      "loss": 2.6375,
      "step": 1355
    },
    {
      "epoch": 0.068,
      "grad_norm": 6.177680492401123,
      "learning_rate": 4.9955722884434114e-05,
      "loss": 2.7793,
      "step": 1360
    },
    {
      "epoch": 0.06825,
      "grad_norm": 8.080923080444336,
      "learning_rate": 4.9954484799374076e-05,
      "loss": 2.7447,
      "step": 1365
    },
    {
      "epoch": 0.0685,
      "grad_norm": 8.943365097045898,
      "learning_rate": 4.995322965815898e-05,
      "loss": 2.7998,
      "step": 1370
    },
    {
      "epoch": 0.06875,
      "grad_norm": 7.935103893280029,
      "learning_rate": 4.9951957461646706e-05,
      "loss": 2.6464,
      "step": 1375
    },
    {
      "epoch": 0.069,
      "grad_norm": 5.556468486785889,
      "learning_rate": 4.995066821070679e-05,
      "loss": 2.5126,
      "step": 1380
    },
    {
      "epoch": 0.06925,
      "grad_norm": 9.73046875,
      "learning_rate": 4.9949361906220425e-05,
      "loss": 2.7189,
      "step": 1385
    },
    {
      "epoch": 0.0695,
      "grad_norm": 6.442550182342529,
      "learning_rate": 4.9948038549080456e-05,
      "loss": 2.4696,
      "step": 1390
    },
    {
      "epoch": 0.06975,
      "grad_norm": 5.926555633544922,
      "learning_rate": 4.994669814019138e-05,
      "loss": 2.588,
      "step": 1395
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.055174827575684,
      "learning_rate": 4.994534068046937e-05,
      "loss": 2.7545,
      "step": 1400
    },
    {
      "epoch": 0.07025,
      "grad_norm": 7.319049835205078,
      "learning_rate": 4.994396617084222e-05,
      "loss": 2.2455,
      "step": 1405
    },
    {
      "epoch": 0.0705,
      "grad_norm": 6.9473876953125,
      "learning_rate": 4.9942574612249394e-05,
      "loss": 2.5047,
      "step": 1410
    },
    {
      "epoch": 0.07075,
      "grad_norm": 8.641410827636719,
      "learning_rate": 4.9941166005642014e-05,
      "loss": 2.3866,
      "step": 1415
    },
    {
      "epoch": 0.071,
      "grad_norm": 7.652199745178223,
      "learning_rate": 4.9939740351982856e-05,
      "loss": 2.3085,
      "step": 1420
    },
    {
      "epoch": 0.07125,
      "grad_norm": 7.177963733673096,
      "learning_rate": 4.993829765224634e-05,
      "loss": 2.4249,
      "step": 1425
    },
    {
      "epoch": 0.0715,
      "grad_norm": 9.295522689819336,
      "learning_rate": 4.993683790741852e-05,
      "loss": 2.6075,
      "step": 1430
    },
    {
      "epoch": 0.07175,
      "grad_norm": 8.341588020324707,
      "learning_rate": 4.9935361118497134e-05,
      "loss": 2.8385,
      "step": 1435
    },
    {
      "epoch": 0.072,
      "grad_norm": 10.167953491210938,
      "learning_rate": 4.993386728649156e-05,
      "loss": 2.6307,
      "step": 1440
    },
    {
      "epoch": 0.07225,
      "grad_norm": 7.407008171081543,
      "learning_rate": 4.99323564124228e-05,
      "loss": 2.5408,
      "step": 1445
    },
    {
      "epoch": 0.0725,
      "grad_norm": 6.589657783508301,
      "learning_rate": 4.9930828497323526e-05,
      "loss": 2.2919,
      "step": 1450
    },
    {
      "epoch": 0.07275,
      "grad_norm": 8.201314926147461,
      "learning_rate": 4.992928354223807e-05,
      "loss": 2.5735,
      "step": 1455
    },
    {
      "epoch": 0.073,
      "grad_norm": 7.351102352142334,
      "learning_rate": 4.9927721548222374e-05,
      "loss": 2.5466,
      "step": 1460
    },
    {
      "epoch": 0.07325,
      "grad_norm": 11.16227912902832,
      "learning_rate": 4.992614251634405e-05,
      "loss": 2.6194,
      "step": 1465
    },
    {
      "epoch": 0.0735,
      "grad_norm": 10.714417457580566,
      "learning_rate": 4.992454644768236e-05,
      "loss": 2.2885,
      "step": 1470
    },
    {
      "epoch": 0.07375,
      "grad_norm": 7.02934455871582,
      "learning_rate": 4.99229333433282e-05,
      "loss": 2.6841,
      "step": 1475
    },
    {
      "epoch": 0.074,
      "grad_norm": 8.404176712036133,
      "learning_rate": 4.9921303204384104e-05,
      "loss": 2.3691,
      "step": 1480
    },
    {
      "epoch": 0.07425,
      "grad_norm": 7.453549861907959,
      "learning_rate": 4.991965603196427e-05,
      "loss": 2.5459,
      "step": 1485
    },
    {
      "epoch": 0.0745,
      "grad_norm": 11.220721244812012,
      "learning_rate": 4.991799182719451e-05,
      "loss": 2.6487,
      "step": 1490
    },
    {
      "epoch": 0.07475,
      "grad_norm": 5.799717426300049,
      "learning_rate": 4.99163105912123e-05,
      "loss": 2.3359,
      "step": 1495
    },
    {
      "epoch": 0.075,
      "grad_norm": 5.619781494140625,
      "learning_rate": 4.991461232516675e-05,
      "loss": 2.2022,
      "step": 1500
    },
    {
      "epoch": 0.075,
      "eval_loss": 2.373138427734375,
      "eval_runtime": 5.2906,
      "eval_samples_per_second": 193.55,
      "eval_steps_per_second": 24.194,
      "step": 1500
    },
    {
      "epoch": 0.07525,
      "grad_norm": 9.908714294433594,
      "learning_rate": 4.9912897030218605e-05,
      "loss": 2.6733,
      "step": 1505
    },
    {
      "epoch": 0.0755,
      "grad_norm": 6.908734321594238,
      "learning_rate": 4.991116470754025e-05,
      "loss": 2.5764,
      "step": 1510
    },
    {
      "epoch": 0.07575,
      "grad_norm": 8.342148780822754,
      "learning_rate": 4.990941535831572e-05,
      "loss": 2.5511,
      "step": 1515
    },
    {
      "epoch": 0.076,
      "grad_norm": 8.13355541229248,
      "learning_rate": 4.990764898374067e-05,
      "loss": 2.6302,
      "step": 1520
    },
    {
      "epoch": 0.07625,
      "grad_norm": 6.4599480628967285,
      "learning_rate": 4.990586558502242e-05,
      "loss": 2.3297,
      "step": 1525
    },
    {
      "epoch": 0.0765,
      "grad_norm": 6.475517749786377,
      "learning_rate": 4.990406516337987e-05,
      "loss": 2.3547,
      "step": 1530
    },
    {
      "epoch": 0.07675,
      "grad_norm": 7.481320858001709,
      "learning_rate": 4.9902247720043626e-05,
      "loss": 2.3308,
      "step": 1535
    },
    {
      "epoch": 0.077,
      "grad_norm": 7.853865623474121,
      "learning_rate": 4.9900413256255876e-05,
      "loss": 2.1612,
      "step": 1540
    },
    {
      "epoch": 0.07725,
      "grad_norm": 7.362637519836426,
      "learning_rate": 4.9898561773270456e-05,
      "loss": 2.4053,
      "step": 1545
    },
    {
      "epoch": 0.0775,
      "grad_norm": 8.494600296020508,
      "learning_rate": 4.9896693272352846e-05,
      "loss": 2.4089,
      "step": 1550
    },
    {
      "epoch": 0.07775,
      "grad_norm": 7.565699100494385,
      "learning_rate": 4.989480775478015e-05,
      "loss": 2.2371,
      "step": 1555
    },
    {
      "epoch": 0.078,
      "grad_norm": 7.120734691619873,
      "learning_rate": 4.98929052218411e-05,
      "loss": 2.3423,
      "step": 1560
    },
    {
      "epoch": 0.07825,
      "grad_norm": 5.707992076873779,
      "learning_rate": 4.989098567483605e-05,
      "loss": 2.1762,
      "step": 1565
    },
    {
      "epoch": 0.0785,
      "grad_norm": 8.764881134033203,
      "learning_rate": 4.9889049115077005e-05,
      "loss": 2.293,
      "step": 1570
    },
    {
      "epoch": 0.07875,
      "grad_norm": 6.080173492431641,
      "learning_rate": 4.988709554388757e-05,
      "loss": 2.2186,
      "step": 1575
    },
    {
      "epoch": 0.079,
      "grad_norm": 11.444064140319824,
      "learning_rate": 4.988512496260301e-05,
      "loss": 2.3407,
      "step": 1580
    },
    {
      "epoch": 0.07925,
      "grad_norm": 6.695216655731201,
      "learning_rate": 4.988313737257019e-05,
      "loss": 2.3805,
      "step": 1585
    },
    {
      "epoch": 0.0795,
      "grad_norm": 7.209412574768066,
      "learning_rate": 4.988113277514761e-05,
      "loss": 2.2965,
      "step": 1590
    },
    {
      "epoch": 0.07975,
      "grad_norm": 9.719297409057617,
      "learning_rate": 4.9879111171705394e-05,
      "loss": 2.3672,
      "step": 1595
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.14646053314209,
      "learning_rate": 4.9877072563625285e-05,
      "loss": 2.2739,
      "step": 1600
    },
    {
      "epoch": 0.08025,
      "grad_norm": 6.998955249786377,
      "learning_rate": 4.987501695230066e-05,
      "loss": 2.4422,
      "step": 1605
    },
    {
      "epoch": 0.0805,
      "grad_norm": 7.194464206695557,
      "learning_rate": 4.9872944339136503e-05,
      "loss": 2.2266,
      "step": 1610
    },
    {
      "epoch": 0.08075,
      "grad_norm": 11.950511932373047,
      "learning_rate": 4.987085472554943e-05,
      "loss": 2.3661,
      "step": 1615
    },
    {
      "epoch": 0.081,
      "grad_norm": 6.648146152496338,
      "learning_rate": 4.986874811296767e-05,
      "loss": 2.3576,
      "step": 1620
    },
    {
      "epoch": 0.08125,
      "grad_norm": 8.574056625366211,
      "learning_rate": 4.986662450283107e-05,
      "loss": 2.4927,
      "step": 1625
    },
    {
      "epoch": 0.0815,
      "grad_norm": 7.704388618469238,
      "learning_rate": 4.9864483896591094e-05,
      "loss": 2.348,
      "step": 1630
    },
    {
      "epoch": 0.08175,
      "grad_norm": 6.840899467468262,
      "learning_rate": 4.986232629571085e-05,
      "loss": 2.2742,
      "step": 1635
    },
    {
      "epoch": 0.082,
      "grad_norm": 6.162930965423584,
      "learning_rate": 4.9860151701665004e-05,
      "loss": 2.3501,
      "step": 1640
    },
    {
      "epoch": 0.08225,
      "grad_norm": 7.180642604827881,
      "learning_rate": 4.98579601159399e-05,
      "loss": 2.2603,
      "step": 1645
    },
    {
      "epoch": 0.0825,
      "grad_norm": 6.585172653198242,
      "learning_rate": 4.985575154003345e-05,
      "loss": 2.355,
      "step": 1650
    },
    {
      "epoch": 0.08275,
      "grad_norm": 7.297514915466309,
      "learning_rate": 4.985352597545519e-05,
      "loss": 2.2877,
      "step": 1655
    },
    {
      "epoch": 0.083,
      "grad_norm": 8.464256286621094,
      "learning_rate": 4.985128342372629e-05,
      "loss": 2.2859,
      "step": 1660
    },
    {
      "epoch": 0.08325,
      "grad_norm": 8.24039363861084,
      "learning_rate": 4.98490238863795e-05,
      "loss": 2.2409,
      "step": 1665
    },
    {
      "epoch": 0.0835,
      "grad_norm": 9.511998176574707,
      "learning_rate": 4.984674736495919e-05,
      "loss": 2.5546,
      "step": 1670
    },
    {
      "epoch": 0.08375,
      "grad_norm": 6.739645004272461,
      "learning_rate": 4.9844453861021356e-05,
      "loss": 2.1877,
      "step": 1675
    },
    {
      "epoch": 0.084,
      "grad_norm": 8.762070655822754,
      "learning_rate": 4.984214337613357e-05,
      "loss": 2.1682,
      "step": 1680
    },
    {
      "epoch": 0.08425,
      "grad_norm": 5.0530781745910645,
      "learning_rate": 4.983981591187504e-05,
      "loss": 2.0516,
      "step": 1685
    },
    {
      "epoch": 0.0845,
      "grad_norm": 8.47240161895752,
      "learning_rate": 4.983747146983656e-05,
      "loss": 2.4216,
      "step": 1690
    },
    {
      "epoch": 0.08475,
      "grad_norm": 6.516696453094482,
      "learning_rate": 4.9835110051620526e-05,
      "loss": 2.1551,
      "step": 1695
    },
    {
      "epoch": 0.085,
      "grad_norm": 7.835097789764404,
      "learning_rate": 4.9832731658840956e-05,
      "loss": 2.1319,
      "step": 1700
    },
    {
      "epoch": 0.08525,
      "grad_norm": 7.486099720001221,
      "learning_rate": 4.983033629312346e-05,
      "loss": 2.2607,
      "step": 1705
    },
    {
      "epoch": 0.0855,
      "grad_norm": 6.67869758605957,
      "learning_rate": 4.982792395610524e-05,
      "loss": 2.1126,
      "step": 1710
    },
    {
      "epoch": 0.08575,
      "grad_norm": 6.007040500640869,
      "learning_rate": 4.982549464943511e-05,
      "loss": 2.2407,
      "step": 1715
    },
    {
      "epoch": 0.086,
      "grad_norm": 6.660036563873291,
      "learning_rate": 4.982304837477348e-05,
      "loss": 2.4023,
      "step": 1720
    },
    {
      "epoch": 0.08625,
      "grad_norm": 5.94547700881958,
      "learning_rate": 4.982058513379235e-05,
      "loss": 2.0576,
      "step": 1725
    },
    {
      "epoch": 0.0865,
      "grad_norm": 5.727936267852783,
      "learning_rate": 4.981810492817532e-05,
      "loss": 2.0849,
      "step": 1730
    },
    {
      "epoch": 0.08675,
      "grad_norm": 5.892794132232666,
      "learning_rate": 4.9815607759617606e-05,
      "loss": 2.0919,
      "step": 1735
    },
    {
      "epoch": 0.087,
      "grad_norm": 10.098066329956055,
      "learning_rate": 4.981309362982598e-05,
      "loss": 2.3923,
      "step": 1740
    },
    {
      "epoch": 0.08725,
      "grad_norm": 7.0776543617248535,
      "learning_rate": 4.9810562540518825e-05,
      "loss": 2.2114,
      "step": 1745
    },
    {
      "epoch": 0.0875,
      "grad_norm": 8.409250259399414,
      "learning_rate": 4.980801449342613e-05,
      "loss": 2.4743,
      "step": 1750
    },
    {
      "epoch": 0.08775,
      "grad_norm": 8.230238914489746,
      "learning_rate": 4.980544949028945e-05,
      "loss": 2.2991,
      "step": 1755
    },
    {
      "epoch": 0.088,
      "grad_norm": 8.570466041564941,
      "learning_rate": 4.980286753286195e-05,
      "loss": 2.2202,
      "step": 1760
    },
    {
      "epoch": 0.08825,
      "grad_norm": 7.156739234924316,
      "learning_rate": 4.9800268622908366e-05,
      "loss": 2.2989,
      "step": 1765
    },
    {
      "epoch": 0.0885,
      "grad_norm": 5.929020404815674,
      "learning_rate": 4.9797652762205025e-05,
      "loss": 2.052,
      "step": 1770
    },
    {
      "epoch": 0.08875,
      "grad_norm": 6.030951023101807,
      "learning_rate": 4.979501995253986e-05,
      "loss": 2.3016,
      "step": 1775
    },
    {
      "epoch": 0.089,
      "grad_norm": 7.414441108703613,
      "learning_rate": 4.979237019571235e-05,
      "loss": 2.2724,
      "step": 1780
    },
    {
      "epoch": 0.08925,
      "grad_norm": 7.108556270599365,
      "learning_rate": 4.9789703493533596e-05,
      "loss": 2.3126,
      "step": 1785
    },
    {
      "epoch": 0.0895,
      "grad_norm": 8.528586387634277,
      "learning_rate": 4.978701984782625e-05,
      "loss": 2.3293,
      "step": 1790
    },
    {
      "epoch": 0.08975,
      "grad_norm": 7.54913854598999,
      "learning_rate": 4.978431926042457e-05,
      "loss": 2.0601,
      "step": 1795
    },
    {
      "epoch": 0.09,
      "grad_norm": 6.998185157775879,
      "learning_rate": 4.978160173317438e-05,
      "loss": 2.2684,
      "step": 1800
    },
    {
      "epoch": 0.09025,
      "grad_norm": 6.713746070861816,
      "learning_rate": 4.9778867267933084e-05,
      "loss": 2.3365,
      "step": 1805
    },
    {
      "epoch": 0.0905,
      "grad_norm": 7.091300010681152,
      "learning_rate": 4.9776115866569654e-05,
      "loss": 2.1077,
      "step": 1810
    },
    {
      "epoch": 0.09075,
      "grad_norm": 6.768202781677246,
      "learning_rate": 4.977334753096466e-05,
      "loss": 1.8967,
      "step": 1815
    },
    {
      "epoch": 0.091,
      "grad_norm": 6.08809757232666,
      "learning_rate": 4.9770562263010225e-05,
      "loss": 2.1515,
      "step": 1820
    },
    {
      "epoch": 0.09125,
      "grad_norm": 5.413473606109619,
      "learning_rate": 4.976776006461006e-05,
      "loss": 2.0948,
      "step": 1825
    },
    {
      "epoch": 0.0915,
      "grad_norm": 7.614098072052002,
      "learning_rate": 4.976494093767943e-05,
      "loss": 2.4469,
      "step": 1830
    },
    {
      "epoch": 0.09175,
      "grad_norm": 5.2740325927734375,
      "learning_rate": 4.976210488414519e-05,
      "loss": 2.4364,
      "step": 1835
    },
    {
      "epoch": 0.092,
      "grad_norm": 5.510372638702393,
      "learning_rate": 4.975925190594575e-05,
      "loss": 2.1176,
      "step": 1840
    },
    {
      "epoch": 0.09225,
      "grad_norm": 6.857629776000977,
      "learning_rate": 4.9756382005031106e-05,
      "loss": 2.3578,
      "step": 1845
    },
    {
      "epoch": 0.0925,
      "grad_norm": 8.387096405029297,
      "learning_rate": 4.9753495183362796e-05,
      "loss": 2.1245,
      "step": 1850
    },
    {
      "epoch": 0.09275,
      "grad_norm": 5.5980634689331055,
      "learning_rate": 4.975059144291394e-05,
      "loss": 2.3055,
      "step": 1855
    },
    {
      "epoch": 0.093,
      "grad_norm": 8.206244468688965,
      "learning_rate": 4.974767078566922e-05,
      "loss": 2.2149,
      "step": 1860
    },
    {
      "epoch": 0.09325,
      "grad_norm": 5.697643756866455,
      "learning_rate": 4.974473321362487e-05,
      "loss": 2.3995,
      "step": 1865
    },
    {
      "epoch": 0.0935,
      "grad_norm": 8.715389251708984,
      "learning_rate": 4.9741778728788705e-05,
      "loss": 2.4247,
      "step": 1870
    },
    {
      "epoch": 0.09375,
      "grad_norm": 6.301906108856201,
      "learning_rate": 4.973880733318007e-05,
      "loss": 2.4454,
      "step": 1875
    },
    {
      "epoch": 0.094,
      "grad_norm": 5.978703498840332,
      "learning_rate": 4.97358190288299e-05,
      "loss": 2.1764,
      "step": 1880
    },
    {
      "epoch": 0.09425,
      "grad_norm": 9.053447723388672,
      "learning_rate": 4.973281381778067e-05,
      "loss": 2.2928,
      "step": 1885
    },
    {
      "epoch": 0.0945,
      "grad_norm": 5.21058988571167,
      "learning_rate": 4.9729791702086414e-05,
      "loss": 2.0103,
      "step": 1890
    },
    {
      "epoch": 0.09475,
      "grad_norm": 6.593051910400391,
      "learning_rate": 4.9726752683812715e-05,
      "loss": 2.3976,
      "step": 1895
    },
    {
      "epoch": 0.095,
      "grad_norm": 8.668044090270996,
      "learning_rate": 4.972369676503672e-05,
      "loss": 2.3521,
      "step": 1900
    },
    {
      "epoch": 0.09525,
      "grad_norm": 7.906021595001221,
      "learning_rate": 4.97206239478471e-05,
      "loss": 2.2567,
      "step": 1905
    },
    {
      "epoch": 0.0955,
      "grad_norm": 6.6987996101379395,
      "learning_rate": 4.971753423434413e-05,
      "loss": 2.3564,
      "step": 1910
    },
    {
      "epoch": 0.09575,
      "grad_norm": 8.807966232299805,
      "learning_rate": 4.971442762663958e-05,
      "loss": 2.2779,
      "step": 1915
    },
    {
      "epoch": 0.096,
      "grad_norm": 6.330145835876465,
      "learning_rate": 4.971130412685679e-05,
      "loss": 2.2182,
      "step": 1920
    },
    {
      "epoch": 0.09625,
      "grad_norm": 6.015011787414551,
      "learning_rate": 4.9708163737130644e-05,
      "loss": 2.1661,
      "step": 1925
    },
    {
      "epoch": 0.0965,
      "grad_norm": 6.748201847076416,
      "learning_rate": 4.970500645960756e-05,
      "loss": 2.0446,
      "step": 1930
    },
    {
      "epoch": 0.09675,
      "grad_norm": 5.047901153564453,
      "learning_rate": 4.9701832296445526e-05,
      "loss": 2.12,
      "step": 1935
    },
    {
      "epoch": 0.097,
      "grad_norm": 6.17144250869751,
      "learning_rate": 4.9698641249814036e-05,
      "loss": 2.0936,
      "step": 1940
    },
    {
      "epoch": 0.09725,
      "grad_norm": 6.636044979095459,
      "learning_rate": 4.9695433321894145e-05,
      "loss": 2.0042,
      "step": 1945
    },
    {
      "epoch": 0.0975,
      "grad_norm": 14.736651420593262,
      "learning_rate": 4.9692208514878444e-05,
      "loss": 2.2186,
      "step": 1950
    },
    {
      "epoch": 0.09775,
      "grad_norm": 10.290700912475586,
      "learning_rate": 4.968896683097106e-05,
      "loss": 2.1433,
      "step": 1955
    },
    {
      "epoch": 0.098,
      "grad_norm": 6.026565074920654,
      "learning_rate": 4.968570827238764e-05,
      "loss": 2.1493,
      "step": 1960
    },
    {
      "epoch": 0.09825,
      "grad_norm": 5.5456223487854,
      "learning_rate": 4.96824328413554e-05,
      "loss": 1.9941,
      "step": 1965
    },
    {
      "epoch": 0.0985,
      "grad_norm": 5.909834861755371,
      "learning_rate": 4.967914054011305e-05,
      "loss": 2.0852,
      "step": 1970
    },
    {
      "epoch": 0.09875,
      "grad_norm": 5.666220188140869,
      "learning_rate": 4.967583137091085e-05,
      "loss": 2.1124,
      "step": 1975
    },
    {
      "epoch": 0.099,
      "grad_norm": 5.764509201049805,
      "learning_rate": 4.967250533601059e-05,
      "loss": 1.9665,
      "step": 1980
    },
    {
      "epoch": 0.09925,
      "grad_norm": 11.303183555603027,
      "learning_rate": 4.966916243768558e-05,
      "loss": 2.3589,
      "step": 1985
    },
    {
      "epoch": 0.0995,
      "grad_norm": 4.425251483917236,
      "learning_rate": 4.966580267822065e-05,
      "loss": 2.1208,
      "step": 1990
    },
    {
      "epoch": 0.09975,
      "grad_norm": 5.776776313781738,
      "learning_rate": 4.9662426059912184e-05,
      "loss": 2.0579,
      "step": 1995
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.655116558074951,
      "learning_rate": 4.965903258506806e-05,
      "loss": 2.324,
      "step": 2000
    },
    {
      "epoch": 0.1,
      "eval_loss": 2.359272003173828,
      "eval_runtime": 5.1451,
      "eval_samples_per_second": 199.022,
      "eval_steps_per_second": 24.878,
      "step": 2000
    },
    {
      "epoch": 0.10025,
      "grad_norm": 7.6346259117126465,
      "learning_rate": 4.9655622256007685e-05,
      "loss": 2.3421,
      "step": 2005
    },
    {
      "epoch": 0.1005,
      "grad_norm": 7.058793544769287,
      "learning_rate": 4.965219507506198e-05,
      "loss": 2.2201,
      "step": 2010
    },
    {
      "epoch": 0.10075,
      "grad_norm": 6.791335582733154,
      "learning_rate": 4.9648751044573405e-05,
      "loss": 2.2523,
      "step": 2015
    },
    {
      "epoch": 0.101,
      "grad_norm": 8.584449768066406,
      "learning_rate": 4.9645290166895906e-05,
      "loss": 2.2974,
      "step": 2020
    },
    {
      "epoch": 0.10125,
      "grad_norm": 6.512170791625977,
      "learning_rate": 4.964181244439498e-05,
      "loss": 2.3133,
      "step": 2025
    },
    {
      "epoch": 0.1015,
      "grad_norm": 5.3042378425598145,
      "learning_rate": 4.9638317879447606e-05,
      "loss": 2.0608,
      "step": 2030
    },
    {
      "epoch": 0.10175,
      "grad_norm": 6.1583476066589355,
      "learning_rate": 4.9634806474442274e-05,
      "loss": 2.1859,
      "step": 2035
    },
    {
      "epoch": 0.102,
      "grad_norm": 8.51344108581543,
      "learning_rate": 4.963127823177902e-05,
      "loss": 2.1319,
      "step": 2040
    },
    {
      "epoch": 0.10225,
      "grad_norm": 5.555214881896973,
      "learning_rate": 4.962773315386935e-05,
      "loss": 2.1491,
      "step": 2045
    },
    {
      "epoch": 0.1025,
      "grad_norm": 5.3118720054626465,
      "learning_rate": 4.96241712431363e-05,
      "loss": 2.0663,
      "step": 2050
    },
    {
      "epoch": 0.10275,
      "grad_norm": 5.968326091766357,
      "learning_rate": 4.9620592502014393e-05,
      "loss": 2.0997,
      "step": 2055
    },
    {
      "epoch": 0.103,
      "grad_norm": 5.341648578643799,
      "learning_rate": 4.9616996932949666e-05,
      "loss": 2.2354,
      "step": 2060
    },
    {
      "epoch": 0.10325,
      "grad_norm": 7.00523567199707,
      "learning_rate": 4.9613384538399665e-05,
      "loss": 1.857,
      "step": 2065
    },
    {
      "epoch": 0.1035,
      "grad_norm": 12.619558334350586,
      "learning_rate": 4.960975532083342e-05,
      "loss": 2.2173,
      "step": 2070
    },
    {
      "epoch": 0.10375,
      "grad_norm": 4.2388997077941895,
      "learning_rate": 4.9606109282731463e-05,
      "loss": 1.8536,
      "step": 2075
    },
    {
      "epoch": 0.104,
      "grad_norm": 5.373368740081787,
      "learning_rate": 4.960244642658585e-05,
      "loss": 2.3096,
      "step": 2080
    },
    {
      "epoch": 0.10425,
      "grad_norm": 7.711463451385498,
      "learning_rate": 4.959876675490007e-05,
      "loss": 2.2611,
      "step": 2085
    },
    {
      "epoch": 0.1045,
      "grad_norm": 6.207176208496094,
      "learning_rate": 4.959507027018918e-05,
      "loss": 2.2193,
      "step": 2090
    },
    {
      "epoch": 0.10475,
      "grad_norm": 7.139505863189697,
      "learning_rate": 4.959135697497967e-05,
      "loss": 1.9652,
      "step": 2095
    },
    {
      "epoch": 0.105,
      "grad_norm": 5.625710964202881,
      "learning_rate": 4.958762687180956e-05,
      "loss": 2.1805,
      "step": 2100
    },
    {
      "epoch": 0.10525,
      "grad_norm": 9.436490058898926,
      "learning_rate": 4.958387996322833e-05,
      "loss": 2.2775,
      "step": 2105
    },
    {
      "epoch": 0.1055,
      "grad_norm": 6.957341194152832,
      "learning_rate": 4.958011625179695e-05,
      "loss": 2.0891,
      "step": 2110
    },
    {
      "epoch": 0.10575,
      "grad_norm": 9.114760398864746,
      "learning_rate": 4.9576335740087886e-05,
      "loss": 2.2084,
      "step": 2115
    },
    {
      "epoch": 0.106,
      "grad_norm": 5.728249549865723,
      "learning_rate": 4.9572538430685094e-05,
      "loss": 1.9896,
      "step": 2120
    },
    {
      "epoch": 0.10625,
      "grad_norm": 5.234599590301514,
      "learning_rate": 4.956872432618399e-05,
      "loss": 2.1748,
      "step": 2125
    },
    {
      "epoch": 0.1065,
      "grad_norm": 8.449766159057617,
      "learning_rate": 4.956489342919147e-05,
      "loss": 2.2126,
      "step": 2130
    },
    {
      "epoch": 0.10675,
      "grad_norm": 6.967552661895752,
      "learning_rate": 4.956104574232593e-05,
      "loss": 2.1585,
      "step": 2135
    },
    {
      "epoch": 0.107,
      "grad_norm": 6.691867351531982,
      "learning_rate": 4.9557181268217227e-05,
      "loss": 2.0993,
      "step": 2140
    },
    {
      "epoch": 0.10725,
      "grad_norm": 7.298217296600342,
      "learning_rate": 4.9553300009506676e-05,
      "loss": 1.9052,
      "step": 2145
    },
    {
      "epoch": 0.1075,
      "grad_norm": 6.36298131942749,
      "learning_rate": 4.95494019688471e-05,
      "loss": 2.1214,
      "step": 2150
    },
    {
      "epoch": 0.10775,
      "grad_norm": 6.505710124969482,
      "learning_rate": 4.954548714890276e-05,
      "loss": 1.929,
      "step": 2155
    },
    {
      "epoch": 0.108,
      "grad_norm": 6.014697551727295,
      "learning_rate": 4.95415555523494e-05,
      "loss": 2.1898,
      "step": 2160
    },
    {
      "epoch": 0.10825,
      "grad_norm": 6.721339702606201,
      "learning_rate": 4.953760718187425e-05,
      "loss": 2.1973,
      "step": 2165
    },
    {
      "epoch": 0.1085,
      "grad_norm": 5.76655387878418,
      "learning_rate": 4.953364204017595e-05,
      "loss": 1.9303,
      "step": 2170
    },
    {
      "epoch": 0.10875,
      "grad_norm": 5.862256050109863,
      "learning_rate": 4.952966012996466e-05,
      "loss": 2.0082,
      "step": 2175
    },
    {
      "epoch": 0.109,
      "grad_norm": 5.214322090148926,
      "learning_rate": 4.952566145396197e-05,
      "loss": 2.2066,
      "step": 2180
    },
    {
      "epoch": 0.10925,
      "grad_norm": 5.055252552032471,
      "learning_rate": 4.952164601490094e-05,
      "loss": 1.9504,
      "step": 2185
    },
    {
      "epoch": 0.1095,
      "grad_norm": 6.639185905456543,
      "learning_rate": 4.951761381552609e-05,
      "loss": 1.8875,
      "step": 2190
    },
    {
      "epoch": 0.10975,
      "grad_norm": 3.903001308441162,
      "learning_rate": 4.9513564858593376e-05,
      "loss": 1.8108,
      "step": 2195
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.395508766174316,
      "learning_rate": 4.9509499146870236e-05,
      "loss": 2.1339,
      "step": 2200
    },
    {
      "epoch": 0.11025,
      "grad_norm": 7.025084018707275,
      "learning_rate": 4.950541668313554e-05,
      "loss": 1.9034,
      "step": 2205
    },
    {
      "epoch": 0.1105,
      "grad_norm": 6.05516242980957,
      "learning_rate": 4.9501317470179606e-05,
      "loss": 1.9455,
      "step": 2210
    },
    {
      "epoch": 0.11075,
      "grad_norm": 7.870569705963135,
      "learning_rate": 4.949720151080422e-05,
      "loss": 2.2529,
      "step": 2215
    },
    {
      "epoch": 0.111,
      "grad_norm": 6.115373134613037,
      "learning_rate": 4.94930688078226e-05,
      "loss": 2.0337,
      "step": 2220
    },
    {
      "epoch": 0.11125,
      "grad_norm": 6.651392459869385,
      "learning_rate": 4.948891936405941e-05,
      "loss": 2.3228,
      "step": 2225
    },
    {
      "epoch": 0.1115,
      "grad_norm": 8.072070121765137,
      "learning_rate": 4.948475318235073e-05,
      "loss": 2.1003,
      "step": 2230
    },
    {
      "epoch": 0.11175,
      "grad_norm": 7.271708011627197,
      "learning_rate": 4.9480570265544144e-05,
      "loss": 2.0011,
      "step": 2235
    },
    {
      "epoch": 0.112,
      "grad_norm": 6.171611785888672,
      "learning_rate": 4.9476370616498617e-05,
      "loss": 2.1183,
      "step": 2240
    },
    {
      "epoch": 0.11225,
      "grad_norm": 5.645359992980957,
      "learning_rate": 4.9472154238084574e-05,
      "loss": 1.9978,
      "step": 2245
    },
    {
      "epoch": 0.1125,
      "grad_norm": 5.326516628265381,
      "learning_rate": 4.946792113318386e-05,
      "loss": 2.301,
      "step": 2250
    },
    {
      "epoch": 0.11275,
      "grad_norm": 5.500300884246826,
      "learning_rate": 4.946367130468978e-05,
      "loss": 1.9353,
      "step": 2255
    },
    {
      "epoch": 0.113,
      "grad_norm": 6.266518592834473,
      "learning_rate": 4.945940475550703e-05,
      "loss": 1.9552,
      "step": 2260
    },
    {
      "epoch": 0.11325,
      "grad_norm": 5.557825565338135,
      "learning_rate": 4.945512148855178e-05,
      "loss": 2.0225,
      "step": 2265
    },
    {
      "epoch": 0.1135,
      "grad_norm": 4.745793342590332,
      "learning_rate": 4.945082150675159e-05,
      "loss": 1.9222,
      "step": 2270
    },
    {
      "epoch": 0.11375,
      "grad_norm": 6.747708320617676,
      "learning_rate": 4.944650481304545e-05,
      "loss": 2.0213,
      "step": 2275
    },
    {
      "epoch": 0.114,
      "grad_norm": 5.0579352378845215,
      "learning_rate": 4.944217141038379e-05,
      "loss": 1.8437,
      "step": 2280
    },
    {
      "epoch": 0.11425,
      "grad_norm": 9.001110076904297,
      "learning_rate": 4.943782130172845e-05,
      "loss": 1.9941,
      "step": 2285
    },
    {
      "epoch": 0.1145,
      "grad_norm": 4.885987281799316,
      "learning_rate": 4.9433454490052675e-05,
      "loss": 2.2588,
      "step": 2290
    },
    {
      "epoch": 0.11475,
      "grad_norm": 6.778171062469482,
      "learning_rate": 4.942907097834116e-05,
      "loss": 2.0419,
      "step": 2295
    },
    {
      "epoch": 0.115,
      "grad_norm": 10.324543952941895,
      "learning_rate": 4.9424670769589984e-05,
      "loss": 2.1627,
      "step": 2300
    },
    {
      "epoch": 0.11525,
      "grad_norm": 9.680310249328613,
      "learning_rate": 4.942025386680664e-05,
      "loss": 2.2939,
      "step": 2305
    },
    {
      "epoch": 0.1155,
      "grad_norm": 5.709784984588623,
      "learning_rate": 4.941582027301006e-05,
      "loss": 1.9583,
      "step": 2310
    },
    {
      "epoch": 0.11575,
      "grad_norm": 6.604119777679443,
      "learning_rate": 4.9411369991230536e-05,
      "loss": 2.1137,
      "step": 2315
    },
    {
      "epoch": 0.116,
      "grad_norm": 5.412128448486328,
      "learning_rate": 4.940690302450982e-05,
      "loss": 2.287,
      "step": 2320
    },
    {
      "epoch": 0.11625,
      "grad_norm": 5.815030574798584,
      "learning_rate": 4.940241937590102e-05,
      "loss": 2.144,
      "step": 2325
    },
    {
      "epoch": 0.1165,
      "grad_norm": 7.654050350189209,
      "learning_rate": 4.939791904846869e-05,
      "loss": 2.2758,
      "step": 2330
    },
    {
      "epoch": 0.11675,
      "grad_norm": 5.268087863922119,
      "learning_rate": 4.939340204528874e-05,
      "loss": 2.1177,
      "step": 2335
    },
    {
      "epoch": 0.117,
      "grad_norm": 5.506587982177734,
      "learning_rate": 4.938886836944851e-05,
      "loss": 2.1516,
      "step": 2340
    },
    {
      "epoch": 0.11725,
      "grad_norm": 4.832278728485107,
      "learning_rate": 4.938431802404672e-05,
      "loss": 2.1924,
      "step": 2345
    },
    {
      "epoch": 0.1175,
      "grad_norm": 5.161113739013672,
      "learning_rate": 4.93797510121935e-05,
      "loss": 2.0947,
      "step": 2350
    },
    {
      "epoch": 0.11775,
      "grad_norm": 5.4995293617248535,
      "learning_rate": 4.9375167337010345e-05,
      "loss": 1.991,
      "step": 2355
    },
    {
      "epoch": 0.118,
      "grad_norm": 8.605300903320312,
      "learning_rate": 4.937056700163015e-05,
      "loss": 2.0527,
      "step": 2360
    },
    {
      "epoch": 0.11825,
      "grad_norm": 8.081191062927246,
      "learning_rate": 4.9365950009197224e-05,
      "loss": 2.1571,
      "step": 2365
    },
    {
      "epoch": 0.1185,
      "grad_norm": 5.3213701248168945,
      "learning_rate": 4.9361316362867215e-05,
      "loss": 1.9467,
      "step": 2370
    },
    {
      "epoch": 0.11875,
      "grad_norm": 6.654092311859131,
      "learning_rate": 4.935666606580719e-05,
      "loss": 2.1089,
      "step": 2375
    },
    {
      "epoch": 0.119,
      "grad_norm": 6.640719890594482,
      "learning_rate": 4.935199912119558e-05,
      "loss": 2.0222,
      "step": 2380
    },
    {
      "epoch": 0.11925,
      "grad_norm": 4.574222087860107,
      "learning_rate": 4.934731553222219e-05,
      "loss": 1.9762,
      "step": 2385
    },
    {
      "epoch": 0.1195,
      "grad_norm": 8.473237991333008,
      "learning_rate": 4.934261530208823e-05,
      "loss": 2.054,
      "step": 2390
    },
    {
      "epoch": 0.11975,
      "grad_norm": 5.072817802429199,
      "learning_rate": 4.9337898434006226e-05,
      "loss": 1.9917,
      "step": 2395
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.668068885803223,
      "learning_rate": 4.933316493120015e-05,
      "loss": 2.0597,
      "step": 2400
    },
    {
      "epoch": 0.12025,
      "grad_norm": 5.185671329498291,
      "learning_rate": 4.9328414796905285e-05,
      "loss": 1.9094,
      "step": 2405
    },
    {
      "epoch": 0.1205,
      "grad_norm": 8.252269744873047,
      "learning_rate": 4.9323648034368316e-05,
      "loss": 2.0875,
      "step": 2410
    },
    {
      "epoch": 0.12075,
      "grad_norm": 8.878116607666016,
      "learning_rate": 4.931886464684727e-05,
      "loss": 2.1391,
      "step": 2415
    },
    {
      "epoch": 0.121,
      "grad_norm": 6.492772102355957,
      "learning_rate": 4.931406463761154e-05,
      "loss": 1.9769,
      "step": 2420
    },
    {
      "epoch": 0.12125,
      "grad_norm": 5.419919490814209,
      "learning_rate": 4.9309248009941914e-05,
      "loss": 1.8944,
      "step": 2425
    },
    {
      "epoch": 0.1215,
      "grad_norm": 4.946309566497803,
      "learning_rate": 4.930441476713049e-05,
      "loss": 2.0793,
      "step": 2430
    },
    {
      "epoch": 0.12175,
      "grad_norm": 6.99525785446167,
      "learning_rate": 4.929956491248076e-05,
      "loss": 1.9403,
      "step": 2435
    },
    {
      "epoch": 0.122,
      "grad_norm": 5.658833026885986,
      "learning_rate": 4.929469844930753e-05,
      "loss": 2.0705,
      "step": 2440
    },
    {
      "epoch": 0.12225,
      "grad_norm": 5.580067157745361,
      "learning_rate": 4.9289815380937e-05,
      "loss": 2.0767,
      "step": 2445
    },
    {
      "epoch": 0.1225,
      "grad_norm": 5.1723809242248535,
      "learning_rate": 4.9284915710706695e-05,
      "loss": 2.1366,
      "step": 2450
    },
    {
      "epoch": 0.12275,
      "grad_norm": 6.625626087188721,
      "learning_rate": 4.9279999441965495e-05,
      "loss": 2.2126,
      "step": 2455
    },
    {
      "epoch": 0.123,
      "grad_norm": 6.108854293823242,
      "learning_rate": 4.9275066578073626e-05,
      "loss": 2.0927,
      "step": 2460
    },
    {
      "epoch": 0.12325,
      "grad_norm": 6.1473236083984375,
      "learning_rate": 4.9270117122402645e-05,
      "loss": 2.0095,
      "step": 2465
    },
    {
      "epoch": 0.1235,
      "grad_norm": 5.732014179229736,
      "learning_rate": 4.926515107833547e-05,
      "loss": 2.0677,
      "step": 2470
    },
    {
      "epoch": 0.12375,
      "grad_norm": 6.241279125213623,
      "learning_rate": 4.9260168449266335e-05,
      "loss": 1.9831,
      "step": 2475
    },
    {
      "epoch": 0.124,
      "grad_norm": 5.92814826965332,
      "learning_rate": 4.925516923860083e-05,
      "loss": 2.0114,
      "step": 2480
    },
    {
      "epoch": 0.12425,
      "grad_norm": 6.928677082061768,
      "learning_rate": 4.9250153449755856e-05,
      "loss": 2.0566,
      "step": 2485
    },
    {
      "epoch": 0.1245,
      "grad_norm": 4.9016923904418945,
      "learning_rate": 4.9245121086159674e-05,
      "loss": 2.1146,
      "step": 2490
    },
    {
      "epoch": 0.12475,
      "grad_norm": 6.07392692565918,
      "learning_rate": 4.9240072151251834e-05,
      "loss": 2.0306,
      "step": 2495
    },
    {
      "epoch": 0.125,
      "grad_norm": 8.528595924377441,
      "learning_rate": 4.923500664848326e-05,
      "loss": 2.2852,
      "step": 2500
    },
    {
      "epoch": 0.125,
      "eval_loss": 2.308736562728882,
      "eval_runtime": 5.92,
      "eval_samples_per_second": 172.972,
      "eval_steps_per_second": 21.622,
      "step": 2500
    },
    {
      "epoch": 0.12525,
      "grad_norm": 5.895473957061768,
      "learning_rate": 4.9229924581316164e-05,
      "loss": 2.0358,
      "step": 2505
    },
    {
      "epoch": 0.1255,
      "grad_norm": 6.050929546356201,
      "learning_rate": 4.9224825953224084e-05,
      "loss": 2.231,
      "step": 2510
    },
    {
      "epoch": 0.12575,
      "grad_norm": 5.676328659057617,
      "learning_rate": 4.92197107676919e-05,
      "loss": 1.8607,
      "step": 2515
    },
    {
      "epoch": 0.126,
      "grad_norm": 5.83917236328125,
      "learning_rate": 4.9214579028215776e-05,
      "loss": 2.0072,
      "step": 2520
    },
    {
      "epoch": 0.12625,
      "grad_norm": 5.7940850257873535,
      "learning_rate": 4.920943073830322e-05,
      "loss": 2.0415,
      "step": 2525
    },
    {
      "epoch": 0.1265,
      "grad_norm": 11.59898567199707,
      "learning_rate": 4.920426590147304e-05,
      "loss": 2.1013,
      "step": 2530
    },
    {
      "epoch": 0.12675,
      "grad_norm": 6.68991231918335,
      "learning_rate": 4.9199084521255345e-05,
      "loss": 2.0724,
      "step": 2535
    },
    {
      "epoch": 0.127,
      "grad_norm": 5.269190788269043,
      "learning_rate": 4.919388660119156e-05,
      "loss": 2.081,
      "step": 2540
    },
    {
      "epoch": 0.12725,
      "grad_norm": 7.622641086578369,
      "learning_rate": 4.9188672144834423e-05,
      "loss": 1.9447,
      "step": 2545
    },
    {
      "epoch": 0.1275,
      "grad_norm": 4.964145660400391,
      "learning_rate": 4.918344115574796e-05,
      "loss": 2.0189,
      "step": 2550
    },
    {
      "epoch": 0.12775,
      "grad_norm": 4.888370513916016,
      "learning_rate": 4.91781936375075e-05,
      "loss": 2.0838,
      "step": 2555
    },
    {
      "epoch": 0.128,
      "grad_norm": 5.959444999694824,
      "learning_rate": 4.917292959369968e-05,
      "loss": 2.0791,
      "step": 2560
    },
    {
      "epoch": 0.12825,
      "grad_norm": 10.464829444885254,
      "learning_rate": 4.9167649027922415e-05,
      "loss": 2.271,
      "step": 2565
    },
    {
      "epoch": 0.1285,
      "grad_norm": 5.903755187988281,
      "learning_rate": 4.9162351943784935e-05,
      "loss": 2.143,
      "step": 2570
    },
    {
      "epoch": 0.12875,
      "grad_norm": 4.8404221534729,
      "learning_rate": 4.915703834490773e-05,
      "loss": 2.364,
      "step": 2575
    },
    {
      "epoch": 0.129,
      "grad_norm": 4.9720001220703125,
      "learning_rate": 4.9151708234922603e-05,
      "loss": 1.9799,
      "step": 2580
    },
    {
      "epoch": 0.12925,
      "grad_norm": 6.377746105194092,
      "learning_rate": 4.9146361617472633e-05,
      "loss": 2.1185,
      "step": 2585
    },
    {
      "epoch": 0.1295,
      "grad_norm": 4.5557026863098145,
      "learning_rate": 4.91409984962122e-05,
      "loss": 2.0255,
      "step": 2590
    },
    {
      "epoch": 0.12975,
      "grad_norm": 5.565547466278076,
      "learning_rate": 4.9135618874806914e-05,
      "loss": 1.9595,
      "step": 2595
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.762688159942627,
      "learning_rate": 4.913022275693372e-05,
      "loss": 2.0286,
      "step": 2600
    },
    {
      "epoch": 0.13025,
      "grad_norm": 5.445267200469971,
      "learning_rate": 4.91248101462808e-05,
      "loss": 2.0448,
      "step": 2605
    },
    {
      "epoch": 0.1305,
      "grad_norm": 6.880414009094238,
      "learning_rate": 4.9119381046547636e-05,
      "loss": 2.0898,
      "step": 2610
    },
    {
      "epoch": 0.13075,
      "grad_norm": 5.341586589813232,
      "learning_rate": 4.9113935461444955e-05,
      "loss": 2.053,
      "step": 2615
    },
    {
      "epoch": 0.131,
      "grad_norm": 9.405060768127441,
      "learning_rate": 4.910847339469477e-05,
      "loss": 1.8808,
      "step": 2620
    },
    {
      "epoch": 0.13125,
      "grad_norm": 7.4889678955078125,
      "learning_rate": 4.9102994850030344e-05,
      "loss": 1.9987,
      "step": 2625
    },
    {
      "epoch": 0.1315,
      "grad_norm": 4.776401519775391,
      "learning_rate": 4.9097499831196216e-05,
      "loss": 1.9515,
      "step": 2630
    },
    {
      "epoch": 0.13175,
      "grad_norm": 8.71658992767334,
      "learning_rate": 4.909198834194818e-05,
      "loss": 1.9992,
      "step": 2635
    },
    {
      "epoch": 0.132,
      "grad_norm": 5.601235389709473,
      "learning_rate": 4.908646038605329e-05,
      "loss": 1.9265,
      "step": 2640
    },
    {
      "epoch": 0.13225,
      "grad_norm": 14.46481704711914,
      "learning_rate": 4.908091596728984e-05,
      "loss": 1.9319,
      "step": 2645
    },
    {
      "epoch": 0.1325,
      "grad_norm": 5.461789131164551,
      "learning_rate": 4.907535508944741e-05,
      "loss": 1.7471,
      "step": 2650
    },
    {
      "epoch": 0.13275,
      "grad_norm": 8.820090293884277,
      "learning_rate": 4.906977775632678e-05,
      "loss": 1.8373,
      "step": 2655
    },
    {
      "epoch": 0.133,
      "grad_norm": 3.9437954425811768,
      "learning_rate": 4.906418397174002e-05,
      "loss": 1.4787,
      "step": 2660
    },
    {
      "epoch": 0.13325,
      "grad_norm": 13.892073631286621,
      "learning_rate": 4.905857373951043e-05,
      "loss": 2.1029,
      "step": 2665
    },
    {
      "epoch": 0.1335,
      "grad_norm": 4.726367950439453,
      "learning_rate": 4.905294706347255e-05,
      "loss": 1.6997,
      "step": 2670
    },
    {
      "epoch": 0.13375,
      "grad_norm": 4.498815059661865,
      "learning_rate": 4.904730394747216e-05,
      "loss": 1.5034,
      "step": 2675
    },
    {
      "epoch": 0.134,
      "grad_norm": 5.407666206359863,
      "learning_rate": 4.904164439536626e-05,
      "loss": 1.8296,
      "step": 2680
    },
    {
      "epoch": 0.13425,
      "grad_norm": 4.442748546600342,
      "learning_rate": 4.9035968411023126e-05,
      "loss": 1.8635,
      "step": 2685
    },
    {
      "epoch": 0.1345,
      "grad_norm": 4.852389812469482,
      "learning_rate": 4.903027599832223e-05,
      "loss": 1.8285,
      "step": 2690
    },
    {
      "epoch": 0.13475,
      "grad_norm": 7.615193843841553,
      "learning_rate": 4.902456716115428e-05,
      "loss": 1.9513,
      "step": 2695
    },
    {
      "epoch": 0.135,
      "grad_norm": 6.216709613800049,
      "learning_rate": 4.901884190342121e-05,
      "loss": 2.2361,
      "step": 2700
    },
    {
      "epoch": 0.13525,
      "grad_norm": 10.153247833251953,
      "learning_rate": 4.901310022903618e-05,
      "loss": 2.1392,
      "step": 2705
    },
    {
      "epoch": 0.1355,
      "grad_norm": 7.253368377685547,
      "learning_rate": 4.900734214192358e-05,
      "loss": 2.0673,
      "step": 2710
    },
    {
      "epoch": 0.13575,
      "grad_norm": 8.322628021240234,
      "learning_rate": 4.9001567646018996e-05,
      "loss": 2.1354,
      "step": 2715
    },
    {
      "epoch": 0.136,
      "grad_norm": 5.85282564163208,
      "learning_rate": 4.8995776745269254e-05,
      "loss": 1.8565,
      "step": 2720
    },
    {
      "epoch": 0.13625,
      "grad_norm": 7.781569480895996,
      "learning_rate": 4.8989969443632366e-05,
      "loss": 1.9278,
      "step": 2725
    },
    {
      "epoch": 0.1365,
      "grad_norm": 5.54121208190918,
      "learning_rate": 4.8984145745077584e-05,
      "loss": 2.1491,
      "step": 2730
    },
    {
      "epoch": 0.13675,
      "grad_norm": 6.551312446594238,
      "learning_rate": 4.897830565358534e-05,
      "loss": 2.095,
      "step": 2735
    },
    {
      "epoch": 0.137,
      "grad_norm": 5.905232906341553,
      "learning_rate": 4.8972449173147276e-05,
      "loss": 2.1608,
      "step": 2740
    },
    {
      "epoch": 0.13725,
      "grad_norm": 5.397660732269287,
      "learning_rate": 4.896657630776626e-05,
      "loss": 2.1463,
      "step": 2745
    },
    {
      "epoch": 0.1375,
      "grad_norm": 8.013290405273438,
      "learning_rate": 4.8960687061456324e-05,
      "loss": 1.8023,
      "step": 2750
    },
    {
      "epoch": 0.13775,
      "grad_norm": 7.508932590484619,
      "learning_rate": 4.895478143824271e-05,
      "loss": 2.0544,
      "step": 2755
    },
    {
      "epoch": 0.138,
      "grad_norm": 4.141922473907471,
      "learning_rate": 4.8948859442161874e-05,
      "loss": 2.1301,
      "step": 2760
    },
    {
      "epoch": 0.13825,
      "grad_norm": 6.4532575607299805,
      "learning_rate": 4.8942921077261425e-05,
      "loss": 2.0669,
      "step": 2765
    },
    {
      "epoch": 0.1385,
      "grad_norm": 8.753400802612305,
      "learning_rate": 4.893696634760019e-05,
      "loss": 2.1994,
      "step": 2770
    },
    {
      "epoch": 0.13875,
      "grad_norm": 6.383365154266357,
      "learning_rate": 4.893099525724818e-05,
      "loss": 2.1085,
      "step": 2775
    },
    {
      "epoch": 0.139,
      "grad_norm": 5.276760578155518,
      "learning_rate": 4.8925007810286546e-05,
      "loss": 2.0555,
      "step": 2780
    },
    {
      "epoch": 0.13925,
      "grad_norm": 4.785524845123291,
      "learning_rate": 4.891900401080769e-05,
      "loss": 1.9743,
      "step": 2785
    },
    {
      "epoch": 0.1395,
      "grad_norm": 5.580018043518066,
      "learning_rate": 4.891298386291513e-05,
      "loss": 1.8914,
      "step": 2790
    },
    {
      "epoch": 0.13975,
      "grad_norm": 4.785403728485107,
      "learning_rate": 4.8906947370723586e-05,
      "loss": 1.9749,
      "step": 2795
    },
    {
      "epoch": 0.14,
      "grad_norm": 7.892486572265625,
      "learning_rate": 4.8900894538358944e-05,
      "loss": 1.9729,
      "step": 2800
    },
    {
      "epoch": 0.14025,
      "grad_norm": 6.896144866943359,
      "learning_rate": 4.8894825369958255e-05,
      "loss": 2.2341,
      "step": 2805
    },
    {
      "epoch": 0.1405,
      "grad_norm": 5.482846736907959,
      "learning_rate": 4.888873986966974e-05,
      "loss": 1.8342,
      "step": 2810
    },
    {
      "epoch": 0.14075,
      "grad_norm": 7.458176136016846,
      "learning_rate": 4.888263804165279e-05,
      "loss": 2.1027,
      "step": 2815
    },
    {
      "epoch": 0.141,
      "grad_norm": 6.029018402099609,
      "learning_rate": 4.8876519890077926e-05,
      "loss": 1.9298,
      "step": 2820
    },
    {
      "epoch": 0.14125,
      "grad_norm": 5.397333145141602,
      "learning_rate": 4.887038541912686e-05,
      "loss": 2.1319,
      "step": 2825
    },
    {
      "epoch": 0.1415,
      "grad_norm": 5.415070533752441,
      "learning_rate": 4.8864234632992457e-05,
      "loss": 1.8211,
      "step": 2830
    },
    {
      "epoch": 0.14175,
      "grad_norm": 5.716930389404297,
      "learning_rate": 4.8858067535878696e-05,
      "loss": 1.7676,
      "step": 2835
    },
    {
      "epoch": 0.142,
      "grad_norm": 6.967779159545898,
      "learning_rate": 4.885188413200075e-05,
      "loss": 2.0637,
      "step": 2840
    },
    {
      "epoch": 0.14225,
      "grad_norm": 8.54919719696045,
      "learning_rate": 4.88456844255849e-05,
      "loss": 2.1312,
      "step": 2845
    },
    {
      "epoch": 0.1425,
      "grad_norm": 4.455983638763428,
      "learning_rate": 4.8839468420868606e-05,
      "loss": 1.7794,
      "step": 2850
    },
    {
      "epoch": 0.14275,
      "grad_norm": 4.272980690002441,
      "learning_rate": 4.883323612210043e-05,
      "loss": 1.8578,
      "step": 2855
    },
    {
      "epoch": 0.143,
      "grad_norm": 4.9769697189331055,
      "learning_rate": 4.8826987533540114e-05,
      "loss": 1.6991,
      "step": 2860
    },
    {
      "epoch": 0.14325,
      "grad_norm": 8.392765998840332,
      "learning_rate": 4.882072265945848e-05,
      "loss": 1.6652,
      "step": 2865
    },
    {
      "epoch": 0.1435,
      "grad_norm": 5.352476596832275,
      "learning_rate": 4.8814441504137534e-05,
      "loss": 1.9204,
      "step": 2870
    },
    {
      "epoch": 0.14375,
      "grad_norm": 7.5213494300842285,
      "learning_rate": 4.8808144071870364e-05,
      "loss": 1.9511,
      "step": 2875
    },
    {
      "epoch": 0.144,
      "grad_norm": 4.965796947479248,
      "learning_rate": 4.880183036696123e-05,
      "loss": 1.8238,
      "step": 2880
    },
    {
      "epoch": 0.14425,
      "grad_norm": 4.124453067779541,
      "learning_rate": 4.879550039372547e-05,
      "loss": 1.9642,
      "step": 2885
    },
    {
      "epoch": 0.1445,
      "grad_norm": 5.96658992767334,
      "learning_rate": 4.878915415648957e-05,
      "loss": 1.6376,
      "step": 2890
    },
    {
      "epoch": 0.14475,
      "grad_norm": 5.873588562011719,
      "learning_rate": 4.8782791659591134e-05,
      "loss": 1.5439,
      "step": 2895
    },
    {
      "epoch": 0.145,
      "grad_norm": 5.635045051574707,
      "learning_rate": 4.877641290737884e-05,
      "loss": 1.7444,
      "step": 2900
    },
    {
      "epoch": 0.14525,
      "grad_norm": 4.024995803833008,
      "learning_rate": 4.8770017904212525e-05,
      "loss": 1.5027,
      "step": 2905
    },
    {
      "epoch": 0.1455,
      "grad_norm": 7.621224880218506,
      "learning_rate": 4.876360665446312e-05,
      "loss": 1.8756,
      "step": 2910
    },
    {
      "epoch": 0.14575,
      "grad_norm": 4.042481899261475,
      "learning_rate": 4.875717916251264e-05,
      "loss": 1.9296,
      "step": 2915
    },
    {
      "epoch": 0.146,
      "grad_norm": 5.975202560424805,
      "learning_rate": 4.875073543275422e-05,
      "loss": 1.6149,
      "step": 2920
    },
    {
      "epoch": 0.14625,
      "grad_norm": 5.832411766052246,
      "learning_rate": 4.874427546959208e-05,
      "loss": 1.9015,
      "step": 2925
    },
    {
      "epoch": 0.1465,
      "grad_norm": 6.114006996154785,
      "learning_rate": 4.8737799277441566e-05,
      "loss": 2.7943,
      "step": 2930
    },
    {
      "epoch": 0.14675,
      "grad_norm": 7.696547985076904,
      "learning_rate": 4.873130686072907e-05,
      "loss": 3.1482,
      "step": 2935
    },
    {
      "epoch": 0.147,
      "grad_norm": 5.145132541656494,
      "learning_rate": 4.872479822389211e-05,
      "loss": 2.9477,
      "step": 2940
    },
    {
      "epoch": 0.14725,
      "grad_norm": 8.666359901428223,
      "learning_rate": 4.8718273371379275e-05,
      "loss": 2.9188,
      "step": 2945
    },
    {
      "epoch": 0.1475,
      "grad_norm": 5.510050296783447,
      "learning_rate": 4.871173230765024e-05,
      "loss": 2.8192,
      "step": 2950
    },
    {
      "epoch": 0.14775,
      "grad_norm": 6.76836633682251,
      "learning_rate": 4.870517503717576e-05,
      "loss": 2.8254,
      "step": 2955
    },
    {
      "epoch": 0.148,
      "grad_norm": 5.039107322692871,
      "learning_rate": 4.8698601564437675e-05,
      "loss": 2.7425,
      "step": 2960
    },
    {
      "epoch": 0.14825,
      "grad_norm": 6.866481781005859,
      "learning_rate": 4.8692011893928876e-05,
      "loss": 2.7001,
      "step": 2965
    },
    {
      "epoch": 0.1485,
      "grad_norm": 5.264921188354492,
      "learning_rate": 4.868540603015335e-05,
      "loss": 2.8055,
      "step": 2970
    },
    {
      "epoch": 0.14875,
      "grad_norm": 8.317389488220215,
      "learning_rate": 4.8678783977626155e-05,
      "loss": 2.9337,
      "step": 2975
    },
    {
      "epoch": 0.149,
      "grad_norm": 5.533519268035889,
      "learning_rate": 4.8672145740873374e-05,
      "loss": 2.833,
      "step": 2980
    },
    {
      "epoch": 0.14925,
      "grad_norm": 4.486927032470703,
      "learning_rate": 4.86654913244322e-05,
      "loss": 2.6956,
      "step": 2985
    },
    {
      "epoch": 0.1495,
      "grad_norm": 5.509954929351807,
      "learning_rate": 4.865882073285086e-05,
      "loss": 2.7241,
      "step": 2990
    },
    {
      "epoch": 0.14975,
      "grad_norm": 5.024867057800293,
      "learning_rate": 4.8652133970688636e-05,
      "loss": 2.6843,
      "step": 2995
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.536849021911621,
      "learning_rate": 4.864543104251587e-05,
      "loss": 2.6458,
      "step": 3000
    },
    {
      "epoch": 0.15,
      "eval_loss": 2.1075336933135986,
      "eval_runtime": 5.1258,
      "eval_samples_per_second": 199.774,
      "eval_steps_per_second": 24.972,
      "step": 3000
    },
    {
      "epoch": 0.15025,
      "grad_norm": 4.454989433288574,
      "learning_rate": 4.863871195291395e-05,
      "loss": 2.6716,
      "step": 3005
    },
    {
      "epoch": 0.1505,
      "grad_norm": 8.126754760742188,
      "learning_rate": 4.863197670647531e-05,
      "loss": 2.866,
      "step": 3010
    },
    {
      "epoch": 0.15075,
      "grad_norm": 7.491089344024658,
      "learning_rate": 4.862522530780342e-05,
      "loss": 2.8133,
      "step": 3015
    },
    {
      "epoch": 0.151,
      "grad_norm": 5.2902703285217285,
      "learning_rate": 4.861845776151281e-05,
      "loss": 2.6889,
      "step": 3020
    },
    {
      "epoch": 0.15125,
      "grad_norm": 4.697310924530029,
      "learning_rate": 4.8611674072229044e-05,
      "loss": 2.7058,
      "step": 3025
    },
    {
      "epoch": 0.1515,
      "grad_norm": 5.807609558105469,
      "learning_rate": 4.860487424458867e-05,
      "loss": 2.8759,
      "step": 3030
    },
    {
      "epoch": 0.15175,
      "grad_norm": 6.286968231201172,
      "learning_rate": 4.8598058283239344e-05,
      "loss": 2.7811,
      "step": 3035
    },
    {
      "epoch": 0.152,
      "grad_norm": 9.59628677368164,
      "learning_rate": 4.8591226192839696e-05,
      "loss": 3.6994,
      "step": 3040
    },
    {
      "epoch": 0.15225,
      "grad_norm": 7.855488300323486,
      "learning_rate": 4.8584377978059395e-05,
      "loss": 3.5809,
      "step": 3045
    },
    {
      "epoch": 0.1525,
      "grad_norm": 7.3187994956970215,
      "learning_rate": 4.857751364357913e-05,
      "loss": 3.3693,
      "step": 3050
    },
    {
      "epoch": 0.15275,
      "grad_norm": 7.989557266235352,
      "learning_rate": 4.857063319409062e-05,
      "loss": 2.7629,
      "step": 3055
    },
    {
      "epoch": 0.153,
      "grad_norm": 6.669147968292236,
      "learning_rate": 4.856373663429657e-05,
      "loss": 3.0124,
      "step": 3060
    },
    {
      "epoch": 0.15325,
      "grad_norm": 5.350693225860596,
      "learning_rate": 4.8556823968910734e-05,
      "loss": 2.4934,
      "step": 3065
    },
    {
      "epoch": 1.00025,
      "grad_norm": 8.07840633392334,
      "learning_rate": 4.8549895202657844e-05,
      "loss": 2.0508,
      "step": 3070
    },
    {
      "epoch": 1.0005,
      "grad_norm": 6.835604667663574,
      "learning_rate": 4.854295034027364e-05,
      "loss": 2.013,
      "step": 3075
    },
    {
      "epoch": 1.00075,
      "grad_norm": 5.376796245574951,
      "learning_rate": 4.853598938650487e-05,
      "loss": 1.958,
      "step": 3080
    },
    {
      "epoch": 1.001,
      "grad_norm": 8.185297966003418,
      "learning_rate": 4.852901234610929e-05,
      "loss": 1.8876,
      "step": 3085
    },
    {
      "epoch": 1.00125,
      "grad_norm": 6.475265979766846,
      "learning_rate": 4.852201922385564e-05,
      "loss": 2.1077,
      "step": 3090
    },
    {
      "epoch": 1.0015,
      "grad_norm": 7.752467155456543,
      "learning_rate": 4.851501002452364e-05,
      "loss": 2.1276,
      "step": 3095
    },
    {
      "epoch": 1.00175,
      "grad_norm": 5.445353031158447,
      "learning_rate": 4.850798475290403e-05,
      "loss": 1.6746,
      "step": 3100
    },
    {
      "epoch": 1.002,
      "grad_norm": 6.368800640106201,
      "learning_rate": 4.850094341379851e-05,
      "loss": 1.9272,
      "step": 3105
    },
    {
      "epoch": 1.00225,
      "grad_norm": 6.431137561798096,
      "learning_rate": 4.8493886012019765e-05,
      "loss": 1.9498,
      "step": 3110
    },
    {
      "epoch": 1.0025,
      "grad_norm": 6.690643787384033,
      "learning_rate": 4.848681255239146e-05,
      "loss": 2.1291,
      "step": 3115
    },
    {
      "epoch": 1.00275,
      "grad_norm": 10.237534523010254,
      "learning_rate": 4.8479723039748246e-05,
      "loss": 2.3201,
      "step": 3120
    },
    {
      "epoch": 1.003,
      "grad_norm": 8.51741886138916,
      "learning_rate": 4.8472617478935746e-05,
      "loss": 2.1467,
      "step": 3125
    },
    {
      "epoch": 1.00325,
      "grad_norm": 7.344959735870361,
      "learning_rate": 4.846549587481052e-05,
      "loss": 2.2469,
      "step": 3130
    },
    {
      "epoch": 1.0035,
      "grad_norm": 6.282517433166504,
      "learning_rate": 4.845835823224013e-05,
      "loss": 2.0233,
      "step": 3135
    },
    {
      "epoch": 1.00375,
      "grad_norm": 5.296603202819824,
      "learning_rate": 4.845120455610309e-05,
      "loss": 1.9291,
      "step": 3140
    },
    {
      "epoch": 1.004,
      "grad_norm": 16.300792694091797,
      "learning_rate": 4.8444034851288866e-05,
      "loss": 2.2962,
      "step": 3145
    },
    {
      "epoch": 1.00425,
      "grad_norm": 11.81851577758789,
      "learning_rate": 4.8436849122697883e-05,
      "loss": 2.3535,
      "step": 3150
    },
    {
      "epoch": 1.0045,
      "grad_norm": 7.446055889129639,
      "learning_rate": 4.842964737524153e-05,
      "loss": 2.2556,
      "step": 3155
    },
    {
      "epoch": 1.00475,
      "grad_norm": 8.401690483093262,
      "learning_rate": 4.842242961384211e-05,
      "loss": 2.282,
      "step": 3160
    },
    {
      "epoch": 1.005,
      "grad_norm": 7.486475467681885,
      "learning_rate": 4.8415195843432925e-05,
      "loss": 2.3185,
      "step": 3165
    },
    {
      "epoch": 1.00525,
      "grad_norm": 6.338302135467529,
      "learning_rate": 4.8407946068958165e-05,
      "loss": 2.2385,
      "step": 3170
    },
    {
      "epoch": 1.0055,
      "grad_norm": 7.914124011993408,
      "learning_rate": 4.840068029537299e-05,
      "loss": 2.5593,
      "step": 3175
    },
    {
      "epoch": 1.00575,
      "grad_norm": 5.585350513458252,
      "learning_rate": 4.83933985276435e-05,
      "loss": 2.2827,
      "step": 3180
    },
    {
      "epoch": 1.006,
      "grad_norm": 7.800945281982422,
      "learning_rate": 4.838610077074669e-05,
      "loss": 2.4591,
      "step": 3185
    },
    {
      "epoch": 1.00625,
      "grad_norm": 7.447098731994629,
      "learning_rate": 4.837878702967052e-05,
      "loss": 2.1929,
      "step": 3190
    },
    {
      "epoch": 1.0065,
      "grad_norm": 7.677919387817383,
      "learning_rate": 4.837145730941387e-05,
      "loss": 2.4006,
      "step": 3195
    },
    {
      "epoch": 1.00675,
      "grad_norm": 6.91140604019165,
      "learning_rate": 4.8364111614986527e-05,
      "loss": 2.0707,
      "step": 3200
    },
    {
      "epoch": 1.007,
      "grad_norm": 8.335005760192871,
      "learning_rate": 4.8356749951409204e-05,
      "loss": 2.1629,
      "step": 3205
    },
    {
      "epoch": 1.00725,
      "grad_norm": 6.634566307067871,
      "learning_rate": 4.834937232371353e-05,
      "loss": 2.3163,
      "step": 3210
    },
    {
      "epoch": 1.0075,
      "grad_norm": 6.287904262542725,
      "learning_rate": 4.834197873694205e-05,
      "loss": 2.3951,
      "step": 3215
    },
    {
      "epoch": 1.00775,
      "grad_norm": 8.925702095031738,
      "learning_rate": 4.83345691961482e-05,
      "loss": 2.1593,
      "step": 3220
    },
    {
      "epoch": 1.008,
      "grad_norm": 6.865070819854736,
      "learning_rate": 4.832714370639633e-05,
      "loss": 2.2158,
      "step": 3225
    },
    {
      "epoch": 1.00825,
      "grad_norm": 7.336075782775879,
      "learning_rate": 4.831970227276171e-05,
      "loss": 2.4168,
      "step": 3230
    },
    {
      "epoch": 1.0085,
      "grad_norm": 10.469801902770996,
      "learning_rate": 4.831224490033047e-05,
      "loss": 2.2226,
      "step": 3235
    },
    {
      "epoch": 1.00875,
      "grad_norm": 7.401913642883301,
      "learning_rate": 4.830477159419966e-05,
      "loss": 2.2276,
      "step": 3240
    },
    {
      "epoch": 1.009,
      "grad_norm": 7.851590633392334,
      "learning_rate": 4.8297282359477225e-05,
      "loss": 2.415,
      "step": 3245
    },
    {
      "epoch": 1.00925,
      "grad_norm": 6.9283447265625,
      "learning_rate": 4.8289777201281974e-05,
      "loss": 2.2217,
      "step": 3250
    },
    {
      "epoch": 1.0095,
      "grad_norm": 7.741013526916504,
      "learning_rate": 4.8282256124743616e-05,
      "loss": 2.1824,
      "step": 3255
    },
    {
      "epoch": 1.00975,
      "grad_norm": 10.491730690002441,
      "learning_rate": 4.827471913500274e-05,
      "loss": 2.3945,
      "step": 3260
    },
    {
      "epoch": 1.01,
      "grad_norm": 6.975367546081543,
      "learning_rate": 4.8267166237210796e-05,
      "loss": 2.206,
      "step": 3265
    },
    {
      "epoch": 1.01025,
      "grad_norm": 7.815775394439697,
      "learning_rate": 4.8259597436530125e-05,
      "loss": 2.2272,
      "step": 3270
    },
    {
      "epoch": 1.0105,
      "grad_norm": 5.598415851593018,
      "learning_rate": 4.825201273813393e-05,
      "loss": 2.4149,
      "step": 3275
    },
    {
      "epoch": 1.01075,
      "grad_norm": 8.737360000610352,
      "learning_rate": 4.8244412147206284e-05,
      "loss": 2.2551,
      "step": 3280
    },
    {
      "epoch": 1.011,
      "grad_norm": 7.0074896812438965,
      "learning_rate": 4.823679566894213e-05,
      "loss": 2.1601,
      "step": 3285
    },
    {
      "epoch": 1.01125,
      "grad_norm": 6.135278701782227,
      "learning_rate": 4.822916330854722e-05,
      "loss": 2.2717,
      "step": 3290
    },
    {
      "epoch": 1.0115,
      "grad_norm": 7.792422294616699,
      "learning_rate": 4.822151507123824e-05,
      "loss": 2.1183,
      "step": 3295
    },
    {
      "epoch": 1.01175,
      "grad_norm": 7.628849983215332,
      "learning_rate": 4.821385096224268e-05,
      "loss": 2.2289,
      "step": 3300
    },
    {
      "epoch": 1.012,
      "grad_norm": 7.43245267868042,
      "learning_rate": 4.8206170986798876e-05,
      "loss": 2.0797,
      "step": 3305
    },
    {
      "epoch": 1.01225,
      "grad_norm": 6.615355014801025,
      "learning_rate": 4.819847515015602e-05,
      "loss": 2.3478,
      "step": 3310
    },
    {
      "epoch": 1.0125,
      "grad_norm": 7.361934185028076,
      "learning_rate": 4.819076345757415e-05,
      "loss": 2.0865,
      "step": 3315
    },
    {
      "epoch": 1.01275,
      "grad_norm": 6.180245399475098,
      "learning_rate": 4.8183035914324136e-05,
      "loss": 1.8757,
      "step": 3320
    },
    {
      "epoch": 1.013,
      "grad_norm": 5.97892427444458,
      "learning_rate": 4.817529252568768e-05,
      "loss": 1.9875,
      "step": 3325
    },
    {
      "epoch": 1.01325,
      "grad_norm": 6.382593631744385,
      "learning_rate": 4.81675332969573e-05,
      "loss": 2.06,
      "step": 3330
    },
    {
      "epoch": 1.0135,
      "grad_norm": 7.258145332336426,
      "learning_rate": 4.815975823343638e-05,
      "loss": 1.9171,
      "step": 3335
    },
    {
      "epoch": 1.01375,
      "grad_norm": 8.738236427307129,
      "learning_rate": 4.815196734043909e-05,
      "loss": 2.0589,
      "step": 3340
    },
    {
      "epoch": 1.014,
      "grad_norm": 7.534472465515137,
      "learning_rate": 4.8144160623290424e-05,
      "loss": 2.4989,
      "step": 3345
    },
    {
      "epoch": 1.01425,
      "grad_norm": 6.029162406921387,
      "learning_rate": 4.8136338087326216e-05,
      "loss": 2.3724,
      "step": 3350
    },
    {
      "epoch": 1.0145,
      "grad_norm": 5.920984268188477,
      "learning_rate": 4.8128499737893086e-05,
      "loss": 1.9717,
      "step": 3355
    },
    {
      "epoch": 1.01475,
      "grad_norm": 6.034327030181885,
      "learning_rate": 4.812064558034847e-05,
      "loss": 2.2643,
      "step": 3360
    },
    {
      "epoch": 1.015,
      "grad_norm": 5.992404460906982,
      "learning_rate": 4.8112775620060626e-05,
      "loss": 2.0796,
      "step": 3365
    },
    {
      "epoch": 1.01525,
      "grad_norm": 7.324666500091553,
      "learning_rate": 4.810488986240858e-05,
      "loss": 1.4237,
      "step": 3370
    },
    {
      "epoch": 1.0155,
      "grad_norm": 8.221999168395996,
      "learning_rate": 4.8096988312782174e-05,
      "loss": 1.6251,
      "step": 3375
    },
    {
      "epoch": 1.01575,
      "grad_norm": 6.7294535636901855,
      "learning_rate": 4.8089070976582054e-05,
      "loss": 1.5538,
      "step": 3380
    },
    {
      "epoch": 1.016,
      "grad_norm": 5.523902893066406,
      "learning_rate": 4.808113785921963e-05,
      "loss": 1.2216,
      "step": 3385
    },
    {
      "epoch": 1.01625,
      "grad_norm": 6.428122043609619,
      "learning_rate": 4.8073188966117126e-05,
      "loss": 1.4924,
      "step": 3390
    },
    {
      "epoch": 1.0165,
      "grad_norm": 12.34906005859375,
      "learning_rate": 4.806522430270753e-05,
      "loss": 1.7186,
      "step": 3395
    },
    {
      "epoch": 1.01675,
      "grad_norm": 7.854061603546143,
      "learning_rate": 4.805724387443462e-05,
      "loss": 2.3191,
      "step": 3400
    },
    {
      "epoch": 1.017,
      "grad_norm": 7.585216045379639,
      "learning_rate": 4.804924768675294e-05,
      "loss": 2.5401,
      "step": 3405
    },
    {
      "epoch": 1.01725,
      "grad_norm": 6.793238639831543,
      "learning_rate": 4.80412357451278e-05,
      "loss": 2.2437,
      "step": 3410
    },
    {
      "epoch": 1.0175,
      "grad_norm": 9.01220703125,
      "learning_rate": 4.8033208055035296e-05,
      "loss": 2.2976,
      "step": 3415
    },
    {
      "epoch": 1.01775,
      "grad_norm": 7.803433895111084,
      "learning_rate": 4.8025164621962284e-05,
      "loss": 1.9463,
      "step": 3420
    },
    {
      "epoch": 1.018,
      "grad_norm": 6.921977996826172,
      "learning_rate": 4.801710545140635e-05,
      "loss": 2.0349,
      "step": 3425
    },
    {
      "epoch": 1.01825,
      "grad_norm": 8.333576202392578,
      "learning_rate": 4.8009030548875896e-05,
      "loss": 2.2752,
      "step": 3430
    },
    {
      "epoch": 1.0185,
      "grad_norm": 6.857061386108398,
      "learning_rate": 4.8000939919890015e-05,
      "loss": 2.432,
      "step": 3435
    },
    {
      "epoch": 1.01875,
      "grad_norm": 7.594109535217285,
      "learning_rate": 4.799283356997859e-05,
      "loss": 2.1595,
      "step": 3440
    },
    {
      "epoch": 1.019,
      "grad_norm": 6.650450706481934,
      "learning_rate": 4.7984711504682225e-05,
      "loss": 2.4079,
      "step": 3445
    },
    {
      "epoch": 1.01925,
      "grad_norm": 7.616575717926025,
      "learning_rate": 4.797657372955228e-05,
      "loss": 2.2187,
      "step": 3450
    },
    {
      "epoch": 1.0195,
      "grad_norm": 7.074879169464111,
      "learning_rate": 4.7968420250150846e-05,
      "loss": 2.1578,
      "step": 3455
    },
    {
      "epoch": 1.01975,
      "grad_norm": 6.926767826080322,
      "learning_rate": 4.796025107205075e-05,
      "loss": 1.9472,
      "step": 3460
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.368941783905029,
      "learning_rate": 4.7952066200835555e-05,
      "loss": 2.1692,
      "step": 3465
    },
    {
      "epoch": 1.02025,
      "grad_norm": 9.175427436828613,
      "learning_rate": 4.794386564209953e-05,
      "loss": 2.4598,
      "step": 3470
    },
    {
      "epoch": 1.0205,
      "grad_norm": 6.640302658081055,
      "learning_rate": 4.793564940144769e-05,
      "loss": 2.3272,
      "step": 3475
    },
    {
      "epoch": 1.02075,
      "grad_norm": 7.348874092102051,
      "learning_rate": 4.792741748449575e-05,
      "loss": 2.058,
      "step": 3480
    },
    {
      "epoch": 1.021,
      "grad_norm": 9.41956901550293,
      "learning_rate": 4.791916989687015e-05,
      "loss": 2.2497,
      "step": 3485
    },
    {
      "epoch": 1.02125,
      "grad_norm": 5.94675350189209,
      "learning_rate": 4.7910906644208054e-05,
      "loss": 2.2244,
      "step": 3490
    },
    {
      "epoch": 1.0215,
      "grad_norm": 7.466141223907471,
      "learning_rate": 4.7902627732157294e-05,
      "loss": 1.9743,
      "step": 3495
    },
    {
      "epoch": 1.02175,
      "grad_norm": 9.317771911621094,
      "learning_rate": 4.789433316637644e-05,
      "loss": 2.1821,
      "step": 3500
    },
    {
      "epoch": 1.02175,
      "eval_loss": 1.9820632934570312,
      "eval_runtime": 5.6778,
      "eval_samples_per_second": 180.352,
      "eval_steps_per_second": 22.544,
      "step": 3500
    },
    {
      "epoch": 1.022,
      "grad_norm": 6.82422399520874,
      "learning_rate": 4.7886022952534745e-05,
      "loss": 2.4114,
      "step": 3505
    },
    {
      "epoch": 1.02225,
      "grad_norm": 9.285131454467773,
      "learning_rate": 4.787769709631217e-05,
      "loss": 2.5109,
      "step": 3510
    },
    {
      "epoch": 1.0225,
      "grad_norm": 7.78342342376709,
      "learning_rate": 4.7869355603399346e-05,
      "loss": 2.6357,
      "step": 3515
    },
    {
      "epoch": 1.02275,
      "grad_norm": 8.187332153320312,
      "learning_rate": 4.786099847949761e-05,
      "loss": 2.2584,
      "step": 3520
    },
    {
      "epoch": 1.023,
      "grad_norm": 6.168136119842529,
      "learning_rate": 4.785262573031899e-05,
      "loss": 2.363,
      "step": 3525
    },
    {
      "epoch": 1.02325,
      "grad_norm": 6.938079833984375,
      "learning_rate": 4.784423736158616e-05,
      "loss": 1.9962,
      "step": 3530
    },
    {
      "epoch": 1.0235,
      "grad_norm": 9.121776580810547,
      "learning_rate": 4.7835833379032516e-05,
      "loss": 2.2992,
      "step": 3535
    },
    {
      "epoch": 1.02375,
      "grad_norm": 5.405620098114014,
      "learning_rate": 4.7827413788402077e-05,
      "loss": 2.0096,
      "step": 3540
    },
    {
      "epoch": 1.024,
      "grad_norm": 8.291473388671875,
      "learning_rate": 4.7818978595449556e-05,
      "loss": 2.0866,
      "step": 3545
    },
    {
      "epoch": 1.02425,
      "grad_norm": 6.387077808380127,
      "learning_rate": 4.781052780594034e-05,
      "loss": 1.9992,
      "step": 3550
    },
    {
      "epoch": 1.0245,
      "grad_norm": 11.882519721984863,
      "learning_rate": 4.780206142565047e-05,
      "loss": 2.595,
      "step": 3555
    },
    {
      "epoch": 1.02475,
      "grad_norm": 6.443548679351807,
      "learning_rate": 4.779357946036661e-05,
      "loss": 2.1542,
      "step": 3560
    },
    {
      "epoch": 1.025,
      "grad_norm": 9.277969360351562,
      "learning_rate": 4.7785081915886134e-05,
      "loss": 2.233,
      "step": 3565
    },
    {
      "epoch": 1.02525,
      "grad_norm": 4.566981792449951,
      "learning_rate": 4.777656879801701e-05,
      "loss": 2.0683,
      "step": 3570
    },
    {
      "epoch": 1.0255,
      "grad_norm": 7.679964542388916,
      "learning_rate": 4.7768040112577885e-05,
      "loss": 2.3339,
      "step": 3575
    },
    {
      "epoch": 1.02575,
      "grad_norm": 5.732082366943359,
      "learning_rate": 4.775949586539803e-05,
      "loss": 2.374,
      "step": 3580
    },
    {
      "epoch": 1.026,
      "grad_norm": 7.9710001945495605,
      "learning_rate": 4.775093606231737e-05,
      "loss": 2.0355,
      "step": 3585
    },
    {
      "epoch": 1.02625,
      "grad_norm": 9.227510452270508,
      "learning_rate": 4.774236070918643e-05,
      "loss": 2.6046,
      "step": 3590
    },
    {
      "epoch": 1.0265,
      "grad_norm": 7.047170639038086,
      "learning_rate": 4.7733769811866405e-05,
      "loss": 2.0631,
      "step": 3595
    },
    {
      "epoch": 1.02675,
      "grad_norm": 9.62891960144043,
      "learning_rate": 4.7725163376229064e-05,
      "loss": 2.2591,
      "step": 3600
    },
    {
      "epoch": 1.027,
      "grad_norm": 9.404744148254395,
      "learning_rate": 4.771654140815685e-05,
      "loss": 2.1724,
      "step": 3605
    },
    {
      "epoch": 1.02725,
      "grad_norm": 6.789613723754883,
      "learning_rate": 4.770790391354279e-05,
      "loss": 2.1046,
      "step": 3610
    },
    {
      "epoch": 1.0275,
      "grad_norm": 8.028067588806152,
      "learning_rate": 4.769925089829052e-05,
      "loss": 2.0381,
      "step": 3615
    },
    {
      "epoch": 1.02775,
      "grad_norm": 6.899889945983887,
      "learning_rate": 4.7690582368314304e-05,
      "loss": 2.2632,
      "step": 3620
    },
    {
      "epoch": 1.028,
      "grad_norm": 10.17885971069336,
      "learning_rate": 4.7681898329539e-05,
      "loss": 2.1,
      "step": 3625
    },
    {
      "epoch": 1.02825,
      "grad_norm": 8.303735733032227,
      "learning_rate": 4.7673198787900063e-05,
      "loss": 2.4244,
      "step": 3630
    },
    {
      "epoch": 1.0285,
      "grad_norm": 6.7238640785217285,
      "learning_rate": 4.766448374934356e-05,
      "loss": 2.1065,
      "step": 3635
    },
    {
      "epoch": 1.02875,
      "grad_norm": 10.189833641052246,
      "learning_rate": 4.7655753219826114e-05,
      "loss": 2.3101,
      "step": 3640
    },
    {
      "epoch": 1.029,
      "grad_norm": 7.404840469360352,
      "learning_rate": 4.7647007205314985e-05,
      "loss": 2.1484,
      "step": 3645
    },
    {
      "epoch": 1.02925,
      "grad_norm": 6.3637213706970215,
      "learning_rate": 4.763824571178798e-05,
      "loss": 2.1113,
      "step": 3650
    },
    {
      "epoch": 1.0295,
      "grad_norm": 4.827723979949951,
      "learning_rate": 4.7629468745233486e-05,
      "loss": 1.8271,
      "step": 3655
    },
    {
      "epoch": 1.02975,
      "grad_norm": 8.996358871459961,
      "learning_rate": 4.762067631165049e-05,
      "loss": 2.1871,
      "step": 3660
    },
    {
      "epoch": 1.03,
      "grad_norm": 4.895386695861816,
      "learning_rate": 4.761186841704854e-05,
      "loss": 2.0212,
      "step": 3665
    },
    {
      "epoch": 1.03025,
      "grad_norm": 9.040709495544434,
      "learning_rate": 4.760304506744774e-05,
      "loss": 2.2107,
      "step": 3670
    },
    {
      "epoch": 1.0305,
      "grad_norm": 7.167008399963379,
      "learning_rate": 4.759420626887877e-05,
      "loss": 2.2267,
      "step": 3675
    },
    {
      "epoch": 1.03075,
      "grad_norm": 8.20396900177002,
      "learning_rate": 4.7585352027382877e-05,
      "loss": 2.1108,
      "step": 3680
    },
    {
      "epoch": 1.031,
      "grad_norm": 5.461686134338379,
      "learning_rate": 4.7576482349011833e-05,
      "loss": 2.0211,
      "step": 3685
    },
    {
      "epoch": 1.03125,
      "grad_norm": 7.447123050689697,
      "learning_rate": 4.7567597239827974e-05,
      "loss": 2.2973,
      "step": 3690
    },
    {
      "epoch": 1.0315,
      "grad_norm": 7.222445964813232,
      "learning_rate": 4.755869670590421e-05,
      "loss": 2.0683,
      "step": 3695
    },
    {
      "epoch": 1.03175,
      "grad_norm": 5.82656192779541,
      "learning_rate": 4.754978075332398e-05,
      "loss": 2.0978,
      "step": 3700
    },
    {
      "epoch": 1.032,
      "grad_norm": 6.368584632873535,
      "learning_rate": 4.754084938818122e-05,
      "loss": 2.0225,
      "step": 3705
    },
    {
      "epoch": 1.03225,
      "grad_norm": 8.662199974060059,
      "learning_rate": 4.753190261658045e-05,
      "loss": 2.1298,
      "step": 3710
    },
    {
      "epoch": 1.0325,
      "grad_norm": 7.639814853668213,
      "learning_rate": 4.752294044463671e-05,
      "loss": 1.8537,
      "step": 3715
    },
    {
      "epoch": 1.03275,
      "grad_norm": 6.715540885925293,
      "learning_rate": 4.751396287847556e-05,
      "loss": 1.806,
      "step": 3720
    },
    {
      "epoch": 1.033,
      "grad_norm": 7.323692321777344,
      "learning_rate": 4.750496992423307e-05,
      "loss": 2.0265,
      "step": 3725
    },
    {
      "epoch": 1.03325,
      "grad_norm": 7.039766311645508,
      "learning_rate": 4.7495961588055836e-05,
      "loss": 2.0838,
      "step": 3730
    },
    {
      "epoch": 1.0335,
      "grad_norm": 6.53250789642334,
      "learning_rate": 4.748693787610099e-05,
      "loss": 2.1014,
      "step": 3735
    },
    {
      "epoch": 1.03375,
      "grad_norm": 9.633206367492676,
      "learning_rate": 4.747789879453615e-05,
      "loss": 2.3111,
      "step": 3740
    },
    {
      "epoch": 1.034,
      "grad_norm": 6.270496368408203,
      "learning_rate": 4.746884434953943e-05,
      "loss": 2.3985,
      "step": 3745
    },
    {
      "epoch": 1.0342500000000001,
      "grad_norm": 6.661495208740234,
      "learning_rate": 4.7459774547299475e-05,
      "loss": 1.9398,
      "step": 3750
    },
    {
      "epoch": 1.0345,
      "grad_norm": 6.504430294036865,
      "learning_rate": 4.745068939401539e-05,
      "loss": 2.0837,
      "step": 3755
    },
    {
      "epoch": 1.03475,
      "grad_norm": 5.67809534072876,
      "learning_rate": 4.7441588895896805e-05,
      "loss": 2.1768,
      "step": 3760
    },
    {
      "epoch": 1.035,
      "grad_norm": 7.215278148651123,
      "learning_rate": 4.743247305916383e-05,
      "loss": 2.2872,
      "step": 3765
    },
    {
      "epoch": 1.03525,
      "grad_norm": 5.575353622436523,
      "learning_rate": 4.742334189004704e-05,
      "loss": 2.1569,
      "step": 3770
    },
    {
      "epoch": 1.0355,
      "grad_norm": 4.991117000579834,
      "learning_rate": 4.74141953947875e-05,
      "loss": 2.1389,
      "step": 3775
    },
    {
      "epoch": 1.03575,
      "grad_norm": 6.3710527420043945,
      "learning_rate": 4.7405033579636756e-05,
      "loss": 2.0943,
      "step": 3780
    },
    {
      "epoch": 1.036,
      "grad_norm": 8.325810432434082,
      "learning_rate": 4.739585645085684e-05,
      "loss": 2.417,
      "step": 3785
    },
    {
      "epoch": 1.03625,
      "grad_norm": 6.174420356750488,
      "learning_rate": 4.738666401472022e-05,
      "loss": 2.2452,
      "step": 3790
    },
    {
      "epoch": 1.0365,
      "grad_norm": 12.609034538269043,
      "learning_rate": 4.737745627750984e-05,
      "loss": 2.276,
      "step": 3795
    },
    {
      "epoch": 1.03675,
      "grad_norm": 7.499090671539307,
      "learning_rate": 4.736823324551909e-05,
      "loss": 2.2587,
      "step": 3800
    },
    {
      "epoch": 1.037,
      "grad_norm": 4.602488994598389,
      "learning_rate": 4.735899492505184e-05,
      "loss": 2.2188,
      "step": 3805
    },
    {
      "epoch": 1.03725,
      "grad_norm": 5.877565383911133,
      "learning_rate": 4.73497413224224e-05,
      "loss": 2.1859,
      "step": 3810
    },
    {
      "epoch": 1.0375,
      "grad_norm": 6.6756463050842285,
      "learning_rate": 4.73404724439555e-05,
      "loss": 2.3823,
      "step": 3815
    },
    {
      "epoch": 1.03775,
      "grad_norm": 5.0961079597473145,
      "learning_rate": 4.733118829598635e-05,
      "loss": 2.115,
      "step": 3820
    },
    {
      "epoch": 1.038,
      "grad_norm": 5.650045871734619,
      "learning_rate": 4.732188888486057e-05,
      "loss": 2.0893,
      "step": 3825
    },
    {
      "epoch": 1.03825,
      "grad_norm": 9.39893913269043,
      "learning_rate": 4.7312574216934225e-05,
      "loss": 2.1952,
      "step": 3830
    },
    {
      "epoch": 1.0385,
      "grad_norm": 6.776681900024414,
      "learning_rate": 4.730324429857379e-05,
      "loss": 2.1603,
      "step": 3835
    },
    {
      "epoch": 1.03875,
      "grad_norm": 6.331654071807861,
      "learning_rate": 4.7293899136156184e-05,
      "loss": 2.3604,
      "step": 3840
    },
    {
      "epoch": 1.039,
      "grad_norm": 8.039820671081543,
      "learning_rate": 4.728453873606874e-05,
      "loss": 2.0981,
      "step": 3845
    },
    {
      "epoch": 1.03925,
      "grad_norm": 5.160001754760742,
      "learning_rate": 4.72751631047092e-05,
      "loss": 2.0623,
      "step": 3850
    },
    {
      "epoch": 1.0395,
      "grad_norm": 7.120738983154297,
      "learning_rate": 4.7265772248485715e-05,
      "loss": 2.2723,
      "step": 3855
    },
    {
      "epoch": 1.03975,
      "grad_norm": 5.3576250076293945,
      "learning_rate": 4.725636617381686e-05,
      "loss": 2.0939,
      "step": 3860
    },
    {
      "epoch": 1.04,
      "grad_norm": 5.938125133514404,
      "learning_rate": 4.7246944887131586e-05,
      "loss": 2.0958,
      "step": 3865
    },
    {
      "epoch": 1.04025,
      "grad_norm": 5.841825008392334,
      "learning_rate": 4.723750839486926e-05,
      "loss": 2.2098,
      "step": 3870
    },
    {
      "epoch": 1.0405,
      "grad_norm": 7.4774041175842285,
      "learning_rate": 4.722805670347963e-05,
      "loss": 2.0418,
      "step": 3875
    },
    {
      "epoch": 1.04075,
      "grad_norm": 5.36475944519043,
      "learning_rate": 4.721858981942284e-05,
      "loss": 1.9562,
      "step": 3880
    },
    {
      "epoch": 1.041,
      "grad_norm": 5.609219551086426,
      "learning_rate": 4.7209107749169424e-05,
      "loss": 2.2942,
      "step": 3885
    },
    {
      "epoch": 1.04125,
      "grad_norm": 6.497797012329102,
      "learning_rate": 4.719961049920027e-05,
      "loss": 2.2826,
      "step": 3890
    },
    {
      "epoch": 1.0415,
      "grad_norm": 5.543242454528809,
      "learning_rate": 4.719009807600668e-05,
      "loss": 2.3488,
      "step": 3895
    },
    {
      "epoch": 1.04175,
      "grad_norm": 6.011270046234131,
      "learning_rate": 4.71805704860903e-05,
      "loss": 2.3164,
      "step": 3900
    },
    {
      "epoch": 1.042,
      "grad_norm": 7.681313514709473,
      "learning_rate": 4.7171027735963136e-05,
      "loss": 2.1961,
      "step": 3905
    },
    {
      "epoch": 1.04225,
      "grad_norm": 7.371852397918701,
      "learning_rate": 4.716146983214757e-05,
      "loss": 2.2238,
      "step": 3910
    },
    {
      "epoch": 1.0425,
      "grad_norm": 5.853066921234131,
      "learning_rate": 4.7151896781176346e-05,
      "loss": 2.3016,
      "step": 3915
    },
    {
      "epoch": 1.04275,
      "grad_norm": 7.635056495666504,
      "learning_rate": 4.7142308589592556e-05,
      "loss": 2.2538,
      "step": 3920
    },
    {
      "epoch": 1.043,
      "grad_norm": 10.296113967895508,
      "learning_rate": 4.7132705263949626e-05,
      "loss": 2.1126,
      "step": 3925
    },
    {
      "epoch": 1.04325,
      "grad_norm": 5.953316688537598,
      "learning_rate": 4.7123086810811356e-05,
      "loss": 2.5097,
      "step": 3930
    },
    {
      "epoch": 1.0435,
      "grad_norm": 7.386350631713867,
      "learning_rate": 4.711345323675186e-05,
      "loss": 2.4046,
      "step": 3935
    },
    {
      "epoch": 1.04375,
      "grad_norm": 5.3855509757995605,
      "learning_rate": 4.710380454835559e-05,
      "loss": 2.0393,
      "step": 3940
    },
    {
      "epoch": 1.044,
      "grad_norm": 6.291208267211914,
      "learning_rate": 4.709414075221734e-05,
      "loss": 2.1117,
      "step": 3945
    },
    {
      "epoch": 1.04425,
      "grad_norm": 5.3934245109558105,
      "learning_rate": 4.708446185494222e-05,
      "loss": 2.0365,
      "step": 3950
    },
    {
      "epoch": 1.0445,
      "grad_norm": 5.332141399383545,
      "learning_rate": 4.7074767863145664e-05,
      "loss": 2.1098,
      "step": 3955
    },
    {
      "epoch": 1.04475,
      "grad_norm": 7.726265907287598,
      "learning_rate": 4.7065058783453424e-05,
      "loss": 2.3649,
      "step": 3960
    },
    {
      "epoch": 1.045,
      "grad_norm": 5.245527267456055,
      "learning_rate": 4.705533462250157e-05,
      "loss": 2.2092,
      "step": 3965
    },
    {
      "epoch": 1.04525,
      "grad_norm": 6.800533294677734,
      "learning_rate": 4.704559538693647e-05,
      "loss": 2.1001,
      "step": 3970
    },
    {
      "epoch": 1.0455,
      "grad_norm": 7.119924545288086,
      "learning_rate": 4.703584108341481e-05,
      "loss": 2.107,
      "step": 3975
    },
    {
      "epoch": 1.04575,
      "grad_norm": 5.81452751159668,
      "learning_rate": 4.7026071718603536e-05,
      "loss": 2.1184,
      "step": 3980
    },
    {
      "epoch": 1.046,
      "grad_norm": 5.987485885620117,
      "learning_rate": 4.701628729917995e-05,
      "loss": 2.05,
      "step": 3985
    },
    {
      "epoch": 1.04625,
      "grad_norm": 7.005894184112549,
      "learning_rate": 4.700648783183159e-05,
      "loss": 2.346,
      "step": 3990
    },
    {
      "epoch": 1.0465,
      "grad_norm": 5.0007548332214355,
      "learning_rate": 4.699667332325631e-05,
      "loss": 2.0486,
      "step": 3995
    },
    {
      "epoch": 1.04675,
      "grad_norm": 6.29308557510376,
      "learning_rate": 4.698684378016222e-05,
      "loss": 2.0477,
      "step": 4000
    },
    {
      "epoch": 1.04675,
      "eval_loss": 1.9267234802246094,
      "eval_runtime": 5.0917,
      "eval_samples_per_second": 201.11,
      "eval_steps_per_second": 25.139,
      "step": 4000
    },
    {
      "epoch": 1.047,
      "grad_norm": 7.211773872375488,
      "learning_rate": 4.697699920926775e-05,
      "loss": 2.0579,
      "step": 4005
    },
    {
      "epoch": 1.04725,
      "grad_norm": 5.348665714263916,
      "learning_rate": 4.696713961730154e-05,
      "loss": 2.1807,
      "step": 4010
    },
    {
      "epoch": 1.0475,
      "grad_norm": 6.986086368560791,
      "learning_rate": 4.695726501100254e-05,
      "loss": 1.9651,
      "step": 4015
    },
    {
      "epoch": 1.04775,
      "grad_norm": 6.216989994049072,
      "learning_rate": 4.694737539711994e-05,
      "loss": 2.1875,
      "step": 4020
    },
    {
      "epoch": 1.048,
      "grad_norm": 5.752617835998535,
      "learning_rate": 4.693747078241322e-05,
      "loss": 2.2206,
      "step": 4025
    },
    {
      "epoch": 1.04825,
      "grad_norm": 8.28859806060791,
      "learning_rate": 4.6927551173652075e-05,
      "loss": 2.3628,
      "step": 4030
    },
    {
      "epoch": 1.0485,
      "grad_norm": 5.190698623657227,
      "learning_rate": 4.691761657761646e-05,
      "loss": 2.1363,
      "step": 4035
    },
    {
      "epoch": 1.04875,
      "grad_norm": 5.111480712890625,
      "learning_rate": 4.690766700109659e-05,
      "loss": 2.1492,
      "step": 4040
    },
    {
      "epoch": 1.049,
      "grad_norm": 6.365204334259033,
      "learning_rate": 4.6897702450892906e-05,
      "loss": 2.2215,
      "step": 4045
    },
    {
      "epoch": 1.04925,
      "grad_norm": 6.385697841644287,
      "learning_rate": 4.6887722933816076e-05,
      "loss": 2.1194,
      "step": 4050
    },
    {
      "epoch": 1.0495,
      "grad_norm": 10.257000923156738,
      "learning_rate": 4.687772845668701e-05,
      "loss": 2.1538,
      "step": 4055
    },
    {
      "epoch": 1.04975,
      "grad_norm": 5.297052383422852,
      "learning_rate": 4.686771902633684e-05,
      "loss": 1.8847,
      "step": 4060
    },
    {
      "epoch": 1.05,
      "grad_norm": 7.96937370300293,
      "learning_rate": 4.685769464960691e-05,
      "loss": 2.0895,
      "step": 4065
    },
    {
      "epoch": 1.05025,
      "grad_norm": 6.809342384338379,
      "learning_rate": 4.684765533334879e-05,
      "loss": 2.2228,
      "step": 4070
    },
    {
      "epoch": 1.0505,
      "grad_norm": 5.776035308837891,
      "learning_rate": 4.683760108442428e-05,
      "loss": 2.1341,
      "step": 4075
    },
    {
      "epoch": 1.05075,
      "grad_norm": 5.43408727645874,
      "learning_rate": 4.682753190970533e-05,
      "loss": 2.2553,
      "step": 4080
    },
    {
      "epoch": 1.051,
      "grad_norm": 5.192442417144775,
      "learning_rate": 4.681744781607414e-05,
      "loss": 2.0866,
      "step": 4085
    },
    {
      "epoch": 1.05125,
      "grad_norm": 5.22816801071167,
      "learning_rate": 4.68073488104231e-05,
      "loss": 2.1832,
      "step": 4090
    },
    {
      "epoch": 1.0515,
      "grad_norm": 5.278865814208984,
      "learning_rate": 4.6797234899654774e-05,
      "loss": 2.12,
      "step": 4095
    },
    {
      "epoch": 1.05175,
      "grad_norm": 7.250347137451172,
      "learning_rate": 4.678710609068193e-05,
      "loss": 2.2321,
      "step": 4100
    },
    {
      "epoch": 1.052,
      "grad_norm": 5.92927885055542,
      "learning_rate": 4.677696239042752e-05,
      "loss": 1.9506,
      "step": 4105
    },
    {
      "epoch": 1.05225,
      "grad_norm": 5.348419666290283,
      "learning_rate": 4.6766803805824655e-05,
      "loss": 2.1642,
      "step": 4110
    },
    {
      "epoch": 1.0525,
      "grad_norm": 4.643019199371338,
      "learning_rate": 4.6756630343816644e-05,
      "loss": 2.0884,
      "step": 4115
    },
    {
      "epoch": 1.05275,
      "grad_norm": 6.521512031555176,
      "learning_rate": 4.674644201135694e-05,
      "loss": 2.1936,
      "step": 4120
    },
    {
      "epoch": 1.053,
      "grad_norm": 5.455228328704834,
      "learning_rate": 4.6736238815409174e-05,
      "loss": 2.0521,
      "step": 4125
    },
    {
      "epoch": 1.05325,
      "grad_norm": 4.283334255218506,
      "learning_rate": 4.672602076294714e-05,
      "loss": 2.0998,
      "step": 4130
    },
    {
      "epoch": 1.0535,
      "grad_norm": 6.058481216430664,
      "learning_rate": 4.671578786095478e-05,
      "loss": 2.0486,
      "step": 4135
    },
    {
      "epoch": 1.05375,
      "grad_norm": 5.025057315826416,
      "learning_rate": 4.670554011642619e-05,
      "loss": 2.0385,
      "step": 4140
    },
    {
      "epoch": 1.054,
      "grad_norm": 6.077906608581543,
      "learning_rate": 4.66952775363656e-05,
      "loss": 1.864,
      "step": 4145
    },
    {
      "epoch": 1.05425,
      "grad_norm": 7.069394111633301,
      "learning_rate": 4.668500012778738e-05,
      "loss": 1.9632,
      "step": 4150
    },
    {
      "epoch": 1.0545,
      "grad_norm": 5.742644786834717,
      "learning_rate": 4.667470789771605e-05,
      "loss": 2.2479,
      "step": 4155
    },
    {
      "epoch": 1.05475,
      "grad_norm": 4.983944892883301,
      "learning_rate": 4.666440085318626e-05,
      "loss": 2.3708,
      "step": 4160
    },
    {
      "epoch": 1.055,
      "grad_norm": 7.695660591125488,
      "learning_rate": 4.6654079001242774e-05,
      "loss": 2.0905,
      "step": 4165
    },
    {
      "epoch": 1.05525,
      "grad_norm": 4.246820449829102,
      "learning_rate": 4.6643742348940464e-05,
      "loss": 2.124,
      "step": 4170
    },
    {
      "epoch": 1.0555,
      "grad_norm": 5.6282734870910645,
      "learning_rate": 4.6633390903344354e-05,
      "loss": 2.0408,
      "step": 4175
    },
    {
      "epoch": 1.05575,
      "grad_norm": 5.598058700561523,
      "learning_rate": 4.662302467152955e-05,
      "loss": 2.1372,
      "step": 4180
    },
    {
      "epoch": 1.056,
      "grad_norm": 5.794990539550781,
      "learning_rate": 4.6612643660581276e-05,
      "loss": 1.9945,
      "step": 4185
    },
    {
      "epoch": 1.05625,
      "grad_norm": 7.366287708282471,
      "learning_rate": 4.660224787759486e-05,
      "loss": 2.2855,
      "step": 4190
    },
    {
      "epoch": 1.0565,
      "grad_norm": 5.272023677825928,
      "learning_rate": 4.659183732967571e-05,
      "loss": 1.9789,
      "step": 4195
    },
    {
      "epoch": 1.05675,
      "grad_norm": 7.9226579666137695,
      "learning_rate": 4.6581412023939354e-05,
      "loss": 2.2412,
      "step": 4200
    },
    {
      "epoch": 1.057,
      "grad_norm": 5.465578556060791,
      "learning_rate": 4.657097196751137e-05,
      "loss": 1.8879,
      "step": 4205
    },
    {
      "epoch": 1.05725,
      "grad_norm": 5.384119987487793,
      "learning_rate": 4.656051716752745e-05,
      "loss": 2.1558,
      "step": 4210
    },
    {
      "epoch": 1.0575,
      "grad_norm": 4.907980918884277,
      "learning_rate": 4.6550047631133345e-05,
      "loss": 2.0608,
      "step": 4215
    },
    {
      "epoch": 1.05775,
      "grad_norm": 5.615555286407471,
      "learning_rate": 4.65395633654849e-05,
      "loss": 1.9092,
      "step": 4220
    },
    {
      "epoch": 1.058,
      "grad_norm": 5.394869327545166,
      "learning_rate": 4.652906437774799e-05,
      "loss": 1.8874,
      "step": 4225
    },
    {
      "epoch": 1.05825,
      "grad_norm": 6.329094409942627,
      "learning_rate": 4.65185506750986e-05,
      "loss": 1.8206,
      "step": 4230
    },
    {
      "epoch": 1.0585,
      "grad_norm": 5.542673587799072,
      "learning_rate": 4.6508022264722715e-05,
      "loss": 2.2346,
      "step": 4235
    },
    {
      "epoch": 1.05875,
      "grad_norm": 8.966267585754395,
      "learning_rate": 4.649747915381643e-05,
      "loss": 1.9771,
      "step": 4240
    },
    {
      "epoch": 1.059,
      "grad_norm": 5.833073139190674,
      "learning_rate": 4.648692134958585e-05,
      "loss": 2.2453,
      "step": 4245
    },
    {
      "epoch": 1.05925,
      "grad_norm": 4.510608196258545,
      "learning_rate": 4.6476348859247134e-05,
      "loss": 1.9389,
      "step": 4250
    },
    {
      "epoch": 1.0594999999999999,
      "grad_norm": 6.539348602294922,
      "learning_rate": 4.6465761690026485e-05,
      "loss": 2.2525,
      "step": 4255
    },
    {
      "epoch": 1.05975,
      "grad_norm": 9.135680198669434,
      "learning_rate": 4.645515984916013e-05,
      "loss": 2.0795,
      "step": 4260
    },
    {
      "epoch": 1.06,
      "grad_norm": 6.605693340301514,
      "learning_rate": 4.644454334389433e-05,
      "loss": 2.2699,
      "step": 4265
    },
    {
      "epoch": 1.06025,
      "grad_norm": 5.8201117515563965,
      "learning_rate": 4.643391218148536e-05,
      "loss": 2.0612,
      "step": 4270
    },
    {
      "epoch": 1.0605,
      "grad_norm": 6.39307165145874,
      "learning_rate": 4.6423266369199524e-05,
      "loss": 2.4077,
      "step": 4275
    },
    {
      "epoch": 1.06075,
      "grad_norm": 5.7858428955078125,
      "learning_rate": 4.6412605914313144e-05,
      "loss": 1.9622,
      "step": 4280
    },
    {
      "epoch": 1.061,
      "grad_norm": 5.514277935028076,
      "learning_rate": 4.640193082411252e-05,
      "loss": 2.0611,
      "step": 4285
    },
    {
      "epoch": 1.06125,
      "grad_norm": 6.137416839599609,
      "learning_rate": 4.639124110589399e-05,
      "loss": 2.1049,
      "step": 4290
    },
    {
      "epoch": 1.0615,
      "grad_norm": 4.808355808258057,
      "learning_rate": 4.638053676696387e-05,
      "loss": 2.0206,
      "step": 4295
    },
    {
      "epoch": 1.06175,
      "grad_norm": 6.166045665740967,
      "learning_rate": 4.6369817814638475e-05,
      "loss": 2.0253,
      "step": 4300
    },
    {
      "epoch": 1.062,
      "grad_norm": 5.462447643280029,
      "learning_rate": 4.635908425624411e-05,
      "loss": 2.08,
      "step": 4305
    },
    {
      "epoch": 1.06225,
      "grad_norm": 6.931205749511719,
      "learning_rate": 4.634833609911706e-05,
      "loss": 2.138,
      "step": 4310
    },
    {
      "epoch": 1.0625,
      "grad_norm": 5.472877025604248,
      "learning_rate": 4.6337573350603594e-05,
      "loss": 1.8262,
      "step": 4315
    },
    {
      "epoch": 1.06275,
      "grad_norm": 7.454887390136719,
      "learning_rate": 4.6326796018059936e-05,
      "loss": 1.9988,
      "step": 4320
    },
    {
      "epoch": 1.063,
      "grad_norm": 6.313100814819336,
      "learning_rate": 4.6316004108852305e-05,
      "loss": 2.1428,
      "step": 4325
    },
    {
      "epoch": 1.06325,
      "grad_norm": 6.48561954498291,
      "learning_rate": 4.630519763035687e-05,
      "loss": 2.1703,
      "step": 4330
    },
    {
      "epoch": 1.0635,
      "grad_norm": 4.483323574066162,
      "learning_rate": 4.629437658995974e-05,
      "loss": 1.8733,
      "step": 4335
    },
    {
      "epoch": 1.06375,
      "grad_norm": 5.414252281188965,
      "learning_rate": 4.6283540995057004e-05,
      "loss": 1.9353,
      "step": 4340
    },
    {
      "epoch": 1.064,
      "grad_norm": 7.708644866943359,
      "learning_rate": 4.627269085305469e-05,
      "loss": 1.9161,
      "step": 4345
    },
    {
      "epoch": 1.06425,
      "grad_norm": 8.460071563720703,
      "learning_rate": 4.6261826171368774e-05,
      "loss": 2.2199,
      "step": 4350
    },
    {
      "epoch": 1.0645,
      "grad_norm": 4.387929439544678,
      "learning_rate": 4.625094695742516e-05,
      "loss": 1.9644,
      "step": 4355
    },
    {
      "epoch": 1.06475,
      "grad_norm": 7.462438106536865,
      "learning_rate": 4.6240053218659674e-05,
      "loss": 2.2196,
      "step": 4360
    },
    {
      "epoch": 1.065,
      "grad_norm": 7.831259250640869,
      "learning_rate": 4.62291449625181e-05,
      "loss": 2.253,
      "step": 4365
    },
    {
      "epoch": 1.06525,
      "grad_norm": 7.932337760925293,
      "learning_rate": 4.621822219645612e-05,
      "loss": 2.2773,
      "step": 4370
    },
    {
      "epoch": 1.0655000000000001,
      "grad_norm": 6.4043354988098145,
      "learning_rate": 4.620728492793934e-05,
      "loss": 2.0846,
      "step": 4375
    },
    {
      "epoch": 1.06575,
      "grad_norm": 5.801063537597656,
      "learning_rate": 4.6196333164443295e-05,
      "loss": 2.1084,
      "step": 4380
    },
    {
      "epoch": 1.066,
      "grad_norm": 6.618105411529541,
      "learning_rate": 4.6185366913453395e-05,
      "loss": 1.9839,
      "step": 4385
    },
    {
      "epoch": 1.06625,
      "grad_norm": 5.9329304695129395,
      "learning_rate": 4.617438618246498e-05,
      "loss": 2.2814,
      "step": 4390
    },
    {
      "epoch": 1.0665,
      "grad_norm": 5.84403657913208,
      "learning_rate": 4.616339097898327e-05,
      "loss": 2.1666,
      "step": 4395
    },
    {
      "epoch": 1.06675,
      "grad_norm": 7.095782279968262,
      "learning_rate": 4.6152381310523387e-05,
      "loss": 2.0629,
      "step": 4400
    },
    {
      "epoch": 1.067,
      "grad_norm": 5.650106906890869,
      "learning_rate": 4.614135718461034e-05,
      "loss": 2.1526,
      "step": 4405
    },
    {
      "epoch": 1.06725,
      "grad_norm": 5.393583297729492,
      "learning_rate": 4.6130318608778995e-05,
      "loss": 1.8885,
      "step": 4410
    },
    {
      "epoch": 1.0675,
      "grad_norm": 6.047986030578613,
      "learning_rate": 4.6119265590574134e-05,
      "loss": 1.9503,
      "step": 4415
    },
    {
      "epoch": 1.06775,
      "grad_norm": 5.473196029663086,
      "learning_rate": 4.610819813755038e-05,
      "loss": 1.9739,
      "step": 4420
    },
    {
      "epoch": 1.068,
      "grad_norm": 4.160706520080566,
      "learning_rate": 4.609711625727224e-05,
      "loss": 2.0385,
      "step": 4425
    },
    {
      "epoch": 1.06825,
      "grad_norm": 5.447325229644775,
      "learning_rate": 4.608601995731407e-05,
      "loss": 1.9946,
      "step": 4430
    },
    {
      "epoch": 1.0685,
      "grad_norm": 4.782063961029053,
      "learning_rate": 4.60749092452601e-05,
      "loss": 1.9671,
      "step": 4435
    },
    {
      "epoch": 1.06875,
      "grad_norm": 4.7649946212768555,
      "learning_rate": 4.6063784128704367e-05,
      "loss": 1.8626,
      "step": 4440
    },
    {
      "epoch": 1.069,
      "grad_norm": 3.68819522857666,
      "learning_rate": 4.605264461525082e-05,
      "loss": 1.795,
      "step": 4445
    },
    {
      "epoch": 1.06925,
      "grad_norm": 6.521597385406494,
      "learning_rate": 4.604149071251318e-05,
      "loss": 1.9221,
      "step": 4450
    },
    {
      "epoch": 1.0695000000000001,
      "grad_norm": 3.4145166873931885,
      "learning_rate": 4.603032242811505e-05,
      "loss": 1.7866,
      "step": 4455
    },
    {
      "epoch": 1.06975,
      "grad_norm": 3.5083670616149902,
      "learning_rate": 4.601913976968985e-05,
      "loss": 1.8705,
      "step": 4460
    },
    {
      "epoch": 1.07,
      "grad_norm": 5.1515793800354,
      "learning_rate": 4.6007942744880806e-05,
      "loss": 1.9653,
      "step": 4465
    },
    {
      "epoch": 1.07025,
      "grad_norm": 4.976546287536621,
      "learning_rate": 4.5996731361340994e-05,
      "loss": 1.6441,
      "step": 4470
    },
    {
      "epoch": 1.0705,
      "grad_norm": 3.877469301223755,
      "learning_rate": 4.598550562673329e-05,
      "loss": 1.8228,
      "step": 4475
    },
    {
      "epoch": 1.07075,
      "grad_norm": 4.963026523590088,
      "learning_rate": 4.597426554873037e-05,
      "loss": 1.7792,
      "step": 4480
    },
    {
      "epoch": 1.071,
      "grad_norm": 4.713569164276123,
      "learning_rate": 4.596301113501471e-05,
      "loss": 1.6375,
      "step": 4485
    },
    {
      "epoch": 1.07125,
      "grad_norm": 3.7954912185668945,
      "learning_rate": 4.595174239327862e-05,
      "loss": 1.7534,
      "step": 4490
    },
    {
      "epoch": 1.0715,
      "grad_norm": 4.717560768127441,
      "learning_rate": 4.594045933122417e-05,
      "loss": 1.8809,
      "step": 4495
    },
    {
      "epoch": 1.07175,
      "grad_norm": 5.523906707763672,
      "learning_rate": 4.592916195656322e-05,
      "loss": 2.1391,
      "step": 4500
    },
    {
      "epoch": 1.07175,
      "eval_loss": 1.987128496170044,
      "eval_runtime": 5.1614,
      "eval_samples_per_second": 198.397,
      "eval_steps_per_second": 24.8,
      "step": 4500
    },
    {
      "epoch": 1.072,
      "grad_norm": 4.769815921783447,
      "learning_rate": 4.5917850277017415e-05,
      "loss": 1.9378,
      "step": 4505
    },
    {
      "epoch": 1.07225,
      "grad_norm": 4.341281890869141,
      "learning_rate": 4.59065243003182e-05,
      "loss": 1.8244,
      "step": 4510
    },
    {
      "epoch": 1.0725,
      "grad_norm": 4.651285171508789,
      "learning_rate": 4.5895184034206765e-05,
      "loss": 1.6351,
      "step": 4515
    },
    {
      "epoch": 1.07275,
      "grad_norm": 5.065062046051025,
      "learning_rate": 4.588382948643406e-05,
      "loss": 1.9003,
      "step": 4520
    },
    {
      "epoch": 1.073,
      "grad_norm": 4.40664529800415,
      "learning_rate": 4.587246066476083e-05,
      "loss": 1.8581,
      "step": 4525
    },
    {
      "epoch": 1.07325,
      "grad_norm": 6.257813930511475,
      "learning_rate": 4.586107757695755e-05,
      "loss": 1.8588,
      "step": 4530
    },
    {
      "epoch": 1.0735,
      "grad_norm": 5.4031147956848145,
      "learning_rate": 4.584968023080446e-05,
      "loss": 1.6473,
      "step": 4535
    },
    {
      "epoch": 1.07375,
      "grad_norm": 3.7445485591888428,
      "learning_rate": 4.5838268634091524e-05,
      "loss": 1.9168,
      "step": 4540
    },
    {
      "epoch": 1.074,
      "grad_norm": 5.356757164001465,
      "learning_rate": 4.5826842794618475e-05,
      "loss": 1.7557,
      "step": 4545
    },
    {
      "epoch": 1.07425,
      "grad_norm": 3.7911956310272217,
      "learning_rate": 4.581540272019476e-05,
      "loss": 1.8448,
      "step": 4550
    },
    {
      "epoch": 1.0745,
      "grad_norm": 6.3350043296813965,
      "learning_rate": 4.5803948418639565e-05,
      "loss": 1.9475,
      "step": 4555
    },
    {
      "epoch": 1.07475,
      "grad_norm": 3.420473098754883,
      "learning_rate": 4.579247989778179e-05,
      "loss": 1.6737,
      "step": 4560
    },
    {
      "epoch": 1.075,
      "grad_norm": 3.7764840126037598,
      "learning_rate": 4.578099716546007e-05,
      "loss": 1.6244,
      "step": 4565
    },
    {
      "epoch": 1.07525,
      "grad_norm": 4.995187759399414,
      "learning_rate": 4.576950022952274e-05,
      "loss": 1.9467,
      "step": 4570
    },
    {
      "epoch": 1.0755,
      "grad_norm": 4.3331804275512695,
      "learning_rate": 4.5757989097827855e-05,
      "loss": 1.9418,
      "step": 4575
    },
    {
      "epoch": 1.07575,
      "grad_norm": 5.2367472648620605,
      "learning_rate": 4.574646377824315e-05,
      "loss": 1.8662,
      "step": 4580
    },
    {
      "epoch": 1.076,
      "grad_norm": 5.261753082275391,
      "learning_rate": 4.5734924278646085e-05,
      "loss": 1.973,
      "step": 4585
    },
    {
      "epoch": 1.07625,
      "grad_norm": 4.1889872550964355,
      "learning_rate": 4.572337060692379e-05,
      "loss": 1.7874,
      "step": 4590
    },
    {
      "epoch": 1.0765,
      "grad_norm": 3.8993968963623047,
      "learning_rate": 4.571180277097309e-05,
      "loss": 1.7327,
      "step": 4595
    },
    {
      "epoch": 1.07675,
      "grad_norm": 4.81164026260376,
      "learning_rate": 4.5700220778700504e-05,
      "loss": 1.7529,
      "step": 4600
    },
    {
      "epoch": 1.077,
      "grad_norm": 4.86481237411499,
      "learning_rate": 4.56886246380222e-05,
      "loss": 1.6312,
      "step": 4605
    },
    {
      "epoch": 1.07725,
      "grad_norm": 4.303720474243164,
      "learning_rate": 4.567701435686404e-05,
      "loss": 1.7846,
      "step": 4610
    },
    {
      "epoch": 1.0775,
      "grad_norm": 4.939575672149658,
      "learning_rate": 4.566538994316155e-05,
      "loss": 1.825,
      "step": 4615
    },
    {
      "epoch": 1.07775,
      "grad_norm": 4.722678184509277,
      "learning_rate": 4.565375140485989e-05,
      "loss": 1.664,
      "step": 4620
    },
    {
      "epoch": 1.078,
      "grad_norm": 4.484785079956055,
      "learning_rate": 4.56420987499139e-05,
      "loss": 1.7624,
      "step": 4625
    },
    {
      "epoch": 1.07825,
      "grad_norm": 3.958397388458252,
      "learning_rate": 4.563043198628806e-05,
      "loss": 1.6614,
      "step": 4630
    },
    {
      "epoch": 1.0785,
      "grad_norm": 5.564257621765137,
      "learning_rate": 4.5618751121956485e-05,
      "loss": 1.7276,
      "step": 4635
    },
    {
      "epoch": 1.07875,
      "grad_norm": 4.482970714569092,
      "learning_rate": 4.560705616490294e-05,
      "loss": 1.7009,
      "step": 4640
    },
    {
      "epoch": 1.079,
      "grad_norm": 7.170011520385742,
      "learning_rate": 4.5595347123120815e-05,
      "loss": 1.7701,
      "step": 4645
    },
    {
      "epoch": 1.07925,
      "grad_norm": 5.12109375,
      "learning_rate": 4.5583624004613145e-05,
      "loss": 1.8238,
      "step": 4650
    },
    {
      "epoch": 1.0795,
      "grad_norm": 4.515164375305176,
      "learning_rate": 4.557188681739256e-05,
      "loss": 1.7149,
      "step": 4655
    },
    {
      "epoch": 1.07975,
      "grad_norm": 6.813350677490234,
      "learning_rate": 4.556013556948131e-05,
      "loss": 1.8148,
      "step": 4660
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.7402873039245605,
      "learning_rate": 4.554837026891127e-05,
      "loss": 1.7092,
      "step": 4665
    },
    {
      "epoch": 1.08025,
      "grad_norm": 4.090934753417969,
      "learning_rate": 4.5536590923723906e-05,
      "loss": 1.8635,
      "step": 4670
    },
    {
      "epoch": 1.0805,
      "grad_norm": 4.9443159103393555,
      "learning_rate": 4.5524797541970304e-05,
      "loss": 1.6969,
      "step": 4675
    },
    {
      "epoch": 1.08075,
      "grad_norm": 7.176087856292725,
      "learning_rate": 4.551299013171111e-05,
      "loss": 1.8262,
      "step": 4680
    },
    {
      "epoch": 1.081,
      "grad_norm": 4.289700984954834,
      "learning_rate": 4.550116870101659e-05,
      "loss": 1.7987,
      "step": 4685
    },
    {
      "epoch": 1.08125,
      "grad_norm": 5.562264919281006,
      "learning_rate": 4.548933325796658e-05,
      "loss": 1.8567,
      "step": 4690
    },
    {
      "epoch": 1.0815,
      "grad_norm": 4.3473358154296875,
      "learning_rate": 4.54774838106505e-05,
      "loss": 1.7832,
      "step": 4695
    },
    {
      "epoch": 1.08175,
      "grad_norm": 3.895545244216919,
      "learning_rate": 4.546562036716732e-05,
      "loss": 1.7469,
      "step": 4700
    },
    {
      "epoch": 1.082,
      "grad_norm": 4.0520830154418945,
      "learning_rate": 4.545374293562559e-05,
      "loss": 1.8267,
      "step": 4705
    },
    {
      "epoch": 1.08225,
      "grad_norm": 4.728288650512695,
      "learning_rate": 4.544185152414343e-05,
      "loss": 1.7312,
      "step": 4710
    },
    {
      "epoch": 1.0825,
      "grad_norm": 4.557685375213623,
      "learning_rate": 4.542994614084852e-05,
      "loss": 1.8178,
      "step": 4715
    },
    {
      "epoch": 1.08275,
      "grad_norm": 4.078312873840332,
      "learning_rate": 4.541802679387806e-05,
      "loss": 1.7584,
      "step": 4720
    },
    {
      "epoch": 1.083,
      "grad_norm": 4.589261531829834,
      "learning_rate": 4.5406093491378815e-05,
      "loss": 1.7225,
      "step": 4725
    },
    {
      "epoch": 1.08325,
      "grad_norm": 5.559367656707764,
      "learning_rate": 4.539414624150708e-05,
      "loss": 1.7262,
      "step": 4730
    },
    {
      "epoch": 1.0835,
      "grad_norm": 6.282257080078125,
      "learning_rate": 4.538218505242871e-05,
      "loss": 1.935,
      "step": 4735
    },
    {
      "epoch": 1.08375,
      "grad_norm": 4.01105260848999,
      "learning_rate": 4.537020993231904e-05,
      "loss": 1.6433,
      "step": 4740
    },
    {
      "epoch": 1.084,
      "grad_norm": 6.2142252922058105,
      "learning_rate": 4.535822088936297e-05,
      "loss": 1.6087,
      "step": 4745
    },
    {
      "epoch": 1.08425,
      "grad_norm": 3.5632247924804688,
      "learning_rate": 4.534621793175487e-05,
      "loss": 1.5224,
      "step": 4750
    },
    {
      "epoch": 1.0845,
      "grad_norm": 6.473487854003906,
      "learning_rate": 4.533420106769868e-05,
      "loss": 1.8481,
      "step": 4755
    },
    {
      "epoch": 1.08475,
      "grad_norm": 3.967258930206299,
      "learning_rate": 4.532217030540781e-05,
      "loss": 1.6007,
      "step": 4760
    },
    {
      "epoch": 1.085,
      "grad_norm": 4.975893020629883,
      "learning_rate": 4.531012565310515e-05,
      "loss": 1.5934,
      "step": 4765
    },
    {
      "epoch": 1.08525,
      "grad_norm": 4.587454795837402,
      "learning_rate": 4.5298067119023114e-05,
      "loss": 1.6405,
      "step": 4770
    },
    {
      "epoch": 1.0855,
      "grad_norm": 4.342927932739258,
      "learning_rate": 4.528599471140361e-05,
      "loss": 1.5649,
      "step": 4775
    },
    {
      "epoch": 1.08575,
      "grad_norm": 4.890066146850586,
      "learning_rate": 4.5273908438498e-05,
      "loss": 1.6533,
      "step": 4780
    },
    {
      "epoch": 1.086,
      "grad_norm": 4.641666889190674,
      "learning_rate": 4.526180830856715e-05,
      "loss": 1.8197,
      "step": 4785
    },
    {
      "epoch": 1.08625,
      "grad_norm": 5.60153341293335,
      "learning_rate": 4.524969432988138e-05,
      "loss": 1.5349,
      "step": 4790
    },
    {
      "epoch": 1.0865,
      "grad_norm": 4.17885160446167,
      "learning_rate": 4.5237566510720476e-05,
      "loss": 1.5582,
      "step": 4795
    },
    {
      "epoch": 1.0867499999999999,
      "grad_norm": 4.317424297332764,
      "learning_rate": 4.522542485937369e-05,
      "loss": 1.5884,
      "step": 4800
    },
    {
      "epoch": 1.087,
      "grad_norm": 6.290103912353516,
      "learning_rate": 4.521326938413972e-05,
      "loss": 1.819,
      "step": 4805
    },
    {
      "epoch": 1.08725,
      "grad_norm": 4.844536781311035,
      "learning_rate": 4.520110009332674e-05,
      "loss": 1.6666,
      "step": 4810
    },
    {
      "epoch": 1.0875,
      "grad_norm": 5.56820821762085,
      "learning_rate": 4.518891699525232e-05,
      "loss": 1.7684,
      "step": 4815
    },
    {
      "epoch": 1.08775,
      "grad_norm": 5.632633686065674,
      "learning_rate": 4.517672009824351e-05,
      "loss": 1.6383,
      "step": 4820
    },
    {
      "epoch": 1.088,
      "grad_norm": 4.85063362121582,
      "learning_rate": 4.516450941063677e-05,
      "loss": 1.6225,
      "step": 4825
    },
    {
      "epoch": 1.08825,
      "grad_norm": 4.706823825836182,
      "learning_rate": 4.515228494077798e-05,
      "loss": 1.6599,
      "step": 4830
    },
    {
      "epoch": 1.0885,
      "grad_norm": 4.905807971954346,
      "learning_rate": 4.514004669702246e-05,
      "loss": 1.5165,
      "step": 4835
    },
    {
      "epoch": 1.08875,
      "grad_norm": 4.544114112854004,
      "learning_rate": 4.512779468773494e-05,
      "loss": 1.7425,
      "step": 4840
    },
    {
      "epoch": 1.089,
      "grad_norm": 4.470858573913574,
      "learning_rate": 4.511552892128953e-05,
      "loss": 1.6994,
      "step": 4845
    },
    {
      "epoch": 1.08925,
      "grad_norm": 4.634580612182617,
      "learning_rate": 4.510324940606979e-05,
      "loss": 1.6956,
      "step": 4850
    },
    {
      "epoch": 1.0895,
      "grad_norm": 6.148083686828613,
      "learning_rate": 4.5090956150468646e-05,
      "loss": 1.6976,
      "step": 4855
    },
    {
      "epoch": 1.08975,
      "grad_norm": 5.191268444061279,
      "learning_rate": 4.5078649162888406e-05,
      "loss": 1.5316,
      "step": 4860
    },
    {
      "epoch": 1.09,
      "grad_norm": 5.113893032073975,
      "learning_rate": 4.50663284517408e-05,
      "loss": 1.7056,
      "step": 4865
    },
    {
      "epoch": 1.09025,
      "grad_norm": 4.478729724884033,
      "learning_rate": 4.505399402544692e-05,
      "loss": 1.729,
      "step": 4870
    },
    {
      "epoch": 1.0905,
      "grad_norm": 4.820679187774658,
      "learning_rate": 4.504164589243721e-05,
      "loss": 1.5378,
      "step": 4875
    },
    {
      "epoch": 1.0907499999999999,
      "grad_norm": 5.407397747039795,
      "learning_rate": 4.502928406115152e-05,
      "loss": 1.4031,
      "step": 4880
    },
    {
      "epoch": 1.091,
      "grad_norm": 4.151090621948242,
      "learning_rate": 4.501690854003904e-05,
      "loss": 1.6403,
      "step": 4885
    },
    {
      "epoch": 1.09125,
      "grad_norm": 4.4840850830078125,
      "learning_rate": 4.500451933755833e-05,
      "loss": 1.624,
      "step": 4890
    },
    {
      "epoch": 1.0915,
      "grad_norm": 5.502420425415039,
      "learning_rate": 4.499211646217727e-05,
      "loss": 1.8548,
      "step": 4895
    },
    {
      "epoch": 1.09175,
      "grad_norm": 4.2910027503967285,
      "learning_rate": 4.497969992237312e-05,
      "loss": 1.862,
      "step": 4900
    },
    {
      "epoch": 1.092,
      "grad_norm": 4.638328552246094,
      "learning_rate": 4.496726972663248e-05,
      "loss": 1.6009,
      "step": 4905
    },
    {
      "epoch": 1.09225,
      "grad_norm": 4.1626458168029785,
      "learning_rate": 4.495482588345126e-05,
      "loss": 1.7984,
      "step": 4910
    },
    {
      "epoch": 1.0925,
      "grad_norm": 4.647152900695801,
      "learning_rate": 4.4942368401334704e-05,
      "loss": 1.5949,
      "step": 4915
    },
    {
      "epoch": 1.09275,
      "grad_norm": 4.050891399383545,
      "learning_rate": 4.49298972887974e-05,
      "loss": 1.762,
      "step": 4920
    },
    {
      "epoch": 1.093,
      "grad_norm": 5.771118640899658,
      "learning_rate": 4.491741255436323e-05,
      "loss": 1.6617,
      "step": 4925
    },
    {
      "epoch": 1.09325,
      "grad_norm": 4.32593297958374,
      "learning_rate": 4.490491420656537e-05,
      "loss": 1.8042,
      "step": 4930
    },
    {
      "epoch": 1.0935,
      "grad_norm": 5.762380599975586,
      "learning_rate": 4.4892402253946355e-05,
      "loss": 1.8735,
      "step": 4935
    },
    {
      "epoch": 1.09375,
      "grad_norm": 4.6608076095581055,
      "learning_rate": 4.487987670505798e-05,
      "loss": 1.899,
      "step": 4940
    },
    {
      "epoch": 1.094,
      "grad_norm": 4.024754047393799,
      "learning_rate": 4.4867337568461325e-05,
      "loss": 1.6406,
      "step": 4945
    },
    {
      "epoch": 1.09425,
      "grad_norm": 5.824357032775879,
      "learning_rate": 4.4854784852726776e-05,
      "loss": 1.6815,
      "step": 4950
    },
    {
      "epoch": 1.0945,
      "grad_norm": 3.600270986557007,
      "learning_rate": 4.484221856643401e-05,
      "loss": 1.5356,
      "step": 4955
    },
    {
      "epoch": 1.09475,
      "grad_norm": 4.774430751800537,
      "learning_rate": 4.4829638718171954e-05,
      "loss": 1.8061,
      "step": 4960
    },
    {
      "epoch": 1.095,
      "grad_norm": 5.551276683807373,
      "learning_rate": 4.4817045316538805e-05,
      "loss": 1.7983,
      "step": 4965
    },
    {
      "epoch": 1.09525,
      "grad_norm": 5.32202672958374,
      "learning_rate": 4.480443837014205e-05,
      "loss": 1.7155,
      "step": 4970
    },
    {
      "epoch": 1.0955,
      "grad_norm": 4.6221923828125,
      "learning_rate": 4.479181788759842e-05,
      "loss": 1.7946,
      "step": 4975
    },
    {
      "epoch": 1.09575,
      "grad_norm": 5.581623077392578,
      "learning_rate": 4.477918387753388e-05,
      "loss": 1.7695,
      "step": 4980
    },
    {
      "epoch": 1.096,
      "grad_norm": 5.2537407875061035,
      "learning_rate": 4.4766536348583674e-05,
      "loss": 1.7605,
      "step": 4985
    },
    {
      "epoch": 1.09625,
      "grad_norm": 4.518068790435791,
      "learning_rate": 4.4753875309392266e-05,
      "loss": 1.705,
      "step": 4990
    },
    {
      "epoch": 1.0965,
      "grad_norm": 4.18558931350708,
      "learning_rate": 4.474120076861335e-05,
      "loss": 1.6337,
      "step": 4995
    },
    {
      "epoch": 1.0967500000000001,
      "grad_norm": 3.9074513912200928,
      "learning_rate": 4.4728512734909844e-05,
      "loss": 1.6838,
      "step": 5000
    },
    {
      "epoch": 1.0967500000000001,
      "eval_loss": 2.089332103729248,
      "eval_runtime": 5.7094,
      "eval_samples_per_second": 179.352,
      "eval_steps_per_second": 22.419,
      "step": 5000
    },
    {
      "epoch": 1.097,
      "grad_norm": 5.1393961906433105,
      "learning_rate": 4.4715811216953916e-05,
      "loss": 1.6546,
      "step": 5005
    },
    {
      "epoch": 1.09725,
      "grad_norm": 4.326952934265137,
      "learning_rate": 4.470309622342694e-05,
      "loss": 1.5882,
      "step": 5010
    },
    {
      "epoch": 1.0975,
      "grad_norm": 11.644607543945312,
      "learning_rate": 4.469036776301948e-05,
      "loss": 1.7626,
      "step": 5015
    },
    {
      "epoch": 1.09775,
      "grad_norm": 6.978612422943115,
      "learning_rate": 4.467762584443131e-05,
      "loss": 1.6827,
      "step": 5020
    },
    {
      "epoch": 1.098,
      "grad_norm": 4.57668399810791,
      "learning_rate": 4.466487047637144e-05,
      "loss": 1.7392,
      "step": 5025
    },
    {
      "epoch": 1.09825,
      "grad_norm": 4.181727409362793,
      "learning_rate": 4.465210166755803e-05,
      "loss": 1.5707,
      "step": 5030
    },
    {
      "epoch": 1.0985,
      "grad_norm": 4.381214618682861,
      "learning_rate": 4.463931942671843e-05,
      "loss": 1.6796,
      "step": 5035
    },
    {
      "epoch": 1.09875,
      "grad_norm": 3.996148109436035,
      "learning_rate": 4.46265237625892e-05,
      "loss": 1.7108,
      "step": 5040
    },
    {
      "epoch": 1.099,
      "grad_norm": 4.018472194671631,
      "learning_rate": 4.461371468391603e-05,
      "loss": 1.5673,
      "step": 5045
    },
    {
      "epoch": 1.09925,
      "grad_norm": 8.418874740600586,
      "learning_rate": 4.460089219945382e-05,
      "loss": 1.8352,
      "step": 5050
    },
    {
      "epoch": 1.0995,
      "grad_norm": 3.1514837741851807,
      "learning_rate": 4.458805631796663e-05,
      "loss": 1.6455,
      "step": 5055
    },
    {
      "epoch": 1.09975,
      "grad_norm": 4.169247150421143,
      "learning_rate": 4.457520704822765e-05,
      "loss": 1.5681,
      "step": 5060
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.9807891845703125,
      "learning_rate": 4.456234439901923e-05,
      "loss": 1.8067,
      "step": 5065
    },
    {
      "epoch": 1.10025,
      "grad_norm": 5.982016086578369,
      "learning_rate": 4.454946837913287e-05,
      "loss": 1.8345,
      "step": 5070
    },
    {
      "epoch": 1.1005,
      "grad_norm": 4.768522262573242,
      "learning_rate": 4.453657899736923e-05,
      "loss": 1.6892,
      "step": 5075
    },
    {
      "epoch": 1.1007500000000001,
      "grad_norm": 4.921236038208008,
      "learning_rate": 4.452367626253805e-05,
      "loss": 1.706,
      "step": 5080
    },
    {
      "epoch": 1.101,
      "grad_norm": 6.3879852294921875,
      "learning_rate": 4.451076018345825e-05,
      "loss": 1.8125,
      "step": 5085
    },
    {
      "epoch": 1.10125,
      "grad_norm": 7.983030319213867,
      "learning_rate": 4.449783076895783e-05,
      "loss": 1.8338,
      "step": 5090
    },
    {
      "epoch": 1.1015,
      "grad_norm": 3.566145181655884,
      "learning_rate": 4.448488802787394e-05,
      "loss": 1.5629,
      "step": 5095
    },
    {
      "epoch": 1.10175,
      "grad_norm": 4.061057090759277,
      "learning_rate": 4.4471931969052816e-05,
      "loss": 1.6671,
      "step": 5100
    },
    {
      "epoch": 1.102,
      "grad_norm": 5.246930122375488,
      "learning_rate": 4.44589626013498e-05,
      "loss": 1.6225,
      "step": 5105
    },
    {
      "epoch": 1.10225,
      "grad_norm": 4.404847621917725,
      "learning_rate": 4.4445979933629324e-05,
      "loss": 1.6577,
      "step": 5110
    },
    {
      "epoch": 1.1025,
      "grad_norm": 3.7464911937713623,
      "learning_rate": 4.443298397476493e-05,
      "loss": 1.6141,
      "step": 5115
    },
    {
      "epoch": 1.10275,
      "grad_norm": 5.662867546081543,
      "learning_rate": 4.4419974733639244e-05,
      "loss": 1.6004,
      "step": 5120
    },
    {
      "epoch": 1.103,
      "grad_norm": 5.079017639160156,
      "learning_rate": 4.4406952219143936e-05,
      "loss": 1.767,
      "step": 5125
    },
    {
      "epoch": 1.10325,
      "grad_norm": 4.531289577484131,
      "learning_rate": 4.4393916440179786e-05,
      "loss": 1.4288,
      "step": 5130
    },
    {
      "epoch": 1.1035,
      "grad_norm": 6.572784900665283,
      "learning_rate": 4.4380867405656625e-05,
      "loss": 1.7087,
      "step": 5135
    },
    {
      "epoch": 1.10375,
      "grad_norm": 3.220719814300537,
      "learning_rate": 4.436780512449334e-05,
      "loss": 1.395,
      "step": 5140
    },
    {
      "epoch": 1.104,
      "grad_norm": 3.9350266456604004,
      "learning_rate": 4.435472960561788e-05,
      "loss": 1.8148,
      "step": 5145
    },
    {
      "epoch": 1.10425,
      "grad_norm": 5.901651382446289,
      "learning_rate": 4.434164085796724e-05,
      "loss": 1.7702,
      "step": 5150
    },
    {
      "epoch": 1.1045,
      "grad_norm": 4.13418436050415,
      "learning_rate": 4.432853889048745e-05,
      "loss": 1.6864,
      "step": 5155
    },
    {
      "epoch": 1.10475,
      "grad_norm": 4.750941753387451,
      "learning_rate": 4.4315423712133595e-05,
      "loss": 1.5332,
      "step": 5160
    },
    {
      "epoch": 1.105,
      "grad_norm": 4.405928611755371,
      "learning_rate": 4.4302295331869756e-05,
      "loss": 1.6928,
      "step": 5165
    },
    {
      "epoch": 1.10525,
      "grad_norm": 6.025449275970459,
      "learning_rate": 4.4289153758669075e-05,
      "loss": 1.7456,
      "step": 5170
    },
    {
      "epoch": 1.1055,
      "grad_norm": 5.145834445953369,
      "learning_rate": 4.427599900151368e-05,
      "loss": 1.594,
      "step": 5175
    },
    {
      "epoch": 1.10575,
      "grad_norm": 7.003096103668213,
      "learning_rate": 4.426283106939474e-05,
      "loss": 1.6819,
      "step": 5180
    },
    {
      "epoch": 1.106,
      "grad_norm": 4.730546951293945,
      "learning_rate": 4.424964997131239e-05,
      "loss": 1.5277,
      "step": 5185
    },
    {
      "epoch": 1.10625,
      "grad_norm": 4.02064847946167,
      "learning_rate": 4.42364557162758e-05,
      "loss": 1.6553,
      "step": 5190
    },
    {
      "epoch": 1.1065,
      "grad_norm": 7.331239700317383,
      "learning_rate": 4.422324831330312e-05,
      "loss": 1.7107,
      "step": 5195
    },
    {
      "epoch": 1.10675,
      "grad_norm": 4.583857536315918,
      "learning_rate": 4.421002777142148e-05,
      "loss": 1.6874,
      "step": 5200
    },
    {
      "epoch": 1.107,
      "grad_norm": 4.895782947540283,
      "learning_rate": 4.419679409966699e-05,
      "loss": 1.6878,
      "step": 5205
    },
    {
      "epoch": 1.10725,
      "grad_norm": 5.435199737548828,
      "learning_rate": 4.418354730708476e-05,
      "loss": 1.4575,
      "step": 5210
    },
    {
      "epoch": 1.1075,
      "grad_norm": 4.3898820877075195,
      "learning_rate": 4.417028740272884e-05,
      "loss": 1.6703,
      "step": 5215
    },
    {
      "epoch": 1.10775,
      "grad_norm": 4.9581685066223145,
      "learning_rate": 4.415701439566223e-05,
      "loss": 1.5049,
      "step": 5220
    },
    {
      "epoch": 1.108,
      "grad_norm": 4.536626815795898,
      "learning_rate": 4.414372829495693e-05,
      "loss": 1.6546,
      "step": 5225
    },
    {
      "epoch": 1.10825,
      "grad_norm": 4.756387710571289,
      "learning_rate": 4.413042910969385e-05,
      "loss": 1.6636,
      "step": 5230
    },
    {
      "epoch": 1.1085,
      "grad_norm": 4.2425150871276855,
      "learning_rate": 4.411711684896287e-05,
      "loss": 1.4957,
      "step": 5235
    },
    {
      "epoch": 1.10875,
      "grad_norm": 4.623615264892578,
      "learning_rate": 4.4103791521862784e-05,
      "loss": 1.5563,
      "step": 5240
    },
    {
      "epoch": 1.109,
      "grad_norm": 3.8660356998443604,
      "learning_rate": 4.409045313750133e-05,
      "loss": 1.6823,
      "step": 5245
    },
    {
      "epoch": 1.10925,
      "grad_norm": 3.872749090194702,
      "learning_rate": 4.4077101704995166e-05,
      "loss": 1.5401,
      "step": 5250
    },
    {
      "epoch": 1.1095,
      "grad_norm": 4.727972030639648,
      "learning_rate": 4.406373723346987e-05,
      "loss": 1.4433,
      "step": 5255
    },
    {
      "epoch": 1.10975,
      "grad_norm": 3.3959484100341797,
      "learning_rate": 4.405035973205994e-05,
      "loss": 1.3969,
      "step": 5260
    },
    {
      "epoch": 1.11,
      "grad_norm": 4.992183685302734,
      "learning_rate": 4.403696920990877e-05,
      "loss": 1.6513,
      "step": 5265
    },
    {
      "epoch": 1.11025,
      "grad_norm": 7.923825740814209,
      "learning_rate": 4.4023565676168655e-05,
      "loss": 1.5179,
      "step": 5270
    },
    {
      "epoch": 1.1105,
      "grad_norm": 4.924827575683594,
      "learning_rate": 4.401014914000078e-05,
      "loss": 1.5611,
      "step": 5275
    },
    {
      "epoch": 1.11075,
      "grad_norm": 5.604221820831299,
      "learning_rate": 4.399671961057522e-05,
      "loss": 1.8454,
      "step": 5280
    },
    {
      "epoch": 1.111,
      "grad_norm": 4.965970039367676,
      "learning_rate": 4.398327709707093e-05,
      "loss": 1.6363,
      "step": 5285
    },
    {
      "epoch": 1.11125,
      "grad_norm": 5.133738994598389,
      "learning_rate": 4.396982160867575e-05,
      "loss": 1.8757,
      "step": 5290
    },
    {
      "epoch": 1.1115,
      "grad_norm": 5.766330242156982,
      "learning_rate": 4.3956353154586375e-05,
      "loss": 1.685,
      "step": 5295
    },
    {
      "epoch": 1.11175,
      "grad_norm": 5.458956718444824,
      "learning_rate": 4.3942871744008374e-05,
      "loss": 1.5945,
      "step": 5300
    },
    {
      "epoch": 1.112,
      "grad_norm": 4.335137367248535,
      "learning_rate": 4.3929377386156144e-05,
      "loss": 1.7117,
      "step": 5305
    },
    {
      "epoch": 1.11225,
      "grad_norm": 4.111393451690674,
      "learning_rate": 4.391587009025297e-05,
      "loss": 1.6206,
      "step": 5310
    },
    {
      "epoch": 1.1125,
      "grad_norm": 3.7985732555389404,
      "learning_rate": 4.3902349865530956e-05,
      "loss": 1.9113,
      "step": 5315
    },
    {
      "epoch": 1.11275,
      "grad_norm": 4.143160343170166,
      "learning_rate": 4.388881672123105e-05,
      "loss": 1.6056,
      "step": 5320
    },
    {
      "epoch": 1.113,
      "grad_norm": 4.620772838592529,
      "learning_rate": 4.387527066660302e-05,
      "loss": 1.6086,
      "step": 5325
    },
    {
      "epoch": 1.11325,
      "grad_norm": 4.116180896759033,
      "learning_rate": 4.386171171090547e-05,
      "loss": 1.6149,
      "step": 5330
    },
    {
      "epoch": 1.1135,
      "grad_norm": 3.681840419769287,
      "learning_rate": 4.384813986340583e-05,
      "loss": 1.5757,
      "step": 5335
    },
    {
      "epoch": 1.11375,
      "grad_norm": 4.8013176918029785,
      "learning_rate": 4.383455513338032e-05,
      "loss": 1.6356,
      "step": 5340
    },
    {
      "epoch": 1.114,
      "grad_norm": 3.857274293899536,
      "learning_rate": 4.382095753011397e-05,
      "loss": 1.5239,
      "step": 5345
    },
    {
      "epoch": 1.11425,
      "grad_norm": 6.697841644287109,
      "learning_rate": 4.3807347062900624e-05,
      "loss": 1.6275,
      "step": 5350
    },
    {
      "epoch": 1.1145,
      "grad_norm": 3.9187519550323486,
      "learning_rate": 4.37937237410429e-05,
      "loss": 1.8264,
      "step": 5355
    },
    {
      "epoch": 1.11475,
      "grad_norm": 5.07972526550293,
      "learning_rate": 4.3780087573852213e-05,
      "loss": 1.6298,
      "step": 5360
    },
    {
      "epoch": 1.115,
      "grad_norm": 6.0884809494018555,
      "learning_rate": 4.376643857064875e-05,
      "loss": 1.7802,
      "step": 5365
    },
    {
      "epoch": 1.11525,
      "grad_norm": 6.772281646728516,
      "learning_rate": 4.375277674076149e-05,
      "loss": 1.8119,
      "step": 5370
    },
    {
      "epoch": 1.1155,
      "grad_norm": 4.64607048034668,
      "learning_rate": 4.373910209352815e-05,
      "loss": 1.4738,
      "step": 5375
    },
    {
      "epoch": 1.11575,
      "grad_norm": 5.114633560180664,
      "learning_rate": 4.3725414638295235e-05,
      "loss": 1.6645,
      "step": 5380
    },
    {
      "epoch": 1.116,
      "grad_norm": 4.005032062530518,
      "learning_rate": 4.371171438441798e-05,
      "loss": 1.8121,
      "step": 5385
    },
    {
      "epoch": 1.11625,
      "grad_norm": 4.213237285614014,
      "learning_rate": 4.369800134126039e-05,
      "loss": 1.6645,
      "step": 5390
    },
    {
      "epoch": 1.1165,
      "grad_norm": 5.199549674987793,
      "learning_rate": 4.368427551819518e-05,
      "loss": 1.7375,
      "step": 5395
    },
    {
      "epoch": 1.11675,
      "grad_norm": 3.9887306690216064,
      "learning_rate": 4.367053692460385e-05,
      "loss": 1.6617,
      "step": 5400
    },
    {
      "epoch": 1.117,
      "grad_norm": 4.347550868988037,
      "learning_rate": 4.365678556987658e-05,
      "loss": 1.6851,
      "step": 5405
    },
    {
      "epoch": 1.11725,
      "grad_norm": 3.861804962158203,
      "learning_rate": 4.3643021463412294e-05,
      "loss": 1.7272,
      "step": 5410
    },
    {
      "epoch": 1.1175,
      "grad_norm": 3.879411458969116,
      "learning_rate": 4.362924461461864e-05,
      "loss": 1.6325,
      "step": 5415
    },
    {
      "epoch": 1.11775,
      "grad_norm": 3.9502875804901123,
      "learning_rate": 4.3615455032911946e-05,
      "loss": 1.5517,
      "step": 5420
    },
    {
      "epoch": 1.1179999999999999,
      "grad_norm": 6.50692081451416,
      "learning_rate": 4.3601652727717266e-05,
      "loss": 1.6126,
      "step": 5425
    },
    {
      "epoch": 1.11825,
      "grad_norm": 5.415174961090088,
      "learning_rate": 4.358783770846836e-05,
      "loss": 1.6853,
      "step": 5430
    },
    {
      "epoch": 1.1185,
      "grad_norm": 3.9663219451904297,
      "learning_rate": 4.357400998460764e-05,
      "loss": 1.4814,
      "step": 5435
    },
    {
      "epoch": 1.11875,
      "grad_norm": 4.311382293701172,
      "learning_rate": 4.356016956558625e-05,
      "loss": 1.6653,
      "step": 5440
    },
    {
      "epoch": 1.119,
      "grad_norm": 5.427711009979248,
      "learning_rate": 4.354631646086397e-05,
      "loss": 1.6203,
      "step": 5445
    },
    {
      "epoch": 1.11925,
      "grad_norm": 3.6861860752105713,
      "learning_rate": 4.3532450679909274e-05,
      "loss": 1.5644,
      "step": 5450
    },
    {
      "epoch": 1.1195,
      "grad_norm": 6.576873302459717,
      "learning_rate": 4.351857223219929e-05,
      "loss": 1.6275,
      "step": 5455
    },
    {
      "epoch": 1.11975,
      "grad_norm": 4.197847366333008,
      "learning_rate": 4.3504681127219793e-05,
      "loss": 1.6141,
      "step": 5460
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.476407051086426,
      "learning_rate": 4.349077737446525e-05,
      "loss": 1.6335,
      "step": 5465
    },
    {
      "epoch": 1.12025,
      "grad_norm": 4.631299018859863,
      "learning_rate": 4.3476860983438714e-05,
      "loss": 1.4774,
      "step": 5470
    },
    {
      "epoch": 1.1205,
      "grad_norm": 7.242486476898193,
      "learning_rate": 4.3462931963651934e-05,
      "loss": 1.6562,
      "step": 5475
    },
    {
      "epoch": 1.12075,
      "grad_norm": 7.709704399108887,
      "learning_rate": 4.3448990324625244e-05,
      "loss": 1.7318,
      "step": 5480
    },
    {
      "epoch": 1.121,
      "grad_norm": 4.196247577667236,
      "learning_rate": 4.343503607588764e-05,
      "loss": 1.6077,
      "step": 5485
    },
    {
      "epoch": 1.12125,
      "grad_norm": 4.410576820373535,
      "learning_rate": 4.342106922697669e-05,
      "loss": 1.5084,
      "step": 5490
    },
    {
      "epoch": 1.1215,
      "grad_norm": 4.302145957946777,
      "learning_rate": 4.3407089787438646e-05,
      "loss": 1.698,
      "step": 5495
    },
    {
      "epoch": 1.12175,
      "grad_norm": 5.0219645500183105,
      "learning_rate": 4.3393097766828293e-05,
      "loss": 1.5554,
      "step": 5500
    },
    {
      "epoch": 1.12175,
      "eval_loss": 2.0568156242370605,
      "eval_runtime": 5.1801,
      "eval_samples_per_second": 197.678,
      "eval_steps_per_second": 24.71,
      "step": 5500
    },
    {
      "epoch": 1.1219999999999999,
      "grad_norm": 4.402721405029297,
      "learning_rate": 4.337909317470905e-05,
      "loss": 1.6874,
      "step": 5505
    },
    {
      "epoch": 1.12225,
      "grad_norm": 4.528267860412598,
      "learning_rate": 4.336507602065293e-05,
      "loss": 1.6559,
      "step": 5510
    },
    {
      "epoch": 1.1225,
      "grad_norm": 4.539250373840332,
      "learning_rate": 4.335104631424052e-05,
      "loss": 1.7264,
      "step": 5515
    },
    {
      "epoch": 1.12275,
      "grad_norm": 5.114004611968994,
      "learning_rate": 4.3337004065061e-05,
      "loss": 1.696,
      "step": 5520
    },
    {
      "epoch": 1.123,
      "grad_norm": 5.194033622741699,
      "learning_rate": 4.33229492827121e-05,
      "loss": 1.6224,
      "step": 5525
    },
    {
      "epoch": 1.12325,
      "grad_norm": 5.202253341674805,
      "learning_rate": 4.3308881976800146e-05,
      "loss": 1.5153,
      "step": 5530
    },
    {
      "epoch": 1.1235,
      "grad_norm": 4.238250255584717,
      "learning_rate": 4.329480215694001e-05,
      "loss": 1.6245,
      "step": 5535
    },
    {
      "epoch": 1.12375,
      "grad_norm": 4.854507923126221,
      "learning_rate": 4.3280709832755094e-05,
      "loss": 1.5783,
      "step": 5540
    },
    {
      "epoch": 1.124,
      "grad_norm": 4.457976341247559,
      "learning_rate": 4.326660501387739e-05,
      "loss": 1.5759,
      "step": 5545
    },
    {
      "epoch": 1.12425,
      "grad_norm": 5.051071643829346,
      "learning_rate": 4.325248770994741e-05,
      "loss": 1.6052,
      "step": 5550
    },
    {
      "epoch": 1.1245,
      "grad_norm": 4.652479648590088,
      "learning_rate": 4.323835793061418e-05,
      "loss": 1.6513,
      "step": 5555
    },
    {
      "epoch": 1.12475,
      "grad_norm": 4.624975681304932,
      "learning_rate": 4.3224215685535294e-05,
      "loss": 1.5337,
      "step": 5560
    },
    {
      "epoch": 1.125,
      "grad_norm": 6.176459312438965,
      "learning_rate": 4.3210060984376824e-05,
      "loss": 1.7985,
      "step": 5565
    },
    {
      "epoch": 1.12525,
      "grad_norm": 3.9201557636260986,
      "learning_rate": 4.319589383681338e-05,
      "loss": 1.6053,
      "step": 5570
    },
    {
      "epoch": 1.1255,
      "grad_norm": 5.048671722412109,
      "learning_rate": 4.318171425252808e-05,
      "loss": 1.7249,
      "step": 5575
    },
    {
      "epoch": 1.12575,
      "grad_norm": 4.81618070602417,
      "learning_rate": 4.316752224121252e-05,
      "loss": 1.4521,
      "step": 5580
    },
    {
      "epoch": 1.126,
      "grad_norm": 4.88008451461792,
      "learning_rate": 4.315331781256684e-05,
      "loss": 1.5801,
      "step": 5585
    },
    {
      "epoch": 1.12625,
      "grad_norm": 4.491096019744873,
      "learning_rate": 4.313910097629959e-05,
      "loss": 1.6013,
      "step": 5590
    },
    {
      "epoch": 1.1265,
      "grad_norm": 9.147683143615723,
      "learning_rate": 4.312487174212787e-05,
      "loss": 1.655,
      "step": 5595
    },
    {
      "epoch": 1.12675,
      "grad_norm": 5.475799083709717,
      "learning_rate": 4.311063011977723e-05,
      "loss": 1.609,
      "step": 5600
    },
    {
      "epoch": 1.127,
      "grad_norm": 4.606815338134766,
      "learning_rate": 4.3096376118981665e-05,
      "loss": 1.6212,
      "step": 5605
    },
    {
      "epoch": 1.12725,
      "grad_norm": 5.587300777435303,
      "learning_rate": 4.308210974948367e-05,
      "loss": 1.512,
      "step": 5610
    },
    {
      "epoch": 1.1275,
      "grad_norm": 3.9414398670196533,
      "learning_rate": 4.306783102103416e-05,
      "loss": 1.5651,
      "step": 5615
    },
    {
      "epoch": 1.12775,
      "grad_norm": 4.046406269073486,
      "learning_rate": 4.305353994339252e-05,
      "loss": 1.6642,
      "step": 5620
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 4.808901309967041,
      "learning_rate": 4.303923652632655e-05,
      "loss": 1.6174,
      "step": 5625
    },
    {
      "epoch": 1.12825,
      "grad_norm": 6.814638137817383,
      "learning_rate": 4.302492077961253e-05,
      "loss": 1.7698,
      "step": 5630
    },
    {
      "epoch": 1.1285,
      "grad_norm": 4.782026767730713,
      "learning_rate": 4.301059271303512e-05,
      "loss": 1.6531,
      "step": 5635
    },
    {
      "epoch": 1.12875,
      "grad_norm": 3.8624494075775146,
      "learning_rate": 4.2996252336387414e-05,
      "loss": 1.916,
      "step": 5640
    },
    {
      "epoch": 1.129,
      "grad_norm": 3.8603174686431885,
      "learning_rate": 4.298189965947094e-05,
      "loss": 1.5025,
      "step": 5645
    },
    {
      "epoch": 1.12925,
      "grad_norm": 5.043858528137207,
      "learning_rate": 4.29675346920956e-05,
      "loss": 1.6084,
      "step": 5650
    },
    {
      "epoch": 1.1295,
      "grad_norm": 3.452209949493408,
      "learning_rate": 4.295315744407972e-05,
      "loss": 1.583,
      "step": 5655
    },
    {
      "epoch": 1.12975,
      "grad_norm": 4.503424167633057,
      "learning_rate": 4.293876792525002e-05,
      "loss": 1.5034,
      "step": 5660
    },
    {
      "epoch": 1.13,
      "grad_norm": 5.048536777496338,
      "learning_rate": 4.2924366145441594e-05,
      "loss": 1.5972,
      "step": 5665
    },
    {
      "epoch": 1.13025,
      "grad_norm": 5.060578346252441,
      "learning_rate": 4.2909952114497925e-05,
      "loss": 1.6088,
      "step": 5670
    },
    {
      "epoch": 1.1305,
      "grad_norm": 4.993824005126953,
      "learning_rate": 4.2895525842270865e-05,
      "loss": 1.6681,
      "step": 5675
    },
    {
      "epoch": 1.13075,
      "grad_norm": 4.243078708648682,
      "learning_rate": 4.288108733862064e-05,
      "loss": 1.6121,
      "step": 5680
    },
    {
      "epoch": 1.131,
      "grad_norm": 6.5013532638549805,
      "learning_rate": 4.2866636613415825e-05,
      "loss": 1.4499,
      "step": 5685
    },
    {
      "epoch": 1.13125,
      "grad_norm": 5.437140464782715,
      "learning_rate": 4.2852173676533356e-05,
      "loss": 1.5442,
      "step": 5690
    },
    {
      "epoch": 1.1315,
      "grad_norm": 3.798945665359497,
      "learning_rate": 4.2837698537858514e-05,
      "loss": 1.4914,
      "step": 5695
    },
    {
      "epoch": 1.13175,
      "grad_norm": 6.392496109008789,
      "learning_rate": 4.282321120728493e-05,
      "loss": 1.5573,
      "step": 5700
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 4.2817487716674805,
      "learning_rate": 4.280871169471454e-05,
      "loss": 1.4994,
      "step": 5705
    },
    {
      "epoch": 1.13225,
      "grad_norm": 5.670204162597656,
      "learning_rate": 4.279420001005764e-05,
      "loss": 1.4917,
      "step": 5710
    },
    {
      "epoch": 1.1325,
      "grad_norm": 4.118837356567383,
      "learning_rate": 4.277967616323281e-05,
      "loss": 1.3833,
      "step": 5715
    },
    {
      "epoch": 1.13275,
      "grad_norm": 6.790956497192383,
      "learning_rate": 4.2765140164166984e-05,
      "loss": 1.4349,
      "step": 5720
    },
    {
      "epoch": 1.133,
      "grad_norm": 3.2466344833374023,
      "learning_rate": 4.275059202279537e-05,
      "loss": 1.1591,
      "step": 5725
    },
    {
      "epoch": 1.13325,
      "grad_norm": 10.246771812438965,
      "learning_rate": 4.273603174906149e-05,
      "loss": 1.6363,
      "step": 5730
    },
    {
      "epoch": 1.1335,
      "grad_norm": 4.150970458984375,
      "learning_rate": 4.272145935291714e-05,
      "loss": 1.3,
      "step": 5735
    },
    {
      "epoch": 1.13375,
      "grad_norm": 3.517396926879883,
      "learning_rate": 4.270687484432243e-05,
      "loss": 1.1685,
      "step": 5740
    },
    {
      "epoch": 1.134,
      "grad_norm": 4.277605056762695,
      "learning_rate": 4.269227823324573e-05,
      "loss": 1.4521,
      "step": 5745
    },
    {
      "epoch": 1.13425,
      "grad_norm": 3.759150505065918,
      "learning_rate": 4.267766952966369e-05,
      "loss": 1.4612,
      "step": 5750
    },
    {
      "epoch": 1.1345,
      "grad_norm": 3.8850388526916504,
      "learning_rate": 4.266304874356122e-05,
      "loss": 1.4416,
      "step": 5755
    },
    {
      "epoch": 1.13475,
      "grad_norm": 5.678086280822754,
      "learning_rate": 4.2648415884931476e-05,
      "loss": 1.5487,
      "step": 5760
    },
    {
      "epoch": 1.135,
      "grad_norm": 4.677554130554199,
      "learning_rate": 4.2633770963775896e-05,
      "loss": 1.7298,
      "step": 5765
    },
    {
      "epoch": 1.13525,
      "grad_norm": 7.112051010131836,
      "learning_rate": 4.261911399010413e-05,
      "loss": 1.7002,
      "step": 5770
    },
    {
      "epoch": 1.1355,
      "grad_norm": 5.275939464569092,
      "learning_rate": 4.26044449739341e-05,
      "loss": 1.639,
      "step": 5775
    },
    {
      "epoch": 1.13575,
      "grad_norm": 5.9437456130981445,
      "learning_rate": 4.258976392529192e-05,
      "loss": 1.7106,
      "step": 5780
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 4.819383144378662,
      "learning_rate": 4.2575070854211975e-05,
      "loss": 1.4314,
      "step": 5785
    },
    {
      "epoch": 1.13625,
      "grad_norm": 5.702167510986328,
      "learning_rate": 4.256036577073681e-05,
      "loss": 1.5083,
      "step": 5790
    },
    {
      "epoch": 1.1365,
      "grad_norm": 4.971037864685059,
      "learning_rate": 4.254564868491723e-05,
      "loss": 1.7292,
      "step": 5795
    },
    {
      "epoch": 1.13675,
      "grad_norm": 4.998748779296875,
      "learning_rate": 4.2530919606812216e-05,
      "loss": 1.6541,
      "step": 5800
    },
    {
      "epoch": 1.137,
      "grad_norm": 5.174299240112305,
      "learning_rate": 4.251617854648896e-05,
      "loss": 1.746,
      "step": 5805
    },
    {
      "epoch": 1.13725,
      "grad_norm": 4.821361064910889,
      "learning_rate": 4.250142551402284e-05,
      "loss": 1.7232,
      "step": 5810
    },
    {
      "epoch": 1.1375,
      "grad_norm": 5.975302696228027,
      "learning_rate": 4.24866605194974e-05,
      "loss": 1.4131,
      "step": 5815
    },
    {
      "epoch": 1.13775,
      "grad_norm": 6.228143215179443,
      "learning_rate": 4.247188357300439e-05,
      "loss": 1.616,
      "step": 5820
    },
    {
      "epoch": 1.138,
      "grad_norm": 3.7239599227905273,
      "learning_rate": 4.245709468464371e-05,
      "loss": 1.6848,
      "step": 5825
    },
    {
      "epoch": 1.13825,
      "grad_norm": 4.879303455352783,
      "learning_rate": 4.244229386452342e-05,
      "loss": 1.6335,
      "step": 5830
    },
    {
      "epoch": 1.1385,
      "grad_norm": 6.450827598571777,
      "learning_rate": 4.242748112275975e-05,
      "loss": 1.7779,
      "step": 5835
    },
    {
      "epoch": 1.13875,
      "grad_norm": 4.906541347503662,
      "learning_rate": 4.241265646947706e-05,
      "loss": 1.7045,
      "step": 5840
    },
    {
      "epoch": 1.139,
      "grad_norm": 4.4692182540893555,
      "learning_rate": 4.2397819914807856e-05,
      "loss": 1.6237,
      "step": 5845
    },
    {
      "epoch": 1.13925,
      "grad_norm": 3.923823356628418,
      "learning_rate": 4.2382971468892806e-05,
      "loss": 1.5949,
      "step": 5850
    },
    {
      "epoch": 1.1395,
      "grad_norm": 4.565322399139404,
      "learning_rate": 4.236811114188066e-05,
      "loss": 1.4939,
      "step": 5855
    },
    {
      "epoch": 1.13975,
      "grad_norm": 3.840031862258911,
      "learning_rate": 4.235323894392832e-05,
      "loss": 1.569,
      "step": 5860
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 6.444325923919678,
      "learning_rate": 4.2338354885200796e-05,
      "loss": 1.5152,
      "step": 5865
    },
    {
      "epoch": 1.14025,
      "grad_norm": 5.180878162384033,
      "learning_rate": 4.23234589758712e-05,
      "loss": 1.748,
      "step": 5870
    },
    {
      "epoch": 1.1405,
      "grad_norm": 4.335064888000488,
      "learning_rate": 4.230855122612074e-05,
      "loss": 1.4516,
      "step": 5875
    },
    {
      "epoch": 1.14075,
      "grad_norm": 5.305441379547119,
      "learning_rate": 4.229363164613874e-05,
      "loss": 1.6802,
      "step": 5880
    },
    {
      "epoch": 1.141,
      "grad_norm": 4.902724266052246,
      "learning_rate": 4.2278700246122566e-05,
      "loss": 1.5181,
      "step": 5885
    },
    {
      "epoch": 1.1412499999999999,
      "grad_norm": 4.399864196777344,
      "learning_rate": 4.2263757036277705e-05,
      "loss": 1.6807,
      "step": 5890
    },
    {
      "epoch": 1.1415,
      "grad_norm": 4.174314022064209,
      "learning_rate": 4.224880202681769e-05,
      "loss": 1.4133,
      "step": 5895
    },
    {
      "epoch": 1.14175,
      "grad_norm": 4.622901439666748,
      "learning_rate": 4.223383522796415e-05,
      "loss": 1.4011,
      "step": 5900
    },
    {
      "epoch": 1.142,
      "grad_norm": 5.651426315307617,
      "learning_rate": 4.2218856649946734e-05,
      "loss": 1.6717,
      "step": 5905
    },
    {
      "epoch": 1.14225,
      "grad_norm": 7.020557880401611,
      "learning_rate": 4.220386630300315e-05,
      "loss": 1.6838,
      "step": 5910
    },
    {
      "epoch": 1.1425,
      "grad_norm": 3.8589887619018555,
      "learning_rate": 4.218886419737919e-05,
      "loss": 1.4077,
      "step": 5915
    },
    {
      "epoch": 1.14275,
      "grad_norm": 3.68108868598938,
      "learning_rate": 4.217385034332861e-05,
      "loss": 1.4572,
      "step": 5920
    },
    {
      "epoch": 1.143,
      "grad_norm": 4.183459758758545,
      "learning_rate": 4.215882475111328e-05,
      "loss": 1.2836,
      "step": 5925
    },
    {
      "epoch": 1.14325,
      "grad_norm": 6.117618560791016,
      "learning_rate": 4.214378743100302e-05,
      "loss": 1.3132,
      "step": 5930
    },
    {
      "epoch": 1.1435,
      "grad_norm": 4.382432460784912,
      "learning_rate": 4.212873839327571e-05,
      "loss": 1.5532,
      "step": 5935
    },
    {
      "epoch": 1.14375,
      "grad_norm": 6.618895053863525,
      "learning_rate": 4.211367764821722e-05,
      "loss": 1.5342,
      "step": 5940
    },
    {
      "epoch": 1.144,
      "grad_norm": 4.302513599395752,
      "learning_rate": 4.209860520612143e-05,
      "loss": 1.4128,
      "step": 5945
    },
    {
      "epoch": 1.14425,
      "grad_norm": 3.6631219387054443,
      "learning_rate": 4.2083521077290213e-05,
      "loss": 1.5279,
      "step": 5950
    },
    {
      "epoch": 1.1445,
      "grad_norm": 4.740677833557129,
      "learning_rate": 4.206842527203343e-05,
      "loss": 1.2698,
      "step": 5955
    },
    {
      "epoch": 1.14475,
      "grad_norm": 4.664431095123291,
      "learning_rate": 4.205331780066892e-05,
      "loss": 1.2243,
      "step": 5960
    },
    {
      "epoch": 1.145,
      "grad_norm": 4.797877788543701,
      "learning_rate": 4.203819867352249e-05,
      "loss": 1.3901,
      "step": 5965
    },
    {
      "epoch": 1.1452499999999999,
      "grad_norm": 3.5202462673187256,
      "learning_rate": 4.202306790092792e-05,
      "loss": 1.1553,
      "step": 5970
    },
    {
      "epoch": 1.1455,
      "grad_norm": 6.029664039611816,
      "learning_rate": 4.200792549322698e-05,
      "loss": 1.4388,
      "step": 5975
    },
    {
      "epoch": 1.14575,
      "grad_norm": 3.3849997520446777,
      "learning_rate": 4.199277146076933e-05,
      "loss": 1.5406,
      "step": 5980
    },
    {
      "epoch": 1.146,
      "grad_norm": 4.694617748260498,
      "learning_rate": 4.1977605813912614e-05,
      "loss": 1.2962,
      "step": 5985
    },
    {
      "epoch": 1.14625,
      "grad_norm": 4.778451919555664,
      "learning_rate": 4.1962428563022414e-05,
      "loss": 1.4822,
      "step": 5990
    },
    {
      "epoch": 1.1465,
      "grad_norm": 6.310236930847168,
      "learning_rate": 4.1947239718472256e-05,
      "loss": 2.3646,
      "step": 5995
    },
    {
      "epoch": 1.14675,
      "grad_norm": 5.896048545837402,
      "learning_rate": 4.193203929064353e-05,
      "loss": 2.7176,
      "step": 6000
    },
    {
      "epoch": 1.14675,
      "eval_loss": 1.990323543548584,
      "eval_runtime": 5.8132,
      "eval_samples_per_second": 176.152,
      "eval_steps_per_second": 22.019,
      "step": 6000
    },
    {
      "epoch": 1.147,
      "grad_norm": 5.744811534881592,
      "learning_rate": 4.1916827289925614e-05,
      "loss": 2.5068,
      "step": 6005
    },
    {
      "epoch": 1.14725,
      "grad_norm": 7.692453861236572,
      "learning_rate": 4.1901603726715766e-05,
      "loss": 2.4048,
      "step": 6010
    },
    {
      "epoch": 1.1475,
      "grad_norm": 5.387821197509766,
      "learning_rate": 4.1886368611419144e-05,
      "loss": 2.3365,
      "step": 6015
    },
    {
      "epoch": 1.14775,
      "grad_norm": 5.893054008483887,
      "learning_rate": 4.18711219544488e-05,
      "loss": 2.3352,
      "step": 6020
    },
    {
      "epoch": 1.148,
      "grad_norm": 4.954916954040527,
      "learning_rate": 4.185586376622569e-05,
      "loss": 2.2744,
      "step": 6025
    },
    {
      "epoch": 1.14825,
      "grad_norm": 6.337256908416748,
      "learning_rate": 4.184059405717863e-05,
      "loss": 2.2366,
      "step": 6030
    },
    {
      "epoch": 1.1485,
      "grad_norm": 4.619714260101318,
      "learning_rate": 4.182531283774434e-05,
      "loss": 2.3264,
      "step": 6035
    },
    {
      "epoch": 1.14875,
      "grad_norm": 8.696773529052734,
      "learning_rate": 4.181002011836737e-05,
      "loss": 2.434,
      "step": 6040
    },
    {
      "epoch": 1.149,
      "grad_norm": 5.045589923858643,
      "learning_rate": 4.179471590950016e-05,
      "loss": 2.3745,
      "step": 6045
    },
    {
      "epoch": 1.1492499999999999,
      "grad_norm": 4.258205413818359,
      "learning_rate": 4.177940022160299e-05,
      "loss": 2.2471,
      "step": 6050
    },
    {
      "epoch": 1.1495,
      "grad_norm": 5.1126813888549805,
      "learning_rate": 4.176407306514399e-05,
      "loss": 2.2896,
      "step": 6055
    },
    {
      "epoch": 1.14975,
      "grad_norm": 4.832104682922363,
      "learning_rate": 4.174873445059913e-05,
      "loss": 2.2197,
      "step": 6060
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.806201934814453,
      "learning_rate": 4.17333843884522e-05,
      "loss": 2.2098,
      "step": 6065
    },
    {
      "epoch": 1.15025,
      "grad_norm": 4.532923221588135,
      "learning_rate": 4.171802288919482e-05,
      "loss": 2.2068,
      "step": 6070
    },
    {
      "epoch": 1.1505,
      "grad_norm": 7.298322677612305,
      "learning_rate": 4.170264996332645e-05,
      "loss": 2.394,
      "step": 6075
    },
    {
      "epoch": 1.15075,
      "grad_norm": 7.170407772064209,
      "learning_rate": 4.1687265621354314e-05,
      "loss": 2.3401,
      "step": 6080
    },
    {
      "epoch": 1.151,
      "grad_norm": 4.7761549949646,
      "learning_rate": 4.167186987379348e-05,
      "loss": 2.2743,
      "step": 6085
    },
    {
      "epoch": 1.15125,
      "grad_norm": 4.519415855407715,
      "learning_rate": 4.165646273116681e-05,
      "loss": 2.3158,
      "step": 6090
    },
    {
      "epoch": 1.1515,
      "grad_norm": 4.956067085266113,
      "learning_rate": 4.164104420400491e-05,
      "loss": 2.3782,
      "step": 6095
    },
    {
      "epoch": 1.15175,
      "grad_norm": 6.223320007324219,
      "learning_rate": 4.16256143028462e-05,
      "loss": 2.3036,
      "step": 6100
    },
    {
      "epoch": 1.152,
      "grad_norm": 9.694369316101074,
      "learning_rate": 4.161017303823691e-05,
      "loss": 2.9989,
      "step": 6105
    },
    {
      "epoch": 1.15225,
      "grad_norm": 8.547613143920898,
      "learning_rate": 4.159472042073096e-05,
      "loss": 2.8549,
      "step": 6110
    },
    {
      "epoch": 1.1525,
      "grad_norm": 7.849088191986084,
      "learning_rate": 4.1579256460890084e-05,
      "loss": 2.6954,
      "step": 6115
    },
    {
      "epoch": 1.15275,
      "grad_norm": 8.406832695007324,
      "learning_rate": 4.156378116928375e-05,
      "loss": 2.301,
      "step": 6120
    },
    {
      "epoch": 1.153,
      "grad_norm": 6.385992050170898,
      "learning_rate": 4.154829455648917e-05,
      "loss": 2.5092,
      "step": 6125
    },
    {
      "epoch": 1.1532499999999999,
      "grad_norm": 4.933682441711426,
      "learning_rate": 4.1532796633091296e-05,
      "loss": 1.978,
      "step": 6130
    },
    {
      "epoch": 2.00025,
      "grad_norm": 5.889321804046631,
      "learning_rate": 4.1517287409682834e-05,
      "loss": 1.5942,
      "step": 6135
    },
    {
      "epoch": 2.0005,
      "grad_norm": 5.852072715759277,
      "learning_rate": 4.150176689686417e-05,
      "loss": 1.5238,
      "step": 6140
    },
    {
      "epoch": 2.00075,
      "grad_norm": 4.975330352783203,
      "learning_rate": 4.148623510524343e-05,
      "loss": 1.5496,
      "step": 6145
    },
    {
      "epoch": 2.001,
      "grad_norm": 7.072881698608398,
      "learning_rate": 4.147069204543645e-05,
      "loss": 1.4351,
      "step": 6150
    },
    {
      "epoch": 2.00125,
      "grad_norm": 5.917412757873535,
      "learning_rate": 4.145513772806677e-05,
      "loss": 1.6342,
      "step": 6155
    },
    {
      "epoch": 2.0015,
      "grad_norm": 6.541387557983398,
      "learning_rate": 4.143957216376561e-05,
      "loss": 1.6743,
      "step": 6160
    },
    {
      "epoch": 2.00175,
      "grad_norm": 5.056737899780273,
      "learning_rate": 4.142399536317191e-05,
      "loss": 1.2836,
      "step": 6165
    },
    {
      "epoch": 2.002,
      "grad_norm": 5.165153503417969,
      "learning_rate": 4.140840733693223e-05,
      "loss": 1.4803,
      "step": 6170
    },
    {
      "epoch": 2.00225,
      "grad_norm": 5.750060558319092,
      "learning_rate": 4.139280809570086e-05,
      "loss": 1.486,
      "step": 6175
    },
    {
      "epoch": 2.0025,
      "grad_norm": 5.938179016113281,
      "learning_rate": 4.137719765013974e-05,
      "loss": 1.7227,
      "step": 6180
    },
    {
      "epoch": 2.00275,
      "grad_norm": 9.523924827575684,
      "learning_rate": 4.1361576010918446e-05,
      "loss": 1.8528,
      "step": 6185
    },
    {
      "epoch": 2.003,
      "grad_norm": 6.173019886016846,
      "learning_rate": 4.134594318871423e-05,
      "loss": 1.7437,
      "step": 6190
    },
    {
      "epoch": 2.00325,
      "grad_norm": 5.728832721710205,
      "learning_rate": 4.133029919421198e-05,
      "loss": 1.7998,
      "step": 6195
    },
    {
      "epoch": 2.0035,
      "grad_norm": 5.3462934494018555,
      "learning_rate": 4.131464403810422e-05,
      "loss": 1.603,
      "step": 6200
    },
    {
      "epoch": 2.00375,
      "grad_norm": 4.823341369628906,
      "learning_rate": 4.1298977731091094e-05,
      "loss": 1.4939,
      "step": 6205
    },
    {
      "epoch": 2.004,
      "grad_norm": 11.80424690246582,
      "learning_rate": 4.128330028388038e-05,
      "loss": 1.753,
      "step": 6210
    },
    {
      "epoch": 2.00425,
      "grad_norm": 10.83203411102295,
      "learning_rate": 4.1267611707187456e-05,
      "loss": 1.9027,
      "step": 6215
    },
    {
      "epoch": 2.0045,
      "grad_norm": 7.148162364959717,
      "learning_rate": 4.1251912011735326e-05,
      "loss": 1.8143,
      "step": 6220
    },
    {
      "epoch": 2.00475,
      "grad_norm": 7.865808963775635,
      "learning_rate": 4.123620120825459e-05,
      "loss": 1.86,
      "step": 6225
    },
    {
      "epoch": 2.005,
      "grad_norm": 6.348903179168701,
      "learning_rate": 4.122047930748343e-05,
      "loss": 1.9015,
      "step": 6230
    },
    {
      "epoch": 2.00525,
      "grad_norm": 5.290425777435303,
      "learning_rate": 4.1204746320167607e-05,
      "loss": 1.7946,
      "step": 6235
    },
    {
      "epoch": 2.0055,
      "grad_norm": 7.479501247406006,
      "learning_rate": 4.118900225706047e-05,
      "loss": 2.0575,
      "step": 6240
    },
    {
      "epoch": 2.00575,
      "grad_norm": 6.178284645080566,
      "learning_rate": 4.117324712892295e-05,
      "loss": 1.8373,
      "step": 6245
    },
    {
      "epoch": 2.006,
      "grad_norm": 6.807607650756836,
      "learning_rate": 4.115748094652352e-05,
      "loss": 2.0283,
      "step": 6250
    },
    {
      "epoch": 2.00625,
      "grad_norm": 6.279960632324219,
      "learning_rate": 4.1141703720638224e-05,
      "loss": 1.7892,
      "step": 6255
    },
    {
      "epoch": 2.0065,
      "grad_norm": 7.330144882202148,
      "learning_rate": 4.112591546205064e-05,
      "loss": 1.9587,
      "step": 6260
    },
    {
      "epoch": 2.00675,
      "grad_norm": 6.031030654907227,
      "learning_rate": 4.111011618155189e-05,
      "loss": 1.6788,
      "step": 6265
    },
    {
      "epoch": 2.007,
      "grad_norm": 7.380406379699707,
      "learning_rate": 4.1094305889940646e-05,
      "loss": 1.7095,
      "step": 6270
    },
    {
      "epoch": 2.00725,
      "grad_norm": 5.70543098449707,
      "learning_rate": 4.107848459802309e-05,
      "loss": 1.8219,
      "step": 6275
    },
    {
      "epoch": 2.0075,
      "grad_norm": 6.276628494262695,
      "learning_rate": 4.106265231661292e-05,
      "loss": 1.9358,
      "step": 6280
    },
    {
      "epoch": 2.00775,
      "grad_norm": 7.835782527923584,
      "learning_rate": 4.1046809056531344e-05,
      "loss": 1.7461,
      "step": 6285
    },
    {
      "epoch": 2.008,
      "grad_norm": 5.992799282073975,
      "learning_rate": 4.1030954828607095e-05,
      "loss": 1.7587,
      "step": 6290
    },
    {
      "epoch": 2.00825,
      "grad_norm": 6.916426658630371,
      "learning_rate": 4.1015089643676386e-05,
      "loss": 1.8817,
      "step": 6295
    },
    {
      "epoch": 2.0085,
      "grad_norm": 8.995530128479004,
      "learning_rate": 4.099921351258292e-05,
      "loss": 1.7374,
      "step": 6300
    },
    {
      "epoch": 2.00875,
      "grad_norm": 6.592686176300049,
      "learning_rate": 4.0983326446177873e-05,
      "loss": 1.7355,
      "step": 6305
    },
    {
      "epoch": 2.009,
      "grad_norm": 7.268220901489258,
      "learning_rate": 4.0967428455319925e-05,
      "loss": 1.8886,
      "step": 6310
    },
    {
      "epoch": 2.00925,
      "grad_norm": 6.842240333557129,
      "learning_rate": 4.095151955087518e-05,
      "loss": 1.7363,
      "step": 6315
    },
    {
      "epoch": 2.0095,
      "grad_norm": 7.344639778137207,
      "learning_rate": 4.093559974371725e-05,
      "loss": 1.6584,
      "step": 6320
    },
    {
      "epoch": 2.00975,
      "grad_norm": 9.524566650390625,
      "learning_rate": 4.091966904472715e-05,
      "loss": 1.917,
      "step": 6325
    },
    {
      "epoch": 2.01,
      "grad_norm": 6.276695251464844,
      "learning_rate": 4.090372746479337e-05,
      "loss": 1.7512,
      "step": 6330
    },
    {
      "epoch": 2.01025,
      "grad_norm": 6.550954818725586,
      "learning_rate": 4.088777501481184e-05,
      "loss": 1.7849,
      "step": 6335
    },
    {
      "epoch": 2.0105,
      "grad_norm": 5.502153396606445,
      "learning_rate": 4.0871811705685883e-05,
      "loss": 1.8867,
      "step": 6340
    },
    {
      "epoch": 2.01075,
      "grad_norm": 8.550463676452637,
      "learning_rate": 4.08558375483263e-05,
      "loss": 1.7365,
      "step": 6345
    },
    {
      "epoch": 2.011,
      "grad_norm": 7.421768665313721,
      "learning_rate": 4.0839852553651265e-05,
      "loss": 1.6777,
      "step": 6350
    },
    {
      "epoch": 2.01125,
      "grad_norm": 5.515841484069824,
      "learning_rate": 4.082385673258637e-05,
      "loss": 1.7894,
      "step": 6355
    },
    {
      "epoch": 2.0115,
      "grad_norm": 6.58716344833374,
      "learning_rate": 4.0807850096064605e-05,
      "loss": 1.6781,
      "step": 6360
    },
    {
      "epoch": 2.01175,
      "grad_norm": 6.64516544342041,
      "learning_rate": 4.079183265502636e-05,
      "loss": 1.7885,
      "step": 6365
    },
    {
      "epoch": 2.012,
      "grad_norm": 6.388620376586914,
      "learning_rate": 4.0775804420419404e-05,
      "loss": 1.6497,
      "step": 6370
    },
    {
      "epoch": 2.01225,
      "grad_norm": 6.740678310394287,
      "learning_rate": 4.075976540319888e-05,
      "loss": 1.9369,
      "step": 6375
    },
    {
      "epoch": 2.0125,
      "grad_norm": 7.218939781188965,
      "learning_rate": 4.0743715614327317e-05,
      "loss": 1.6682,
      "step": 6380
    },
    {
      "epoch": 2.01275,
      "grad_norm": 5.724467754364014,
      "learning_rate": 4.072765506477457e-05,
      "loss": 1.4787,
      "step": 6385
    },
    {
      "epoch": 2.013,
      "grad_norm": 5.926642417907715,
      "learning_rate": 4.07115837655179e-05,
      "loss": 1.6191,
      "step": 6390
    },
    {
      "epoch": 2.01325,
      "grad_norm": 6.436286926269531,
      "learning_rate": 4.069550172754189e-05,
      "loss": 1.6446,
      "step": 6395
    },
    {
      "epoch": 2.0135,
      "grad_norm": 6.71317720413208,
      "learning_rate": 4.067940896183843e-05,
      "loss": 1.489,
      "step": 6400
    },
    {
      "epoch": 2.01375,
      "grad_norm": 7.336287021636963,
      "learning_rate": 4.06633054794068e-05,
      "loss": 1.4981,
      "step": 6405
    },
    {
      "epoch": 2.014,
      "grad_norm": 7.873203277587891,
      "learning_rate": 4.064719129125356e-05,
      "loss": 1.8109,
      "step": 6410
    },
    {
      "epoch": 2.01425,
      "grad_norm": 5.726783752441406,
      "learning_rate": 4.063106640839264e-05,
      "loss": 1.6714,
      "step": 6415
    },
    {
      "epoch": 2.0145,
      "grad_norm": 5.540205478668213,
      "learning_rate": 4.06149308418452e-05,
      "loss": 1.3357,
      "step": 6420
    },
    {
      "epoch": 2.01475,
      "grad_norm": 6.475637912750244,
      "learning_rate": 4.0598784602639776e-05,
      "loss": 1.5087,
      "step": 6425
    },
    {
      "epoch": 2.015,
      "grad_norm": 5.134166717529297,
      "learning_rate": 4.058262770181217e-05,
      "loss": 1.4008,
      "step": 6430
    },
    {
      "epoch": 2.01525,
      "grad_norm": 8.151066780090332,
      "learning_rate": 4.056646015040546e-05,
      "loss": 0.9308,
      "step": 6435
    },
    {
      "epoch": 2.0155,
      "grad_norm": 9.019984245300293,
      "learning_rate": 4.0550281959470023e-05,
      "loss": 1.0196,
      "step": 6440
    },
    {
      "epoch": 2.01575,
      "grad_norm": 4.715202331542969,
      "learning_rate": 4.053409314006349e-05,
      "loss": 0.8828,
      "step": 6445
    },
    {
      "epoch": 2.016,
      "grad_norm": 4.5275044441223145,
      "learning_rate": 4.051789370325078e-05,
      "loss": 0.7147,
      "step": 6450
    },
    {
      "epoch": 2.01625,
      "grad_norm": 6.080944061279297,
      "learning_rate": 4.050168366010405e-05,
      "loss": 0.8404,
      "step": 6455
    },
    {
      "epoch": 2.0165,
      "grad_norm": 13.929104804992676,
      "learning_rate": 4.048546302170271e-05,
      "loss": 1.1448,
      "step": 6460
    },
    {
      "epoch": 2.01675,
      "grad_norm": 9.162164688110352,
      "learning_rate": 4.046923179913341e-05,
      "loss": 1.9465,
      "step": 6465
    },
    {
      "epoch": 2.017,
      "grad_norm": 8.804879188537598,
      "learning_rate": 4.0452990003490047e-05,
      "loss": 2.0973,
      "step": 6470
    },
    {
      "epoch": 2.01725,
      "grad_norm": 6.1842474937438965,
      "learning_rate": 4.0436737645873715e-05,
      "loss": 1.9011,
      "step": 6475
    },
    {
      "epoch": 2.0175,
      "grad_norm": 8.22524642944336,
      "learning_rate": 4.042047473739278e-05,
      "loss": 1.871,
      "step": 6480
    },
    {
      "epoch": 2.01775,
      "grad_norm": 6.290178298950195,
      "learning_rate": 4.0404201289162755e-05,
      "loss": 1.6187,
      "step": 6485
    },
    {
      "epoch": 2.018,
      "grad_norm": 6.321609020233154,
      "learning_rate": 4.0387917312306414e-05,
      "loss": 1.6803,
      "step": 6490
    },
    {
      "epoch": 2.01825,
      "grad_norm": 8.027162551879883,
      "learning_rate": 4.037162281795368e-05,
      "loss": 1.8669,
      "step": 6495
    },
    {
      "epoch": 2.0185,
      "grad_norm": 6.749007225036621,
      "learning_rate": 4.03553178172417e-05,
      "loss": 1.9385,
      "step": 6500
    },
    {
      "epoch": 2.0185,
      "eval_loss": 1.87970769405365,
      "eval_runtime": 5.0924,
      "eval_samples_per_second": 201.085,
      "eval_steps_per_second": 25.136,
      "step": 6500
    },
    {
      "epoch": 2.01875,
      "grad_norm": 6.747420310974121,
      "learning_rate": 4.033900232131478e-05,
      "loss": 1.7112,
      "step": 6505
    },
    {
      "epoch": 2.019,
      "grad_norm": 6.522228240966797,
      "learning_rate": 4.0322676341324415e-05,
      "loss": 1.8919,
      "step": 6510
    },
    {
      "epoch": 2.01925,
      "grad_norm": 6.418597221374512,
      "learning_rate": 4.0306339888429254e-05,
      "loss": 1.7453,
      "step": 6515
    },
    {
      "epoch": 2.0195,
      "grad_norm": 6.813872814178467,
      "learning_rate": 4.028999297379511e-05,
      "loss": 1.7427,
      "step": 6520
    },
    {
      "epoch": 2.01975,
      "grad_norm": 6.0759100914001465,
      "learning_rate": 4.027363560859494e-05,
      "loss": 1.5132,
      "step": 6525
    },
    {
      "epoch": 2.02,
      "grad_norm": 7.065266132354736,
      "learning_rate": 4.025726780400886e-05,
      "loss": 1.7099,
      "step": 6530
    },
    {
      "epoch": 2.02025,
      "grad_norm": 8.459104537963867,
      "learning_rate": 4.0240889571224105e-05,
      "loss": 1.9625,
      "step": 6535
    },
    {
      "epoch": 2.0205,
      "grad_norm": 6.3243513107299805,
      "learning_rate": 4.0224500921435035e-05,
      "loss": 1.8716,
      "step": 6540
    },
    {
      "epoch": 2.02075,
      "grad_norm": 7.889038562774658,
      "learning_rate": 4.020810186584314e-05,
      "loss": 1.6459,
      "step": 6545
    },
    {
      "epoch": 2.021,
      "grad_norm": 8.329846382141113,
      "learning_rate": 4.019169241565703e-05,
      "loss": 1.8463,
      "step": 6550
    },
    {
      "epoch": 2.02125,
      "grad_norm": 5.564646244049072,
      "learning_rate": 4.01752725820924e-05,
      "loss": 1.7533,
      "step": 6555
    },
    {
      "epoch": 2.0215,
      "grad_norm": 7.373452186584473,
      "learning_rate": 4.0158842376372064e-05,
      "loss": 1.6035,
      "step": 6560
    },
    {
      "epoch": 2.02175,
      "grad_norm": 9.472991943359375,
      "learning_rate": 4.0142401809725896e-05,
      "loss": 1.7898,
      "step": 6565
    },
    {
      "epoch": 2.022,
      "grad_norm": 6.779891490936279,
      "learning_rate": 4.0125950893390876e-05,
      "loss": 1.9059,
      "step": 6570
    },
    {
      "epoch": 2.02225,
      "grad_norm": 8.817904472351074,
      "learning_rate": 4.010948963861104e-05,
      "loss": 2.0199,
      "step": 6575
    },
    {
      "epoch": 2.0225,
      "grad_norm": 7.401157379150391,
      "learning_rate": 4.009301805663752e-05,
      "loss": 2.1079,
      "step": 6580
    },
    {
      "epoch": 2.02275,
      "grad_norm": 7.585205554962158,
      "learning_rate": 4.007653615872847e-05,
      "loss": 1.821,
      "step": 6585
    },
    {
      "epoch": 2.023,
      "grad_norm": 6.2483415603637695,
      "learning_rate": 4.006004395614913e-05,
      "loss": 1.8544,
      "step": 6590
    },
    {
      "epoch": 2.02325,
      "grad_norm": 6.670477867126465,
      "learning_rate": 4.0043541460171746e-05,
      "loss": 1.56,
      "step": 6595
    },
    {
      "epoch": 2.0235,
      "grad_norm": 8.259538650512695,
      "learning_rate": 4.002702868207563e-05,
      "loss": 1.8219,
      "step": 6600
    },
    {
      "epoch": 2.02375,
      "grad_norm": 5.353694438934326,
      "learning_rate": 4.0010505633147106e-05,
      "loss": 1.5859,
      "step": 6605
    },
    {
      "epoch": 2.024,
      "grad_norm": 7.407003402709961,
      "learning_rate": 3.999397232467952e-05,
      "loss": 1.6756,
      "step": 6610
    },
    {
      "epoch": 2.02425,
      "grad_norm": 6.594243049621582,
      "learning_rate": 3.9977428767973234e-05,
      "loss": 1.5602,
      "step": 6615
    },
    {
      "epoch": 2.0245,
      "grad_norm": 9.658063888549805,
      "learning_rate": 3.996087497433562e-05,
      "loss": 1.9952,
      "step": 6620
    },
    {
      "epoch": 2.02475,
      "grad_norm": 6.75510835647583,
      "learning_rate": 3.994431095508102e-05,
      "loss": 1.7164,
      "step": 6625
    },
    {
      "epoch": 2.025,
      "grad_norm": 8.365036964416504,
      "learning_rate": 3.9927736721530805e-05,
      "loss": 1.7843,
      "step": 6630
    },
    {
      "epoch": 2.02525,
      "grad_norm": 4.398618698120117,
      "learning_rate": 3.991115228501331e-05,
      "loss": 1.7067,
      "step": 6635
    },
    {
      "epoch": 2.0255,
      "grad_norm": 7.499884128570557,
      "learning_rate": 3.9894557656863823e-05,
      "loss": 1.9086,
      "step": 6640
    },
    {
      "epoch": 2.02575,
      "grad_norm": 6.7309675216674805,
      "learning_rate": 3.9877952848424624e-05,
      "loss": 1.8824,
      "step": 6645
    },
    {
      "epoch": 2.026,
      "grad_norm": 7.182687759399414,
      "learning_rate": 3.9861337871044954e-05,
      "loss": 1.6466,
      "step": 6650
    },
    {
      "epoch": 2.02625,
      "grad_norm": 8.903766632080078,
      "learning_rate": 3.984471273608097e-05,
      "loss": 2.0915,
      "step": 6655
    },
    {
      "epoch": 2.0265,
      "grad_norm": 6.273398399353027,
      "learning_rate": 3.9828077454895815e-05,
      "loss": 1.6191,
      "step": 6660
    },
    {
      "epoch": 2.02675,
      "grad_norm": 8.853021621704102,
      "learning_rate": 3.9811432038859545e-05,
      "loss": 1.7698,
      "step": 6665
    },
    {
      "epoch": 2.027,
      "grad_norm": 9.809370040893555,
      "learning_rate": 3.9794776499349126e-05,
      "loss": 1.6797,
      "step": 6670
    },
    {
      "epoch": 2.02725,
      "grad_norm": 6.656440734863281,
      "learning_rate": 3.9778110847748485e-05,
      "loss": 1.709,
      "step": 6675
    },
    {
      "epoch": 2.0275,
      "grad_norm": 6.982326030731201,
      "learning_rate": 3.976143509544843e-05,
      "loss": 1.603,
      "step": 6680
    },
    {
      "epoch": 2.02775,
      "grad_norm": 6.179593086242676,
      "learning_rate": 3.9744749253846674e-05,
      "loss": 1.8073,
      "step": 6685
    },
    {
      "epoch": 2.028,
      "grad_norm": 10.613361358642578,
      "learning_rate": 3.972805333434784e-05,
      "loss": 1.7016,
      "step": 6690
    },
    {
      "epoch": 2.02825,
      "grad_norm": 7.994349479675293,
      "learning_rate": 3.971134734836344e-05,
      "loss": 1.9297,
      "step": 6695
    },
    {
      "epoch": 2.0285,
      "grad_norm": 6.475415229797363,
      "learning_rate": 3.969463130731183e-05,
      "loss": 1.6527,
      "step": 6700
    },
    {
      "epoch": 2.02875,
      "grad_norm": 9.975399017333984,
      "learning_rate": 3.967790522261829e-05,
      "loss": 1.8338,
      "step": 6705
    },
    {
      "epoch": 2.029,
      "grad_norm": 6.902524948120117,
      "learning_rate": 3.966116910571494e-05,
      "loss": 1.7345,
      "step": 6710
    },
    {
      "epoch": 2.02925,
      "grad_norm": 6.510923862457275,
      "learning_rate": 3.964442296804074e-05,
      "loss": 1.7032,
      "step": 6715
    },
    {
      "epoch": 2.0295,
      "grad_norm": 4.626046180725098,
      "learning_rate": 3.9627666821041545e-05,
      "loss": 1.4651,
      "step": 6720
    },
    {
      "epoch": 2.02975,
      "grad_norm": 9.074337005615234,
      "learning_rate": 3.961090067617e-05,
      "loss": 1.7281,
      "step": 6725
    },
    {
      "epoch": 2.03,
      "grad_norm": 4.934937000274658,
      "learning_rate": 3.9594124544885615e-05,
      "loss": 1.6175,
      "step": 6730
    },
    {
      "epoch": 2.03025,
      "grad_norm": 8.700403213500977,
      "learning_rate": 3.957733843865472e-05,
      "loss": 1.7892,
      "step": 6735
    },
    {
      "epoch": 2.0305,
      "grad_norm": 6.208251476287842,
      "learning_rate": 3.956054236895046e-05,
      "loss": 1.7856,
      "step": 6740
    },
    {
      "epoch": 2.03075,
      "grad_norm": 7.491854667663574,
      "learning_rate": 3.954373634725279e-05,
      "loss": 1.7278,
      "step": 6745
    },
    {
      "epoch": 2.031,
      "grad_norm": 5.717381477355957,
      "learning_rate": 3.952692038504846e-05,
      "loss": 1.6265,
      "step": 6750
    },
    {
      "epoch": 2.03125,
      "grad_norm": 6.852360248565674,
      "learning_rate": 3.9510094493831027e-05,
      "loss": 1.8687,
      "step": 6755
    },
    {
      "epoch": 2.0315,
      "grad_norm": 7.628792762756348,
      "learning_rate": 3.949325868510083e-05,
      "loss": 1.6618,
      "step": 6760
    },
    {
      "epoch": 2.03175,
      "grad_norm": 5.664748668670654,
      "learning_rate": 3.9476412970364996e-05,
      "loss": 1.6954,
      "step": 6765
    },
    {
      "epoch": 2.032,
      "grad_norm": 6.485970497131348,
      "learning_rate": 3.945955736113739e-05,
      "loss": 1.5634,
      "step": 6770
    },
    {
      "epoch": 2.03225,
      "grad_norm": 7.7187886238098145,
      "learning_rate": 3.944269186893867e-05,
      "loss": 1.6514,
      "step": 6775
    },
    {
      "epoch": 2.0325,
      "grad_norm": 7.88890266418457,
      "learning_rate": 3.942581650529625e-05,
      "loss": 1.4908,
      "step": 6780
    },
    {
      "epoch": 2.03275,
      "grad_norm": 6.384628772735596,
      "learning_rate": 3.940893128174428e-05,
      "loss": 1.4541,
      "step": 6785
    },
    {
      "epoch": 2.033,
      "grad_norm": 7.343711853027344,
      "learning_rate": 3.9392036209823644e-05,
      "loss": 1.6454,
      "step": 6790
    },
    {
      "epoch": 2.03325,
      "grad_norm": 6.336919784545898,
      "learning_rate": 3.937513130108197e-05,
      "loss": 1.6859,
      "step": 6795
    },
    {
      "epoch": 2.0335,
      "grad_norm": 6.42595911026001,
      "learning_rate": 3.935821656707359e-05,
      "loss": 1.6861,
      "step": 6800
    },
    {
      "epoch": 2.03375,
      "grad_norm": 8.355293273925781,
      "learning_rate": 3.934129201935959e-05,
      "loss": 1.8392,
      "step": 6805
    },
    {
      "epoch": 2.034,
      "grad_norm": 6.455617427825928,
      "learning_rate": 3.932435766950772e-05,
      "loss": 1.9754,
      "step": 6810
    },
    {
      "epoch": 2.03425,
      "grad_norm": 6.470085620880127,
      "learning_rate": 3.9307413529092454e-05,
      "loss": 1.5594,
      "step": 6815
    },
    {
      "epoch": 2.0345,
      "grad_norm": 6.193700790405273,
      "learning_rate": 3.929045960969494e-05,
      "loss": 1.7263,
      "step": 6820
    },
    {
      "epoch": 2.03475,
      "grad_norm": 5.483184814453125,
      "learning_rate": 3.9273495922903046e-05,
      "loss": 1.7805,
      "step": 6825
    },
    {
      "epoch": 2.035,
      "grad_norm": 5.975904941558838,
      "learning_rate": 3.925652248031127e-05,
      "loss": 1.9015,
      "step": 6830
    },
    {
      "epoch": 2.03525,
      "grad_norm": 6.091358661651611,
      "learning_rate": 3.923953929352083e-05,
      "loss": 1.7903,
      "step": 6835
    },
    {
      "epoch": 2.0355,
      "grad_norm": 4.961208820343018,
      "learning_rate": 3.9222546374139533e-05,
      "loss": 1.7576,
      "step": 6840
    },
    {
      "epoch": 2.03575,
      "grad_norm": 6.261785984039307,
      "learning_rate": 3.920554373378191e-05,
      "loss": 1.7256,
      "step": 6845
    },
    {
      "epoch": 2.036,
      "grad_norm": 6.945226669311523,
      "learning_rate": 3.9188531384069096e-05,
      "loss": 2.0299,
      "step": 6850
    },
    {
      "epoch": 2.03625,
      "grad_norm": 5.757417678833008,
      "learning_rate": 3.9171509336628864e-05,
      "loss": 1.8418,
      "step": 6855
    },
    {
      "epoch": 2.0365,
      "grad_norm": 10.56873607635498,
      "learning_rate": 3.915447760309564e-05,
      "loss": 1.815,
      "step": 6860
    },
    {
      "epoch": 2.03675,
      "grad_norm": 7.655534267425537,
      "learning_rate": 3.9137436195110435e-05,
      "loss": 1.8385,
      "step": 6865
    },
    {
      "epoch": 2.037,
      "grad_norm": 4.549964427947998,
      "learning_rate": 3.9120385124320894e-05,
      "loss": 1.8434,
      "step": 6870
    },
    {
      "epoch": 2.03725,
      "grad_norm": 5.269055366516113,
      "learning_rate": 3.910332440238128e-05,
      "loss": 1.8047,
      "step": 6875
    },
    {
      "epoch": 2.0375,
      "grad_norm": 6.768215656280518,
      "learning_rate": 3.9086254040952416e-05,
      "loss": 2.0055,
      "step": 6880
    },
    {
      "epoch": 2.03775,
      "grad_norm": 5.277390480041504,
      "learning_rate": 3.906917405170174e-05,
      "loss": 1.7643,
      "step": 6885
    },
    {
      "epoch": 2.038,
      "grad_norm": 5.476654529571533,
      "learning_rate": 3.905208444630327e-05,
      "loss": 1.7448,
      "step": 6890
    },
    {
      "epoch": 2.03825,
      "grad_norm": 8.763066291809082,
      "learning_rate": 3.903498523643758e-05,
      "loss": 1.8251,
      "step": 6895
    },
    {
      "epoch": 2.0385,
      "grad_norm": 5.985193252563477,
      "learning_rate": 3.901787643379182e-05,
      "loss": 1.7897,
      "step": 6900
    },
    {
      "epoch": 2.03875,
      "grad_norm": 6.5963873863220215,
      "learning_rate": 3.900075805005971e-05,
      "loss": 1.9748,
      "step": 6905
    },
    {
      "epoch": 2.039,
      "grad_norm": 6.551289081573486,
      "learning_rate": 3.898363009694148e-05,
      "loss": 1.7511,
      "step": 6910
    },
    {
      "epoch": 2.03925,
      "grad_norm": 5.1454033851623535,
      "learning_rate": 3.896649258614393e-05,
      "loss": 1.7224,
      "step": 6915
    },
    {
      "epoch": 2.0395,
      "grad_norm": 7.109480857849121,
      "learning_rate": 3.894934552938041e-05,
      "loss": 1.8453,
      "step": 6920
    },
    {
      "epoch": 2.03975,
      "grad_norm": 5.098613262176514,
      "learning_rate": 3.8932188938370746e-05,
      "loss": 1.7125,
      "step": 6925
    },
    {
      "epoch": 2.04,
      "grad_norm": 6.298327922821045,
      "learning_rate": 3.891502282484132e-05,
      "loss": 1.7285,
      "step": 6930
    },
    {
      "epoch": 2.04025,
      "grad_norm": 5.526846408843994,
      "learning_rate": 3.8897847200525e-05,
      "loss": 1.8179,
      "step": 6935
    },
    {
      "epoch": 2.0405,
      "grad_norm": 6.634101867675781,
      "learning_rate": 3.888066207716117e-05,
      "loss": 1.6689,
      "step": 6940
    },
    {
      "epoch": 2.04075,
      "grad_norm": 5.257121562957764,
      "learning_rate": 3.886346746649569e-05,
      "loss": 1.5905,
      "step": 6945
    },
    {
      "epoch": 2.041,
      "grad_norm": 5.961594581604004,
      "learning_rate": 3.884626338028094e-05,
      "loss": 1.9015,
      "step": 6950
    },
    {
      "epoch": 2.04125,
      "grad_norm": 6.267558574676514,
      "learning_rate": 3.882904983027571e-05,
      "loss": 1.855,
      "step": 6955
    },
    {
      "epoch": 2.0415,
      "grad_norm": 5.226838111877441,
      "learning_rate": 3.8811826828245334e-05,
      "loss": 1.8831,
      "step": 6960
    },
    {
      "epoch": 2.04175,
      "grad_norm": 5.268368721008301,
      "learning_rate": 3.879459438596155e-05,
      "loss": 1.9195,
      "step": 6965
    },
    {
      "epoch": 2.042,
      "grad_norm": 7.61348819732666,
      "learning_rate": 3.877735251520258e-05,
      "loss": 1.8213,
      "step": 6970
    },
    {
      "epoch": 2.04225,
      "grad_norm": 7.512228488922119,
      "learning_rate": 3.876010122775309e-05,
      "loss": 1.7982,
      "step": 6975
    },
    {
      "epoch": 2.0425,
      "grad_norm": 5.78782320022583,
      "learning_rate": 3.874284053540416e-05,
      "loss": 1.8997,
      "step": 6980
    },
    {
      "epoch": 2.04275,
      "grad_norm": 6.861756324768066,
      "learning_rate": 3.87255704499533e-05,
      "loss": 1.8464,
      "step": 6985
    },
    {
      "epoch": 2.043,
      "grad_norm": 9.463058471679688,
      "learning_rate": 3.870829098320446e-05,
      "loss": 1.7551,
      "step": 6990
    },
    {
      "epoch": 2.04325,
      "grad_norm": 6.006198406219482,
      "learning_rate": 3.8691002146968e-05,
      "loss": 2.0673,
      "step": 6995
    },
    {
      "epoch": 2.0435,
      "grad_norm": 7.262631893157959,
      "learning_rate": 3.867370395306068e-05,
      "loss": 2.0152,
      "step": 7000
    },
    {
      "epoch": 2.0435,
      "eval_loss": 1.8532612323760986,
      "eval_runtime": 5.1577,
      "eval_samples_per_second": 198.539,
      "eval_steps_per_second": 24.817,
      "step": 7000
    },
    {
      "epoch": 2.04375,
      "grad_norm": 5.436552047729492,
      "learning_rate": 3.865639641330563e-05,
      "loss": 1.6816,
      "step": 7005
    },
    {
      "epoch": 2.044,
      "grad_norm": 6.0821075439453125,
      "learning_rate": 3.8639079539532405e-05,
      "loss": 1.7484,
      "step": 7010
    },
    {
      "epoch": 2.04425,
      "grad_norm": 5.287977695465088,
      "learning_rate": 3.862175334357693e-05,
      "loss": 1.6849,
      "step": 7015
    },
    {
      "epoch": 2.0445,
      "grad_norm": 5.754778861999512,
      "learning_rate": 3.860441783728149e-05,
      "loss": 1.7423,
      "step": 7020
    },
    {
      "epoch": 2.04475,
      "grad_norm": 7.909186363220215,
      "learning_rate": 3.858707303249473e-05,
      "loss": 1.9389,
      "step": 7025
    },
    {
      "epoch": 2.045,
      "grad_norm": 5.3497843742370605,
      "learning_rate": 3.8569718941071684e-05,
      "loss": 1.8238,
      "step": 7030
    },
    {
      "epoch": 2.04525,
      "grad_norm": 6.916540622711182,
      "learning_rate": 3.855235557487369e-05,
      "loss": 1.7507,
      "step": 7035
    },
    {
      "epoch": 2.0455,
      "grad_norm": 6.838929176330566,
      "learning_rate": 3.853498294576845e-05,
      "loss": 1.7329,
      "step": 7040
    },
    {
      "epoch": 2.04575,
      "grad_norm": 5.689896106719971,
      "learning_rate": 3.851760106563e-05,
      "loss": 1.7552,
      "step": 7045
    },
    {
      "epoch": 2.046,
      "grad_norm": 5.545389652252197,
      "learning_rate": 3.850020994633868e-05,
      "loss": 1.6823,
      "step": 7050
    },
    {
      "epoch": 2.04625,
      "grad_norm": 6.7385077476501465,
      "learning_rate": 3.848280959978116e-05,
      "loss": 1.9491,
      "step": 7055
    },
    {
      "epoch": 2.0465,
      "grad_norm": 5.208011627197266,
      "learning_rate": 3.846540003785042e-05,
      "loss": 1.6816,
      "step": 7060
    },
    {
      "epoch": 2.04675,
      "grad_norm": 5.675981044769287,
      "learning_rate": 3.844798127244572e-05,
      "loss": 1.6797,
      "step": 7065
    },
    {
      "epoch": 2.047,
      "grad_norm": 7.030714988708496,
      "learning_rate": 3.8430553315472626e-05,
      "loss": 1.7039,
      "step": 7070
    },
    {
      "epoch": 2.04725,
      "grad_norm": 5.633366107940674,
      "learning_rate": 3.841311617884299e-05,
      "loss": 1.8112,
      "step": 7075
    },
    {
      "epoch": 2.0475,
      "grad_norm": 6.682476043701172,
      "learning_rate": 3.8395669874474915e-05,
      "loss": 1.6249,
      "step": 7080
    },
    {
      "epoch": 2.04775,
      "grad_norm": 6.375860214233398,
      "learning_rate": 3.83782144142928e-05,
      "loss": 1.8221,
      "step": 7085
    },
    {
      "epoch": 2.048,
      "grad_norm": 5.557384490966797,
      "learning_rate": 3.8360749810227286e-05,
      "loss": 1.8636,
      "step": 7090
    },
    {
      "epoch": 2.04825,
      "grad_norm": 7.747983932495117,
      "learning_rate": 3.834327607421525e-05,
      "loss": 1.9674,
      "step": 7095
    },
    {
      "epoch": 2.0485,
      "grad_norm": 5.017320156097412,
      "learning_rate": 3.832579321819985e-05,
      "loss": 1.8068,
      "step": 7100
    },
    {
      "epoch": 2.04875,
      "grad_norm": 4.710677623748779,
      "learning_rate": 3.830830125413043e-05,
      "loss": 1.8304,
      "step": 7105
    },
    {
      "epoch": 2.049,
      "grad_norm": 6.1192708015441895,
      "learning_rate": 3.829080019396259e-05,
      "loss": 1.8673,
      "step": 7110
    },
    {
      "epoch": 2.04925,
      "grad_norm": 5.872855186462402,
      "learning_rate": 3.827329004965816e-05,
      "loss": 1.8025,
      "step": 7115
    },
    {
      "epoch": 2.0495,
      "grad_norm": 9.218117713928223,
      "learning_rate": 3.825577083318512e-05,
      "loss": 1.8195,
      "step": 7120
    },
    {
      "epoch": 2.04975,
      "grad_norm": 5.139591217041016,
      "learning_rate": 3.823824255651772e-05,
      "loss": 1.597,
      "step": 7125
    },
    {
      "epoch": 2.05,
      "grad_norm": 7.082363128662109,
      "learning_rate": 3.822070523163636e-05,
      "loss": 1.7181,
      "step": 7130
    },
    {
      "epoch": 2.05025,
      "grad_norm": 6.499672889709473,
      "learning_rate": 3.820315887052764e-05,
      "loss": 1.8333,
      "step": 7135
    },
    {
      "epoch": 2.0505,
      "grad_norm": 5.361475467681885,
      "learning_rate": 3.818560348518433e-05,
      "loss": 1.8046,
      "step": 7140
    },
    {
      "epoch": 2.05075,
      "grad_norm": 5.157938480377197,
      "learning_rate": 3.816803908760537e-05,
      "loss": 1.9108,
      "step": 7145
    },
    {
      "epoch": 2.051,
      "grad_norm": 5.27643346786499,
      "learning_rate": 3.8150465689795854e-05,
      "loss": 1.7045,
      "step": 7150
    },
    {
      "epoch": 2.05125,
      "grad_norm": 4.907177448272705,
      "learning_rate": 3.813288330376705e-05,
      "loss": 1.814,
      "step": 7155
    },
    {
      "epoch": 2.0515,
      "grad_norm": 4.774582862854004,
      "learning_rate": 3.8115291941536345e-05,
      "loss": 1.7041,
      "step": 7160
    },
    {
      "epoch": 2.05175,
      "grad_norm": 6.979622840881348,
      "learning_rate": 3.809769161512726e-05,
      "loss": 1.8475,
      "step": 7165
    },
    {
      "epoch": 2.052,
      "grad_norm": 6.1199188232421875,
      "learning_rate": 3.8080082336569455e-05,
      "loss": 1.635,
      "step": 7170
    },
    {
      "epoch": 2.05225,
      "grad_norm": 5.429759979248047,
      "learning_rate": 3.8062464117898724e-05,
      "loss": 1.7675,
      "step": 7175
    },
    {
      "epoch": 2.0525,
      "grad_norm": 5.052498817443848,
      "learning_rate": 3.8044836971156936e-05,
      "loss": 1.7464,
      "step": 7180
    },
    {
      "epoch": 2.05275,
      "grad_norm": 6.143676280975342,
      "learning_rate": 3.802720090839208e-05,
      "loss": 1.7489,
      "step": 7185
    },
    {
      "epoch": 2.053,
      "grad_norm": 5.804373264312744,
      "learning_rate": 3.800955594165825e-05,
      "loss": 1.7032,
      "step": 7190
    },
    {
      "epoch": 2.05325,
      "grad_norm": 5.014298915863037,
      "learning_rate": 3.7991902083015595e-05,
      "loss": 1.7294,
      "step": 7195
    },
    {
      "epoch": 2.0535,
      "grad_norm": 6.334753036499023,
      "learning_rate": 3.797423934453038e-05,
      "loss": 1.6461,
      "step": 7200
    },
    {
      "epoch": 2.05375,
      "grad_norm": 5.010311126708984,
      "learning_rate": 3.7956567738274904e-05,
      "loss": 1.6419,
      "step": 7205
    },
    {
      "epoch": 2.054,
      "grad_norm": 5.830365180969238,
      "learning_rate": 3.793888727632757e-05,
      "loss": 1.5441,
      "step": 7210
    },
    {
      "epoch": 2.05425,
      "grad_norm": 6.160248756408691,
      "learning_rate": 3.792119797077278e-05,
      "loss": 1.6009,
      "step": 7215
    },
    {
      "epoch": 2.0545,
      "grad_norm": 6.514049530029297,
      "learning_rate": 3.7903499833701006e-05,
      "loss": 1.8831,
      "step": 7220
    },
    {
      "epoch": 2.05475,
      "grad_norm": 5.135915279388428,
      "learning_rate": 3.788579287720878e-05,
      "loss": 1.9481,
      "step": 7225
    },
    {
      "epoch": 2.055,
      "grad_norm": 6.879960536956787,
      "learning_rate": 3.786807711339863e-05,
      "loss": 1.7271,
      "step": 7230
    },
    {
      "epoch": 2.05525,
      "grad_norm": 4.312736511230469,
      "learning_rate": 3.785035255437911e-05,
      "loss": 1.753,
      "step": 7235
    },
    {
      "epoch": 2.0555,
      "grad_norm": 5.570722579956055,
      "learning_rate": 3.783261921226479e-05,
      "loss": 1.6767,
      "step": 7240
    },
    {
      "epoch": 2.05575,
      "grad_norm": 5.203579902648926,
      "learning_rate": 3.7814877099176235e-05,
      "loss": 1.7617,
      "step": 7245
    },
    {
      "epoch": 2.056,
      "grad_norm": 5.409900665283203,
      "learning_rate": 3.779712622724003e-05,
      "loss": 1.6829,
      "step": 7250
    },
    {
      "epoch": 2.05625,
      "grad_norm": 7.515172004699707,
      "learning_rate": 3.7779366608588714e-05,
      "loss": 1.8712,
      "step": 7255
    },
    {
      "epoch": 2.0565,
      "grad_norm": 5.0146002769470215,
      "learning_rate": 3.776159825536082e-05,
      "loss": 1.583,
      "step": 7260
    },
    {
      "epoch": 2.05675,
      "grad_norm": 7.972779750823975,
      "learning_rate": 3.774382117970086e-05,
      "loss": 1.8066,
      "step": 7265
    },
    {
      "epoch": 2.057,
      "grad_norm": 5.267390251159668,
      "learning_rate": 3.7726035393759285e-05,
      "loss": 1.5347,
      "step": 7270
    },
    {
      "epoch": 2.05725,
      "grad_norm": 4.993257999420166,
      "learning_rate": 3.7708240909692516e-05,
      "loss": 1.7696,
      "step": 7275
    },
    {
      "epoch": 2.0575,
      "grad_norm": 5.512138843536377,
      "learning_rate": 3.7690437739662924e-05,
      "loss": 1.7239,
      "step": 7280
    },
    {
      "epoch": 2.05775,
      "grad_norm": 5.896265506744385,
      "learning_rate": 3.76726258958388e-05,
      "loss": 1.5586,
      "step": 7285
    },
    {
      "epoch": 2.058,
      "grad_norm": 5.504922389984131,
      "learning_rate": 3.7654805390394366e-05,
      "loss": 1.5253,
      "step": 7290
    },
    {
      "epoch": 2.05825,
      "grad_norm": 6.6613264083862305,
      "learning_rate": 3.763697623550978e-05,
      "loss": 1.5148,
      "step": 7295
    },
    {
      "epoch": 2.0585,
      "grad_norm": 5.511622428894043,
      "learning_rate": 3.76191384433711e-05,
      "loss": 1.802,
      "step": 7300
    },
    {
      "epoch": 2.05875,
      "grad_norm": 8.28770637512207,
      "learning_rate": 3.7601292026170276e-05,
      "loss": 1.6256,
      "step": 7305
    },
    {
      "epoch": 2.059,
      "grad_norm": 6.759071350097656,
      "learning_rate": 3.7583436996105185e-05,
      "loss": 1.8697,
      "step": 7310
    },
    {
      "epoch": 2.05925,
      "grad_norm": 4.442849159240723,
      "learning_rate": 3.7565573365379545e-05,
      "loss": 1.6235,
      "step": 7315
    },
    {
      "epoch": 2.0595,
      "grad_norm": 6.472750186920166,
      "learning_rate": 3.7547701146203005e-05,
      "loss": 1.8684,
      "step": 7320
    },
    {
      "epoch": 2.05975,
      "grad_norm": 8.078521728515625,
      "learning_rate": 3.752982035079107e-05,
      "loss": 1.7068,
      "step": 7325
    },
    {
      "epoch": 2.06,
      "grad_norm": 6.2683539390563965,
      "learning_rate": 3.751193099136505e-05,
      "loss": 1.896,
      "step": 7330
    },
    {
      "epoch": 2.06025,
      "grad_norm": 6.0253729820251465,
      "learning_rate": 3.749403308015218e-05,
      "loss": 1.7408,
      "step": 7335
    },
    {
      "epoch": 2.0605,
      "grad_norm": 6.746856689453125,
      "learning_rate": 3.747612662938552e-05,
      "loss": 1.9984,
      "step": 7340
    },
    {
      "epoch": 2.06075,
      "grad_norm": 5.824853897094727,
      "learning_rate": 3.7458211651303945e-05,
      "loss": 1.6609,
      "step": 7345
    },
    {
      "epoch": 2.061,
      "grad_norm": 5.536524295806885,
      "learning_rate": 3.7440288158152187e-05,
      "loss": 1.692,
      "step": 7350
    },
    {
      "epoch": 2.06125,
      "grad_norm": 6.105922698974609,
      "learning_rate": 3.742235616218077e-05,
      "loss": 1.7152,
      "step": 7355
    },
    {
      "epoch": 2.0615,
      "grad_norm": 4.799760818481445,
      "learning_rate": 3.7404415675646054e-05,
      "loss": 1.706,
      "step": 7360
    },
    {
      "epoch": 2.06175,
      "grad_norm": 6.449755668640137,
      "learning_rate": 3.7386466710810194e-05,
      "loss": 1.6732,
      "step": 7365
    },
    {
      "epoch": 2.062,
      "grad_norm": 5.753307342529297,
      "learning_rate": 3.7368509279941134e-05,
      "loss": 1.7435,
      "step": 7370
    },
    {
      "epoch": 2.06225,
      "grad_norm": 7.050090789794922,
      "learning_rate": 3.7350543395312606e-05,
      "loss": 1.7805,
      "step": 7375
    },
    {
      "epoch": 2.0625,
      "grad_norm": 5.114118576049805,
      "learning_rate": 3.733256906920413e-05,
      "loss": 1.495,
      "step": 7380
    },
    {
      "epoch": 2.06275,
      "grad_norm": 7.244599342346191,
      "learning_rate": 3.7314586313900976e-05,
      "loss": 1.6176,
      "step": 7385
    },
    {
      "epoch": 2.063,
      "grad_norm": 6.268754482269287,
      "learning_rate": 3.72965951416942e-05,
      "loss": 1.7842,
      "step": 7390
    },
    {
      "epoch": 2.06325,
      "grad_norm": 7.973094940185547,
      "learning_rate": 3.72785955648806e-05,
      "loss": 1.8201,
      "step": 7395
    },
    {
      "epoch": 2.0635,
      "grad_norm": 4.77327823638916,
      "learning_rate": 3.726058759576271e-05,
      "loss": 1.5251,
      "step": 7400
    },
    {
      "epoch": 2.06375,
      "grad_norm": 5.8689069747924805,
      "learning_rate": 3.724257124664881e-05,
      "loss": 1.6308,
      "step": 7405
    },
    {
      "epoch": 2.064,
      "grad_norm": 7.047646522521973,
      "learning_rate": 3.722454652985289e-05,
      "loss": 1.6121,
      "step": 7410
    },
    {
      "epoch": 2.06425,
      "grad_norm": 8.663344383239746,
      "learning_rate": 3.72065134576947e-05,
      "loss": 1.8271,
      "step": 7415
    },
    {
      "epoch": 2.0645,
      "grad_norm": 3.961278200149536,
      "learning_rate": 3.718847204249966e-05,
      "loss": 1.5977,
      "step": 7420
    },
    {
      "epoch": 2.06475,
      "grad_norm": 7.124480724334717,
      "learning_rate": 3.717042229659891e-05,
      "loss": 1.8352,
      "step": 7425
    },
    {
      "epoch": 2.065,
      "grad_norm": 8.177349090576172,
      "learning_rate": 3.715236423232928e-05,
      "loss": 1.8623,
      "step": 7430
    },
    {
      "epoch": 2.06525,
      "grad_norm": 7.467679023742676,
      "learning_rate": 3.7134297862033284e-05,
      "loss": 1.8851,
      "step": 7435
    },
    {
      "epoch": 2.0655,
      "grad_norm": 6.9956769943237305,
      "learning_rate": 3.711622319805913e-05,
      "loss": 1.7051,
      "step": 7440
    },
    {
      "epoch": 2.06575,
      "grad_norm": 6.275454521179199,
      "learning_rate": 3.7098140252760655e-05,
      "loss": 1.7101,
      "step": 7445
    },
    {
      "epoch": 2.066,
      "grad_norm": 6.413116931915283,
      "learning_rate": 3.708004903849741e-05,
      "loss": 1.653,
      "step": 7450
    },
    {
      "epoch": 2.06625,
      "grad_norm": 7.478536128997803,
      "learning_rate": 3.7061949567634534e-05,
      "loss": 1.9263,
      "step": 7455
    },
    {
      "epoch": 2.0665,
      "grad_norm": 6.5057172775268555,
      "learning_rate": 3.704384185254288e-05,
      "loss": 1.7518,
      "step": 7460
    },
    {
      "epoch": 2.06675,
      "grad_norm": 6.967605113983154,
      "learning_rate": 3.7025725905598894e-05,
      "loss": 1.6928,
      "step": 7465
    },
    {
      "epoch": 2.067,
      "grad_norm": 6.014114856719971,
      "learning_rate": 3.700760173918463e-05,
      "loss": 1.7095,
      "step": 7470
    },
    {
      "epoch": 2.06725,
      "grad_norm": 5.761167049407959,
      "learning_rate": 3.698946936568782e-05,
      "loss": 1.5537,
      "step": 7475
    },
    {
      "epoch": 2.0675,
      "grad_norm": 5.748974800109863,
      "learning_rate": 3.697132879750174e-05,
      "loss": 1.5687,
      "step": 7480
    },
    {
      "epoch": 2.06775,
      "grad_norm": 5.327802658081055,
      "learning_rate": 3.6953180047025313e-05,
      "loss": 1.5522,
      "step": 7485
    },
    {
      "epoch": 2.068,
      "grad_norm": 4.093128681182861,
      "learning_rate": 3.693502312666304e-05,
      "loss": 1.7067,
      "step": 7490
    },
    {
      "epoch": 2.06825,
      "grad_norm": 4.9045329093933105,
      "learning_rate": 3.6916858048824996e-05,
      "loss": 1.6288,
      "step": 7495
    },
    {
      "epoch": 2.0685000000000002,
      "grad_norm": 5.133330345153809,
      "learning_rate": 3.689868482592684e-05,
      "loss": 1.5974,
      "step": 7500
    },
    {
      "epoch": 2.0685000000000002,
      "eval_loss": 1.906946063041687,
      "eval_runtime": 5.1541,
      "eval_samples_per_second": 198.675,
      "eval_steps_per_second": 24.834,
      "step": 7500
    },
    {
      "epoch": 2.06875,
      "grad_norm": 4.546999931335449,
      "learning_rate": 3.688050347038981e-05,
      "loss": 1.5035,
      "step": 7505
    },
    {
      "epoch": 2.069,
      "grad_norm": 3.7723913192749023,
      "learning_rate": 3.6862313994640686e-05,
      "loss": 1.4726,
      "step": 7510
    },
    {
      "epoch": 2.06925,
      "grad_norm": 6.203147888183594,
      "learning_rate": 3.68441164111118e-05,
      "loss": 1.5402,
      "step": 7515
    },
    {
      "epoch": 2.0695,
      "grad_norm": 3.7209486961364746,
      "learning_rate": 3.6825910732241026e-05,
      "loss": 1.4594,
      "step": 7520
    },
    {
      "epoch": 2.06975,
      "grad_norm": 3.319016218185425,
      "learning_rate": 3.680769697047178e-05,
      "loss": 1.5364,
      "step": 7525
    },
    {
      "epoch": 2.07,
      "grad_norm": 5.115212917327881,
      "learning_rate": 3.678947513825299e-05,
      "loss": 1.5994,
      "step": 7530
    },
    {
      "epoch": 2.07025,
      "grad_norm": 4.943305015563965,
      "learning_rate": 3.677124524803912e-05,
      "loss": 1.3639,
      "step": 7535
    },
    {
      "epoch": 2.0705,
      "grad_norm": 3.929518461227417,
      "learning_rate": 3.675300731229012e-05,
      "loss": 1.512,
      "step": 7540
    },
    {
      "epoch": 2.07075,
      "grad_norm": 4.637051582336426,
      "learning_rate": 3.673476134347144e-05,
      "loss": 1.4569,
      "step": 7545
    },
    {
      "epoch": 2.071,
      "grad_norm": 4.479070663452148,
      "learning_rate": 3.671650735405404e-05,
      "loss": 1.3292,
      "step": 7550
    },
    {
      "epoch": 2.07125,
      "grad_norm": 4.190317630767822,
      "learning_rate": 3.6698245356514335e-05,
      "loss": 1.418,
      "step": 7555
    },
    {
      "epoch": 2.0715,
      "grad_norm": 4.763996124267578,
      "learning_rate": 3.667997536333424e-05,
      "loss": 1.5159,
      "step": 7560
    },
    {
      "epoch": 2.07175,
      "grad_norm": 5.388274192810059,
      "learning_rate": 3.666169738700113e-05,
      "loss": 1.7761,
      "step": 7565
    },
    {
      "epoch": 2.072,
      "grad_norm": 4.298276424407959,
      "learning_rate": 3.6643411440007804e-05,
      "loss": 1.5865,
      "step": 7570
    },
    {
      "epoch": 2.07225,
      "grad_norm": 4.422248363494873,
      "learning_rate": 3.662511753485256e-05,
      "loss": 1.4848,
      "step": 7575
    },
    {
      "epoch": 2.0725,
      "grad_norm": 4.595855712890625,
      "learning_rate": 3.66068156840391e-05,
      "loss": 1.3222,
      "step": 7580
    },
    {
      "epoch": 2.07275,
      "grad_norm": 4.9628777503967285,
      "learning_rate": 3.6588505900076553e-05,
      "loss": 1.557,
      "step": 7585
    },
    {
      "epoch": 2.073,
      "grad_norm": 4.364582538604736,
      "learning_rate": 3.65701881954795e-05,
      "loss": 1.5152,
      "step": 7590
    },
    {
      "epoch": 2.07325,
      "grad_norm": 5.68834114074707,
      "learning_rate": 3.6551862582767925e-05,
      "loss": 1.4722,
      "step": 7595
    },
    {
      "epoch": 2.0735,
      "grad_norm": 5.137077808380127,
      "learning_rate": 3.65335290744672e-05,
      "loss": 1.32,
      "step": 7600
    },
    {
      "epoch": 2.07375,
      "grad_norm": 4.096175670623779,
      "learning_rate": 3.65151876831081e-05,
      "loss": 1.5789,
      "step": 7605
    },
    {
      "epoch": 2.074,
      "grad_norm": 5.129400253295898,
      "learning_rate": 3.649683842122681e-05,
      "loss": 1.428,
      "step": 7610
    },
    {
      "epoch": 2.07425,
      "grad_norm": 4.37814998626709,
      "learning_rate": 3.6478481301364864e-05,
      "loss": 1.4739,
      "step": 7615
    },
    {
      "epoch": 2.0745,
      "grad_norm": 5.9733452796936035,
      "learning_rate": 3.6460116336069176e-05,
      "loss": 1.5976,
      "step": 7620
    },
    {
      "epoch": 2.07475,
      "grad_norm": 3.5537233352661133,
      "learning_rate": 3.644174353789204e-05,
      "loss": 1.3356,
      "step": 7625
    },
    {
      "epoch": 2.075,
      "grad_norm": 4.013000965118408,
      "learning_rate": 3.642336291939109e-05,
      "loss": 1.3159,
      "step": 7630
    },
    {
      "epoch": 2.07525,
      "grad_norm": 5.395144939422607,
      "learning_rate": 3.64049744931293e-05,
      "loss": 1.5341,
      "step": 7635
    },
    {
      "epoch": 2.0755,
      "grad_norm": 4.614659786224365,
      "learning_rate": 3.6386578271674984e-05,
      "loss": 1.5904,
      "step": 7640
    },
    {
      "epoch": 2.07575,
      "grad_norm": 5.317315578460693,
      "learning_rate": 3.636817426760178e-05,
      "loss": 1.5133,
      "step": 7645
    },
    {
      "epoch": 2.076,
      "grad_norm": 5.428571701049805,
      "learning_rate": 3.634976249348867e-05,
      "loss": 1.6337,
      "step": 7650
    },
    {
      "epoch": 2.07625,
      "grad_norm": 4.628364562988281,
      "learning_rate": 3.633134296191992e-05,
      "loss": 1.4931,
      "step": 7655
    },
    {
      "epoch": 2.0765,
      "grad_norm": 4.441822052001953,
      "learning_rate": 3.631291568548509e-05,
      "loss": 1.425,
      "step": 7660
    },
    {
      "epoch": 2.07675,
      "grad_norm": 4.752884864807129,
      "learning_rate": 3.629448067677908e-05,
      "loss": 1.4439,
      "step": 7665
    },
    {
      "epoch": 2.077,
      "grad_norm": 4.87833833694458,
      "learning_rate": 3.627603794840201e-05,
      "loss": 1.3581,
      "step": 7670
    },
    {
      "epoch": 2.07725,
      "grad_norm": 4.463069438934326,
      "learning_rate": 3.6257587512959346e-05,
      "loss": 1.4453,
      "step": 7675
    },
    {
      "epoch": 2.0775,
      "grad_norm": 5.092744827270508,
      "learning_rate": 3.623912938306176e-05,
      "loss": 1.5121,
      "step": 7680
    },
    {
      "epoch": 2.07775,
      "grad_norm": 4.316360950469971,
      "learning_rate": 3.622066357132522e-05,
      "loss": 1.3864,
      "step": 7685
    },
    {
      "epoch": 2.078,
      "grad_norm": 4.275850772857666,
      "learning_rate": 3.6202190090370944e-05,
      "loss": 1.4699,
      "step": 7690
    },
    {
      "epoch": 2.07825,
      "grad_norm": 4.097822666168213,
      "learning_rate": 3.618370895282536e-05,
      "loss": 1.3745,
      "step": 7695
    },
    {
      "epoch": 2.0785,
      "grad_norm": 5.121838569641113,
      "learning_rate": 3.616522017132017e-05,
      "loss": 1.3819,
      "step": 7700
    },
    {
      "epoch": 2.07875,
      "grad_norm": 4.872469425201416,
      "learning_rate": 3.614672375849227e-05,
      "loss": 1.401,
      "step": 7705
    },
    {
      "epoch": 2.079,
      "grad_norm": 6.36907434463501,
      "learning_rate": 3.6128219726983784e-05,
      "loss": 1.44,
      "step": 7710
    },
    {
      "epoch": 2.07925,
      "grad_norm": 5.270010471343994,
      "learning_rate": 3.610970808944205e-05,
      "loss": 1.5225,
      "step": 7715
    },
    {
      "epoch": 2.0795,
      "grad_norm": 4.3161516189575195,
      "learning_rate": 3.6091188858519607e-05,
      "loss": 1.406,
      "step": 7720
    },
    {
      "epoch": 2.07975,
      "grad_norm": 6.42068338394165,
      "learning_rate": 3.6072662046874146e-05,
      "loss": 1.4928,
      "step": 7725
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.6792705059051514,
      "learning_rate": 3.6054127667168596e-05,
      "loss": 1.4271,
      "step": 7730
    },
    {
      "epoch": 2.08025,
      "grad_norm": 4.356193542480469,
      "learning_rate": 3.603558573207101e-05,
      "loss": 1.5439,
      "step": 7735
    },
    {
      "epoch": 2.0805,
      "grad_norm": 4.598501205444336,
      "learning_rate": 3.601703625425464e-05,
      "loss": 1.4334,
      "step": 7740
    },
    {
      "epoch": 2.08075,
      "grad_norm": 6.5858612060546875,
      "learning_rate": 3.599847924639788e-05,
      "loss": 1.5215,
      "step": 7745
    },
    {
      "epoch": 2.081,
      "grad_norm": 4.000481128692627,
      "learning_rate": 3.597991472118426e-05,
      "loss": 1.4976,
      "step": 7750
    },
    {
      "epoch": 2.08125,
      "grad_norm": 4.619418621063232,
      "learning_rate": 3.596134269130247e-05,
      "loss": 1.5326,
      "step": 7755
    },
    {
      "epoch": 2.0815,
      "grad_norm": 4.212691307067871,
      "learning_rate": 3.5942763169446295e-05,
      "loss": 1.4765,
      "step": 7760
    },
    {
      "epoch": 2.08175,
      "grad_norm": 3.7920782566070557,
      "learning_rate": 3.592417616831469e-05,
      "loss": 1.4688,
      "step": 7765
    },
    {
      "epoch": 2.082,
      "grad_norm": 4.3278021812438965,
      "learning_rate": 3.590558170061168e-05,
      "loss": 1.5302,
      "step": 7770
    },
    {
      "epoch": 2.08225,
      "grad_norm": 4.384753227233887,
      "learning_rate": 3.58869797790464e-05,
      "loss": 1.4452,
      "step": 7775
    },
    {
      "epoch": 2.0825,
      "grad_norm": 4.546833515167236,
      "learning_rate": 3.586837041633312e-05,
      "loss": 1.514,
      "step": 7780
    },
    {
      "epoch": 2.08275,
      "grad_norm": 3.9449450969696045,
      "learning_rate": 3.5849753625191124e-05,
      "loss": 1.4533,
      "step": 7785
    },
    {
      "epoch": 2.083,
      "grad_norm": 4.542697906494141,
      "learning_rate": 3.5831129418344845e-05,
      "loss": 1.4207,
      "step": 7790
    },
    {
      "epoch": 2.08325,
      "grad_norm": 5.533426284790039,
      "learning_rate": 3.5812497808523734e-05,
      "loss": 1.4154,
      "step": 7795
    },
    {
      "epoch": 2.0835,
      "grad_norm": 6.216200351715088,
      "learning_rate": 3.579385880846232e-05,
      "loss": 1.6124,
      "step": 7800
    },
    {
      "epoch": 2.08375,
      "grad_norm": 3.9940991401672363,
      "learning_rate": 3.5775212430900204e-05,
      "loss": 1.3477,
      "step": 7805
    },
    {
      "epoch": 2.084,
      "grad_norm": 5.475193977355957,
      "learning_rate": 3.5756558688581985e-05,
      "loss": 1.2927,
      "step": 7810
    },
    {
      "epoch": 2.08425,
      "grad_norm": 3.5233962535858154,
      "learning_rate": 3.5737897594257344e-05,
      "loss": 1.2131,
      "step": 7815
    },
    {
      "epoch": 2.0845,
      "grad_norm": 6.453643321990967,
      "learning_rate": 3.571922916068094e-05,
      "loss": 1.5038,
      "step": 7820
    },
    {
      "epoch": 2.08475,
      "grad_norm": 3.831521511077881,
      "learning_rate": 3.570055340061248e-05,
      "loss": 1.2732,
      "step": 7825
    },
    {
      "epoch": 2.085,
      "grad_norm": 5.308055400848389,
      "learning_rate": 3.568187032681667e-05,
      "loss": 1.2724,
      "step": 7830
    },
    {
      "epoch": 2.08525,
      "grad_norm": 4.903427600860596,
      "learning_rate": 3.566317995206322e-05,
      "loss": 1.3094,
      "step": 7835
    },
    {
      "epoch": 2.0855,
      "grad_norm": 4.248048782348633,
      "learning_rate": 3.564448228912682e-05,
      "loss": 1.2293,
      "step": 7840
    },
    {
      "epoch": 2.08575,
      "grad_norm": 4.391646862030029,
      "learning_rate": 3.5625777350787146e-05,
      "loss": 1.3485,
      "step": 7845
    },
    {
      "epoch": 2.086,
      "grad_norm": 4.765039443969727,
      "learning_rate": 3.5607065149828843e-05,
      "loss": 1.4675,
      "step": 7850
    },
    {
      "epoch": 2.08625,
      "grad_norm": 4.596372127532959,
      "learning_rate": 3.5588345699041535e-05,
      "loss": 1.238,
      "step": 7855
    },
    {
      "epoch": 2.0865,
      "grad_norm": 4.36716365814209,
      "learning_rate": 3.556961901121978e-05,
      "loss": 1.2665,
      "step": 7860
    },
    {
      "epoch": 2.08675,
      "grad_norm": 4.382824897766113,
      "learning_rate": 3.55508850991631e-05,
      "loss": 1.2917,
      "step": 7865
    },
    {
      "epoch": 2.087,
      "grad_norm": 6.325425148010254,
      "learning_rate": 3.553214397567595e-05,
      "loss": 1.4605,
      "step": 7870
    },
    {
      "epoch": 2.08725,
      "grad_norm": 4.77617073059082,
      "learning_rate": 3.5513395653567685e-05,
      "loss": 1.3548,
      "step": 7875
    },
    {
      "epoch": 2.0875,
      "grad_norm": 5.6082587242126465,
      "learning_rate": 3.549464014565265e-05,
      "loss": 1.3849,
      "step": 7880
    },
    {
      "epoch": 2.0877499999999998,
      "grad_norm": 5.3149027824401855,
      "learning_rate": 3.547587746475002e-05,
      "loss": 1.2663,
      "step": 7885
    },
    {
      "epoch": 2.088,
      "grad_norm": 4.9776177406311035,
      "learning_rate": 3.545710762368392e-05,
      "loss": 1.2853,
      "step": 7890
    },
    {
      "epoch": 2.08825,
      "grad_norm": 4.650234222412109,
      "learning_rate": 3.5438330635283375e-05,
      "loss": 1.3118,
      "step": 7895
    },
    {
      "epoch": 2.0885,
      "grad_norm": 5.194924831390381,
      "learning_rate": 3.5419546512382266e-05,
      "loss": 1.2186,
      "step": 7900
    },
    {
      "epoch": 2.08875,
      "grad_norm": 4.536736488342285,
      "learning_rate": 3.540075526781936e-05,
      "loss": 1.4155,
      "step": 7905
    },
    {
      "epoch": 2.089,
      "grad_norm": 4.479315280914307,
      "learning_rate": 3.5381956914438305e-05,
      "loss": 1.3699,
      "step": 7910
    },
    {
      "epoch": 2.08925,
      "grad_norm": 5.227468490600586,
      "learning_rate": 3.53631514650876e-05,
      "loss": 1.3303,
      "step": 7915
    },
    {
      "epoch": 2.0895,
      "grad_norm": 5.540550231933594,
      "learning_rate": 3.534433893262058e-05,
      "loss": 1.3408,
      "step": 7920
    },
    {
      "epoch": 2.08975,
      "grad_norm": 5.318605899810791,
      "learning_rate": 3.532551932989544e-05,
      "loss": 1.2098,
      "step": 7925
    },
    {
      "epoch": 2.09,
      "grad_norm": 5.306321620941162,
      "learning_rate": 3.530669266977521e-05,
      "loss": 1.3831,
      "step": 7930
    },
    {
      "epoch": 2.09025,
      "grad_norm": 5.114377975463867,
      "learning_rate": 3.528785896512772e-05,
      "loss": 1.3294,
      "step": 7935
    },
    {
      "epoch": 2.0905,
      "grad_norm": 5.228114128112793,
      "learning_rate": 3.526901822882564e-05,
      "loss": 1.2002,
      "step": 7940
    },
    {
      "epoch": 2.09075,
      "grad_norm": 5.214347839355469,
      "learning_rate": 3.525017047374643e-05,
      "loss": 1.1089,
      "step": 7945
    },
    {
      "epoch": 2.091,
      "grad_norm": 4.381906986236572,
      "learning_rate": 3.523131571277235e-05,
      "loss": 1.2999,
      "step": 7950
    },
    {
      "epoch": 2.09125,
      "grad_norm": 4.902562141418457,
      "learning_rate": 3.521245395879047e-05,
      "loss": 1.3241,
      "step": 7955
    },
    {
      "epoch": 2.0915,
      "grad_norm": 5.499211311340332,
      "learning_rate": 3.519358522469259e-05,
      "loss": 1.5008,
      "step": 7960
    },
    {
      "epoch": 2.09175,
      "grad_norm": 4.187617778778076,
      "learning_rate": 3.5174709523375334e-05,
      "loss": 1.5364,
      "step": 7965
    },
    {
      "epoch": 2.092,
      "grad_norm": 4.250159740447998,
      "learning_rate": 3.515582686774007e-05,
      "loss": 1.2916,
      "step": 7970
    },
    {
      "epoch": 2.09225,
      "grad_norm": 4.536859512329102,
      "learning_rate": 3.513693727069289e-05,
      "loss": 1.4656,
      "step": 7975
    },
    {
      "epoch": 2.0925,
      "grad_norm": 4.895967483520508,
      "learning_rate": 3.511804074514468e-05,
      "loss": 1.302,
      "step": 7980
    },
    {
      "epoch": 2.09275,
      "grad_norm": 4.24763298034668,
      "learning_rate": 3.509913730401103e-05,
      "loss": 1.4378,
      "step": 7985
    },
    {
      "epoch": 2.093,
      "grad_norm": 5.619935989379883,
      "learning_rate": 3.508022696021226e-05,
      "loss": 1.3358,
      "step": 7990
    },
    {
      "epoch": 2.09325,
      "grad_norm": 4.079983234405518,
      "learning_rate": 3.5061309726673415e-05,
      "loss": 1.4464,
      "step": 7995
    },
    {
      "epoch": 2.0935,
      "grad_norm": 5.604879856109619,
      "learning_rate": 3.504238561632424e-05,
      "loss": 1.4942,
      "step": 8000
    },
    {
      "epoch": 2.0935,
      "eval_loss": 2.001856803894043,
      "eval_runtime": 5.2931,
      "eval_samples_per_second": 193.46,
      "eval_steps_per_second": 24.183,
      "step": 8000
    },
    {
      "epoch": 2.09375,
      "grad_norm": 5.802464008331299,
      "learning_rate": 3.502345464209919e-05,
      "loss": 1.5957,
      "step": 8005
    },
    {
      "epoch": 2.094,
      "grad_norm": 4.293885707855225,
      "learning_rate": 3.500451681693741e-05,
      "loss": 1.3196,
      "step": 8010
    },
    {
      "epoch": 2.09425,
      "grad_norm": 5.78262186050415,
      "learning_rate": 3.498557215378272e-05,
      "loss": 1.3155,
      "step": 8015
    },
    {
      "epoch": 2.0945,
      "grad_norm": 3.779815435409546,
      "learning_rate": 3.496662066558363e-05,
      "loss": 1.2503,
      "step": 8020
    },
    {
      "epoch": 2.09475,
      "grad_norm": 5.129040241241455,
      "learning_rate": 3.4947662365293286e-05,
      "loss": 1.4355,
      "step": 8025
    },
    {
      "epoch": 2.095,
      "grad_norm": 5.559129238128662,
      "learning_rate": 3.4928697265869515e-05,
      "loss": 1.4481,
      "step": 8030
    },
    {
      "epoch": 2.09525,
      "grad_norm": 5.170417308807373,
      "learning_rate": 3.4909725380274795e-05,
      "loss": 1.3887,
      "step": 8035
    },
    {
      "epoch": 2.0955,
      "grad_norm": 4.675784111022949,
      "learning_rate": 3.489074672147621e-05,
      "loss": 1.479,
      "step": 8040
    },
    {
      "epoch": 2.09575,
      "grad_norm": 5.296899795532227,
      "learning_rate": 3.4871761302445515e-05,
      "loss": 1.4845,
      "step": 8045
    },
    {
      "epoch": 2.096,
      "grad_norm": 5.088869571685791,
      "learning_rate": 3.485276913615905e-05,
      "loss": 1.4815,
      "step": 8050
    },
    {
      "epoch": 2.09625,
      "grad_norm": 4.57219123840332,
      "learning_rate": 3.483377023559777e-05,
      "loss": 1.4174,
      "step": 8055
    },
    {
      "epoch": 2.0965,
      "grad_norm": 3.965566396713257,
      "learning_rate": 3.4814764613747286e-05,
      "loss": 1.3731,
      "step": 8060
    },
    {
      "epoch": 2.09675,
      "grad_norm": 4.865204334259033,
      "learning_rate": 3.479575228359772e-05,
      "loss": 1.3937,
      "step": 8065
    },
    {
      "epoch": 2.097,
      "grad_norm": 5.205683708190918,
      "learning_rate": 3.4776733258143854e-05,
      "loss": 1.329,
      "step": 8070
    },
    {
      "epoch": 2.09725,
      "grad_norm": 4.648715496063232,
      "learning_rate": 3.4757707550384974e-05,
      "loss": 1.2998,
      "step": 8075
    },
    {
      "epoch": 2.0975,
      "grad_norm": 11.506444931030273,
      "learning_rate": 3.473867517332501e-05,
      "loss": 1.4433,
      "step": 8080
    },
    {
      "epoch": 2.09775,
      "grad_norm": 6.899975299835205,
      "learning_rate": 3.471963613997239e-05,
      "loss": 1.3827,
      "step": 8085
    },
    {
      "epoch": 2.098,
      "grad_norm": 5.153929710388184,
      "learning_rate": 3.470059046334011e-05,
      "loss": 1.455,
      "step": 8090
    },
    {
      "epoch": 2.09825,
      "grad_norm": 4.661798000335693,
      "learning_rate": 3.468153815644574e-05,
      "loss": 1.2809,
      "step": 8095
    },
    {
      "epoch": 2.0985,
      "grad_norm": 4.956273555755615,
      "learning_rate": 3.4662479232311306e-05,
      "loss": 1.4113,
      "step": 8100
    },
    {
      "epoch": 2.09875,
      "grad_norm": 4.580479621887207,
      "learning_rate": 3.464341370396344e-05,
      "loss": 1.4438,
      "step": 8105
    },
    {
      "epoch": 2.099,
      "grad_norm": 3.6577465534210205,
      "learning_rate": 3.4624341584433244e-05,
      "loss": 1.3097,
      "step": 8110
    },
    {
      "epoch": 2.09925,
      "grad_norm": 7.223110675811768,
      "learning_rate": 3.460526288675632e-05,
      "loss": 1.5149,
      "step": 8115
    },
    {
      "epoch": 2.0995,
      "grad_norm": 3.4895405769348145,
      "learning_rate": 3.458617762397279e-05,
      "loss": 1.3541,
      "step": 8120
    },
    {
      "epoch": 2.0997500000000002,
      "grad_norm": 3.7604756355285645,
      "learning_rate": 3.456708580912725e-05,
      "loss": 1.2754,
      "step": 8125
    },
    {
      "epoch": 2.1,
      "grad_norm": 4.628238677978516,
      "learning_rate": 3.454798745526876e-05,
      "loss": 1.4878,
      "step": 8130
    },
    {
      "epoch": 2.10025,
      "grad_norm": 5.307082653045654,
      "learning_rate": 3.4528882575450886e-05,
      "loss": 1.5248,
      "step": 8135
    },
    {
      "epoch": 2.1005,
      "grad_norm": 4.541940689086914,
      "learning_rate": 3.450977118273162e-05,
      "loss": 1.3527,
      "step": 8140
    },
    {
      "epoch": 2.10075,
      "grad_norm": 4.983758449554443,
      "learning_rate": 3.4490653290173426e-05,
      "loss": 1.3611,
      "step": 8145
    },
    {
      "epoch": 2.101,
      "grad_norm": 7.04695463180542,
      "learning_rate": 3.447152891084319e-05,
      "loss": 1.4636,
      "step": 8150
    },
    {
      "epoch": 2.10125,
      "grad_norm": 7.403731822967529,
      "learning_rate": 3.4452398057812266e-05,
      "loss": 1.5515,
      "step": 8155
    },
    {
      "epoch": 2.1015,
      "grad_norm": 3.8405072689056396,
      "learning_rate": 3.4433260744156396e-05,
      "loss": 1.2797,
      "step": 8160
    },
    {
      "epoch": 2.10175,
      "grad_norm": 4.1195831298828125,
      "learning_rate": 3.441411698295576e-05,
      "loss": 1.3444,
      "step": 8165
    },
    {
      "epoch": 2.102,
      "grad_norm": 5.145584583282471,
      "learning_rate": 3.439496678729493e-05,
      "loss": 1.2859,
      "step": 8170
    },
    {
      "epoch": 2.10225,
      "grad_norm": 4.523098468780518,
      "learning_rate": 3.437581017026289e-05,
      "loss": 1.3584,
      "step": 8175
    },
    {
      "epoch": 2.1025,
      "grad_norm": 3.8840548992156982,
      "learning_rate": 3.435664714495301e-05,
      "loss": 1.3103,
      "step": 8180
    },
    {
      "epoch": 2.10275,
      "grad_norm": 5.160536766052246,
      "learning_rate": 3.433747772446304e-05,
      "loss": 1.288,
      "step": 8185
    },
    {
      "epoch": 2.103,
      "grad_norm": 4.655435562133789,
      "learning_rate": 3.4318301921895084e-05,
      "loss": 1.4623,
      "step": 8190
    },
    {
      "epoch": 2.10325,
      "grad_norm": 4.516211032867432,
      "learning_rate": 3.429911975035563e-05,
      "loss": 1.1415,
      "step": 8195
    },
    {
      "epoch": 2.1035,
      "grad_norm": 6.1041035652160645,
      "learning_rate": 3.427993122295552e-05,
      "loss": 1.4022,
      "step": 8200
    },
    {
      "epoch": 2.10375,
      "grad_norm": 3.5208652019500732,
      "learning_rate": 3.426073635280992e-05,
      "loss": 1.1124,
      "step": 8205
    },
    {
      "epoch": 2.104,
      "grad_norm": 4.175789833068848,
      "learning_rate": 3.424153515303835e-05,
      "loss": 1.4901,
      "step": 8210
    },
    {
      "epoch": 2.10425,
      "grad_norm": 6.2131028175354,
      "learning_rate": 3.422232763676464e-05,
      "loss": 1.4557,
      "step": 8215
    },
    {
      "epoch": 2.1045,
      "grad_norm": 4.307847023010254,
      "learning_rate": 3.4203113817116957e-05,
      "loss": 1.3546,
      "step": 8220
    },
    {
      "epoch": 2.10475,
      "grad_norm": 5.2805681228637695,
      "learning_rate": 3.418389370722775e-05,
      "loss": 1.2455,
      "step": 8225
    },
    {
      "epoch": 2.105,
      "grad_norm": 4.578540325164795,
      "learning_rate": 3.41646673202338e-05,
      "loss": 1.3785,
      "step": 8230
    },
    {
      "epoch": 2.10525,
      "grad_norm": 6.328821659088135,
      "learning_rate": 3.414543466927616e-05,
      "loss": 1.371,
      "step": 8235
    },
    {
      "epoch": 2.1055,
      "grad_norm": 5.102791786193848,
      "learning_rate": 3.412619576750014e-05,
      "loss": 1.2771,
      "step": 8240
    },
    {
      "epoch": 2.10575,
      "grad_norm": 7.285670757293701,
      "learning_rate": 3.410695062805539e-05,
      "loss": 1.3245,
      "step": 8245
    },
    {
      "epoch": 2.106,
      "grad_norm": 5.073956489562988,
      "learning_rate": 3.4087699264095745e-05,
      "loss": 1.2333,
      "step": 8250
    },
    {
      "epoch": 2.10625,
      "grad_norm": 4.459643840789795,
      "learning_rate": 3.4068441688779355e-05,
      "loss": 1.3063,
      "step": 8255
    },
    {
      "epoch": 2.1065,
      "grad_norm": 6.174842834472656,
      "learning_rate": 3.4049177915268576e-05,
      "loss": 1.3644,
      "step": 8260
    },
    {
      "epoch": 2.10675,
      "grad_norm": 5.192503452301025,
      "learning_rate": 3.4029907956730026e-05,
      "loss": 1.3566,
      "step": 8265
    },
    {
      "epoch": 2.107,
      "grad_norm": 4.669296741485596,
      "learning_rate": 3.4010631826334526e-05,
      "loss": 1.4128,
      "step": 8270
    },
    {
      "epoch": 2.10725,
      "grad_norm": 5.118370532989502,
      "learning_rate": 3.399134953725714e-05,
      "loss": 1.1682,
      "step": 8275
    },
    {
      "epoch": 2.1075,
      "grad_norm": 4.555074691772461,
      "learning_rate": 3.397206110267713e-05,
      "loss": 1.3687,
      "step": 8280
    },
    {
      "epoch": 2.10775,
      "grad_norm": 5.2186737060546875,
      "learning_rate": 3.3952766535777956e-05,
      "loss": 1.231,
      "step": 8285
    },
    {
      "epoch": 2.108,
      "grad_norm": 4.789300441741943,
      "learning_rate": 3.3933465849747275e-05,
      "loss": 1.2972,
      "step": 8290
    },
    {
      "epoch": 2.10825,
      "grad_norm": 5.596569538116455,
      "learning_rate": 3.3914159057776926e-05,
      "loss": 1.3313,
      "step": 8295
    },
    {
      "epoch": 2.1085,
      "grad_norm": 4.568972110748291,
      "learning_rate": 3.389484617306292e-05,
      "loss": 1.2209,
      "step": 8300
    },
    {
      "epoch": 2.10875,
      "grad_norm": 5.185361385345459,
      "learning_rate": 3.387552720880542e-05,
      "loss": 1.2501,
      "step": 8305
    },
    {
      "epoch": 2.109,
      "grad_norm": 3.963104486465454,
      "learning_rate": 3.385620217820877e-05,
      "loss": 1.3624,
      "step": 8310
    },
    {
      "epoch": 2.10925,
      "grad_norm": 4.277282238006592,
      "learning_rate": 3.383687109448143e-05,
      "loss": 1.264,
      "step": 8315
    },
    {
      "epoch": 2.1095,
      "grad_norm": 5.048586368560791,
      "learning_rate": 3.381753397083604e-05,
      "loss": 1.1598,
      "step": 8320
    },
    {
      "epoch": 2.10975,
      "grad_norm": 3.6794257164001465,
      "learning_rate": 3.379819082048931e-05,
      "loss": 1.1372,
      "step": 8325
    },
    {
      "epoch": 2.11,
      "grad_norm": 5.0184502601623535,
      "learning_rate": 3.377884165666212e-05,
      "loss": 1.3281,
      "step": 8330
    },
    {
      "epoch": 2.11025,
      "grad_norm": 5.27329683303833,
      "learning_rate": 3.3759486492579436e-05,
      "loss": 1.2528,
      "step": 8335
    },
    {
      "epoch": 2.1105,
      "grad_norm": 4.7169365882873535,
      "learning_rate": 3.3740125341470336e-05,
      "loss": 1.2938,
      "step": 8340
    },
    {
      "epoch": 2.11075,
      "grad_norm": 5.220252990722656,
      "learning_rate": 3.3720758216567984e-05,
      "loss": 1.5549,
      "step": 8345
    },
    {
      "epoch": 2.111,
      "grad_norm": 4.648995876312256,
      "learning_rate": 3.3701385131109616e-05,
      "loss": 1.3518,
      "step": 8350
    },
    {
      "epoch": 2.11125,
      "grad_norm": 5.83317232131958,
      "learning_rate": 3.368200609833656e-05,
      "loss": 1.5693,
      "step": 8355
    },
    {
      "epoch": 2.1115,
      "grad_norm": 6.114229202270508,
      "learning_rate": 3.3662621131494204e-05,
      "loss": 1.3948,
      "step": 8360
    },
    {
      "epoch": 2.11175,
      "grad_norm": 5.581258296966553,
      "learning_rate": 3.364323024383198e-05,
      "loss": 1.3425,
      "step": 8365
    },
    {
      "epoch": 2.112,
      "grad_norm": 4.807028293609619,
      "learning_rate": 3.36238334486034e-05,
      "loss": 1.4383,
      "step": 8370
    },
    {
      "epoch": 2.11225,
      "grad_norm": 4.501047134399414,
      "learning_rate": 3.360443075906597e-05,
      "loss": 1.3394,
      "step": 8375
    },
    {
      "epoch": 2.1125,
      "grad_norm": 4.04604434967041,
      "learning_rate": 3.358502218848125e-05,
      "loss": 1.6371,
      "step": 8380
    },
    {
      "epoch": 2.11275,
      "grad_norm": 4.65274715423584,
      "learning_rate": 3.3565607750114816e-05,
      "loss": 1.3485,
      "step": 8385
    },
    {
      "epoch": 2.113,
      "grad_norm": 4.726500034332275,
      "learning_rate": 3.3546187457236244e-05,
      "loss": 1.3614,
      "step": 8390
    },
    {
      "epoch": 2.11325,
      "grad_norm": 4.293733596801758,
      "learning_rate": 3.352676132311914e-05,
      "loss": 1.3683,
      "step": 8395
    },
    {
      "epoch": 2.1135,
      "grad_norm": 4.077037334442139,
      "learning_rate": 3.350732936104108e-05,
      "loss": 1.3218,
      "step": 8400
    },
    {
      "epoch": 2.11375,
      "grad_norm": 5.292092800140381,
      "learning_rate": 3.3487891584283615e-05,
      "loss": 1.3511,
      "step": 8405
    },
    {
      "epoch": 2.114,
      "grad_norm": 4.1769843101501465,
      "learning_rate": 3.346844800613229e-05,
      "loss": 1.2928,
      "step": 8410
    },
    {
      "epoch": 2.11425,
      "grad_norm": 6.883411407470703,
      "learning_rate": 3.34489986398766e-05,
      "loss": 1.3521,
      "step": 8415
    },
    {
      "epoch": 2.1145,
      "grad_norm": 4.4180707931518555,
      "learning_rate": 3.342954349881001e-05,
      "loss": 1.5459,
      "step": 8420
    },
    {
      "epoch": 2.11475,
      "grad_norm": 5.4186625480651855,
      "learning_rate": 3.341008259622993e-05,
      "loss": 1.3324,
      "step": 8425
    },
    {
      "epoch": 2.115,
      "grad_norm": 7.197362422943115,
      "learning_rate": 3.33906159454377e-05,
      "loss": 1.5002,
      "step": 8430
    },
    {
      "epoch": 2.11525,
      "grad_norm": 6.5193376541137695,
      "learning_rate": 3.337114355973858e-05,
      "loss": 1.5123,
      "step": 8435
    },
    {
      "epoch": 2.1155,
      "grad_norm": 4.3797502517700195,
      "learning_rate": 3.335166545244178e-05,
      "loss": 1.1366,
      "step": 8440
    },
    {
      "epoch": 2.11575,
      "grad_norm": 5.504974842071533,
      "learning_rate": 3.333218163686039e-05,
      "loss": 1.3354,
      "step": 8445
    },
    {
      "epoch": 2.116,
      "grad_norm": 4.552544116973877,
      "learning_rate": 3.3312692126311425e-05,
      "loss": 1.4786,
      "step": 8450
    },
    {
      "epoch": 2.11625,
      "grad_norm": 5.420443534851074,
      "learning_rate": 3.3293196934115765e-05,
      "loss": 1.3507,
      "step": 8455
    },
    {
      "epoch": 2.1165,
      "grad_norm": 5.418705940246582,
      "learning_rate": 3.327369607359821e-05,
      "loss": 1.3866,
      "step": 8460
    },
    {
      "epoch": 2.11675,
      "grad_norm": 4.236335754394531,
      "learning_rate": 3.3254189558087404e-05,
      "loss": 1.3426,
      "step": 8465
    },
    {
      "epoch": 2.117,
      "grad_norm": 4.478068828582764,
      "learning_rate": 3.3234677400915865e-05,
      "loss": 1.3717,
      "step": 8470
    },
    {
      "epoch": 2.11725,
      "grad_norm": 4.27915620803833,
      "learning_rate": 3.3215159615419975e-05,
      "loss": 1.4157,
      "step": 8475
    },
    {
      "epoch": 2.1175,
      "grad_norm": 4.017310619354248,
      "learning_rate": 3.319563621493994e-05,
      "loss": 1.306,
      "step": 8480
    },
    {
      "epoch": 2.11775,
      "grad_norm": 4.645217418670654,
      "learning_rate": 3.317610721281985e-05,
      "loss": 1.2509,
      "step": 8485
    },
    {
      "epoch": 2.118,
      "grad_norm": 5.633517742156982,
      "learning_rate": 3.3156572622407565e-05,
      "loss": 1.3019,
      "step": 8490
    },
    {
      "epoch": 2.11825,
      "grad_norm": 5.013377666473389,
      "learning_rate": 3.31370324570548e-05,
      "loss": 1.3514,
      "step": 8495
    },
    {
      "epoch": 2.1185,
      "grad_norm": 4.607456684112549,
      "learning_rate": 3.311748673011709e-05,
      "loss": 1.1633,
      "step": 8500
    },
    {
      "epoch": 2.1185,
      "eval_loss": 2.0223751068115234,
      "eval_runtime": 5.6346,
      "eval_samples_per_second": 181.735,
      "eval_steps_per_second": 22.717,
      "step": 8500
    },
    {
      "epoch": 2.11875,
      "grad_norm": 4.793761253356934,
      "learning_rate": 3.309793545495374e-05,
      "loss": 1.3569,
      "step": 8505
    },
    {
      "epoch": 2.1189999999999998,
      "grad_norm": 5.520724773406982,
      "learning_rate": 3.307837864492786e-05,
      "loss": 1.3522,
      "step": 8510
    },
    {
      "epoch": 2.11925,
      "grad_norm": 4.365861415863037,
      "learning_rate": 3.305881631340636e-05,
      "loss": 1.2893,
      "step": 8515
    },
    {
      "epoch": 2.1195,
      "grad_norm": 6.739862442016602,
      "learning_rate": 3.3039248473759885e-05,
      "loss": 1.3026,
      "step": 8520
    },
    {
      "epoch": 2.11975,
      "grad_norm": 4.680141448974609,
      "learning_rate": 3.3019675139362897e-05,
      "loss": 1.3551,
      "step": 8525
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.620816946029663,
      "learning_rate": 3.300009632359357e-05,
      "loss": 1.3216,
      "step": 8530
    },
    {
      "epoch": 2.12025,
      "grad_norm": 4.702208995819092,
      "learning_rate": 3.298051203983384e-05,
      "loss": 1.1713,
      "step": 8535
    },
    {
      "epoch": 2.1205,
      "grad_norm": 6.430941104888916,
      "learning_rate": 3.2960922301469385e-05,
      "loss": 1.3476,
      "step": 8540
    },
    {
      "epoch": 2.12075,
      "grad_norm": 8.544681549072266,
      "learning_rate": 3.2941327121889596e-05,
      "loss": 1.4296,
      "step": 8545
    },
    {
      "epoch": 2.121,
      "grad_norm": 4.177489757537842,
      "learning_rate": 3.2921726514487614e-05,
      "loss": 1.3521,
      "step": 8550
    },
    {
      "epoch": 2.12125,
      "grad_norm": 4.419776916503906,
      "learning_rate": 3.290212049266025e-05,
      "loss": 1.2252,
      "step": 8555
    },
    {
      "epoch": 2.1215,
      "grad_norm": 4.727868556976318,
      "learning_rate": 3.2882509069808044e-05,
      "loss": 1.4125,
      "step": 8560
    },
    {
      "epoch": 2.12175,
      "grad_norm": 5.18543004989624,
      "learning_rate": 3.286289225933521e-05,
      "loss": 1.2644,
      "step": 8565
    },
    {
      "epoch": 2.122,
      "grad_norm": 4.566936492919922,
      "learning_rate": 3.284327007464966e-05,
      "loss": 1.3968,
      "step": 8570
    },
    {
      "epoch": 2.12225,
      "grad_norm": 5.141506195068359,
      "learning_rate": 3.282364252916298e-05,
      "loss": 1.346,
      "step": 8575
    },
    {
      "epoch": 2.1225,
      "grad_norm": 4.488609313964844,
      "learning_rate": 3.28040096362904e-05,
      "loss": 1.3988,
      "step": 8580
    },
    {
      "epoch": 2.12275,
      "grad_norm": 5.162388801574707,
      "learning_rate": 3.278437140945082e-05,
      "loss": 1.367,
      "step": 8585
    },
    {
      "epoch": 2.123,
      "grad_norm": 4.856635093688965,
      "learning_rate": 3.276472786206679e-05,
      "loss": 1.292,
      "step": 8590
    },
    {
      "epoch": 2.12325,
      "grad_norm": 5.344956874847412,
      "learning_rate": 3.2745079007564474e-05,
      "loss": 1.2083,
      "step": 8595
    },
    {
      "epoch": 2.1235,
      "grad_norm": 4.497158050537109,
      "learning_rate": 3.272542485937369e-05,
      "loss": 1.3259,
      "step": 8600
    },
    {
      "epoch": 2.12375,
      "grad_norm": 5.054836273193359,
      "learning_rate": 3.270576543092786e-05,
      "loss": 1.2919,
      "step": 8605
    },
    {
      "epoch": 2.124,
      "grad_norm": 4.801906585693359,
      "learning_rate": 3.2686100735664024e-05,
      "loss": 1.2716,
      "step": 8610
    },
    {
      "epoch": 2.12425,
      "grad_norm": 4.959705352783203,
      "learning_rate": 3.266643078702281e-05,
      "loss": 1.2837,
      "step": 8615
    },
    {
      "epoch": 2.1245,
      "grad_norm": 4.448188304901123,
      "learning_rate": 3.264675559844844e-05,
      "loss": 1.3371,
      "step": 8620
    },
    {
      "epoch": 2.12475,
      "grad_norm": 5.013472080230713,
      "learning_rate": 3.262707518338872e-05,
      "loss": 1.1927,
      "step": 8625
    },
    {
      "epoch": 2.125,
      "grad_norm": 6.870335102081299,
      "learning_rate": 3.260738955529504e-05,
      "loss": 1.4481,
      "step": 8630
    },
    {
      "epoch": 2.12525,
      "grad_norm": 4.669546127319336,
      "learning_rate": 3.258769872762232e-05,
      "loss": 1.3071,
      "step": 8635
    },
    {
      "epoch": 2.1255,
      "grad_norm": 5.021124839782715,
      "learning_rate": 3.2568002713829084e-05,
      "loss": 1.3875,
      "step": 8640
    },
    {
      "epoch": 2.12575,
      "grad_norm": 5.451903343200684,
      "learning_rate": 3.254830152737734e-05,
      "loss": 1.1798,
      "step": 8645
    },
    {
      "epoch": 2.126,
      "grad_norm": 5.20745325088501,
      "learning_rate": 3.252859518173269e-05,
      "loss": 1.2723,
      "step": 8650
    },
    {
      "epoch": 2.12625,
      "grad_norm": 4.88095235824585,
      "learning_rate": 3.250888369036422e-05,
      "loss": 1.2883,
      "step": 8655
    },
    {
      "epoch": 2.1265,
      "grad_norm": 8.526677131652832,
      "learning_rate": 3.2489167066744547e-05,
      "loss": 1.3123,
      "step": 8660
    },
    {
      "epoch": 2.12675,
      "grad_norm": 5.228065490722656,
      "learning_rate": 3.246944532434981e-05,
      "loss": 1.2831,
      "step": 8665
    },
    {
      "epoch": 2.127,
      "grad_norm": 4.755767822265625,
      "learning_rate": 3.244971847665962e-05,
      "loss": 1.2864,
      "step": 8670
    },
    {
      "epoch": 2.12725,
      "grad_norm": 6.370349884033203,
      "learning_rate": 3.24299865371571e-05,
      "loss": 1.1991,
      "step": 8675
    },
    {
      "epoch": 2.1275,
      "grad_norm": 4.357653617858887,
      "learning_rate": 3.241024951932885e-05,
      "loss": 1.2358,
      "step": 8680
    },
    {
      "epoch": 2.12775,
      "grad_norm": 4.338053226470947,
      "learning_rate": 3.239050743666491e-05,
      "loss": 1.3568,
      "step": 8685
    },
    {
      "epoch": 2.128,
      "grad_norm": 4.895227909088135,
      "learning_rate": 3.237076030265884e-05,
      "loss": 1.2817,
      "step": 8690
    },
    {
      "epoch": 2.12825,
      "grad_norm": 7.4243927001953125,
      "learning_rate": 3.23510081308076e-05,
      "loss": 1.3971,
      "step": 8695
    },
    {
      "epoch": 2.1285,
      "grad_norm": 5.711658000946045,
      "learning_rate": 3.2331250934611624e-05,
      "loss": 1.322,
      "step": 8700
    },
    {
      "epoch": 2.12875,
      "grad_norm": 4.415455341339111,
      "learning_rate": 3.231148872757476e-05,
      "loss": 1.5872,
      "step": 8705
    },
    {
      "epoch": 2.129,
      "grad_norm": 3.995943784713745,
      "learning_rate": 3.229172152320429e-05,
      "loss": 1.1728,
      "step": 8710
    },
    {
      "epoch": 2.12925,
      "grad_norm": 4.957951545715332,
      "learning_rate": 3.227194933501092e-05,
      "loss": 1.2413,
      "step": 8715
    },
    {
      "epoch": 2.1295,
      "grad_norm": 3.771738052368164,
      "learning_rate": 3.225217217650876e-05,
      "loss": 1.2593,
      "step": 8720
    },
    {
      "epoch": 2.12975,
      "grad_norm": 5.4736857414245605,
      "learning_rate": 3.223239006121528e-05,
      "loss": 1.1728,
      "step": 8725
    },
    {
      "epoch": 2.13,
      "grad_norm": 4.797023773193359,
      "learning_rate": 3.22126030026514e-05,
      "loss": 1.2992,
      "step": 8730
    },
    {
      "epoch": 2.13025,
      "grad_norm": 5.361494064331055,
      "learning_rate": 3.219281101434138e-05,
      "loss": 1.2672,
      "step": 8735
    },
    {
      "epoch": 2.1305,
      "grad_norm": 5.165260314941406,
      "learning_rate": 3.217301410981285e-05,
      "loss": 1.3609,
      "step": 8740
    },
    {
      "epoch": 2.13075,
      "grad_norm": 4.784485816955566,
      "learning_rate": 3.2153212302596823e-05,
      "loss": 1.317,
      "step": 8745
    },
    {
      "epoch": 2.1310000000000002,
      "grad_norm": 5.866313457489014,
      "learning_rate": 3.213340560622763e-05,
      "loss": 1.1303,
      "step": 8750
    },
    {
      "epoch": 2.13125,
      "grad_norm": 5.495769023895264,
      "learning_rate": 3.2113594034242974e-05,
      "loss": 1.218,
      "step": 8755
    },
    {
      "epoch": 2.1315,
      "grad_norm": 4.483447074890137,
      "learning_rate": 3.2093777600183875e-05,
      "loss": 1.1502,
      "step": 8760
    },
    {
      "epoch": 2.13175,
      "grad_norm": 6.217635154724121,
      "learning_rate": 3.207395631759467e-05,
      "loss": 1.2249,
      "step": 8765
    },
    {
      "epoch": 2.132,
      "grad_norm": 4.90217924118042,
      "learning_rate": 3.205413020002303e-05,
      "loss": 1.1935,
      "step": 8770
    },
    {
      "epoch": 2.13225,
      "grad_norm": 5.8392486572265625,
      "learning_rate": 3.2034299261019914e-05,
      "loss": 1.1788,
      "step": 8775
    },
    {
      "epoch": 2.1325,
      "grad_norm": 4.3584089279174805,
      "learning_rate": 3.201446351413958e-05,
      "loss": 1.1228,
      "step": 8780
    },
    {
      "epoch": 2.13275,
      "grad_norm": 5.624030113220215,
      "learning_rate": 3.199462297293958e-05,
      "loss": 1.1612,
      "step": 8785
    },
    {
      "epoch": 2.133,
      "grad_norm": 3.4148194789886475,
      "learning_rate": 3.1974777650980735e-05,
      "loss": 0.9284,
      "step": 8790
    },
    {
      "epoch": 2.13325,
      "grad_norm": 8.622627258300781,
      "learning_rate": 3.195492756182713e-05,
      "loss": 1.2916,
      "step": 8795
    },
    {
      "epoch": 2.1335,
      "grad_norm": 4.48293924331665,
      "learning_rate": 3.1935072719046115e-05,
      "loss": 1.0155,
      "step": 8800
    },
    {
      "epoch": 2.13375,
      "grad_norm": 3.6238152980804443,
      "learning_rate": 3.1915213136208296e-05,
      "loss": 0.9215,
      "step": 8805
    },
    {
      "epoch": 2.134,
      "grad_norm": 4.916107177734375,
      "learning_rate": 3.18953488268875e-05,
      "loss": 1.1711,
      "step": 8810
    },
    {
      "epoch": 2.13425,
      "grad_norm": 4.0913472175598145,
      "learning_rate": 3.187547980466081e-05,
      "loss": 1.1768,
      "step": 8815
    },
    {
      "epoch": 2.1345,
      "grad_norm": 3.9629428386688232,
      "learning_rate": 3.185560608310849e-05,
      "loss": 1.1637,
      "step": 8820
    },
    {
      "epoch": 2.13475,
      "grad_norm": 5.755816459655762,
      "learning_rate": 3.1835727675814064e-05,
      "loss": 1.2568,
      "step": 8825
    },
    {
      "epoch": 2.135,
      "grad_norm": 5.0225677490234375,
      "learning_rate": 3.181584459636423e-05,
      "loss": 1.3691,
      "step": 8830
    },
    {
      "epoch": 2.13525,
      "grad_norm": 7.457278251647949,
      "learning_rate": 3.1795956858348885e-05,
      "loss": 1.3706,
      "step": 8835
    },
    {
      "epoch": 2.1355,
      "grad_norm": 5.1660919189453125,
      "learning_rate": 3.1776064475361114e-05,
      "loss": 1.3183,
      "step": 8840
    },
    {
      "epoch": 2.13575,
      "grad_norm": 6.003780364990234,
      "learning_rate": 3.1756167460997155e-05,
      "loss": 1.3769,
      "step": 8845
    },
    {
      "epoch": 2.136,
      "grad_norm": 5.849248886108398,
      "learning_rate": 3.173626582885645e-05,
      "loss": 1.1349,
      "step": 8850
    },
    {
      "epoch": 2.13625,
      "grad_norm": 5.916825294494629,
      "learning_rate": 3.1716359592541574e-05,
      "loss": 1.2177,
      "step": 8855
    },
    {
      "epoch": 2.1365,
      "grad_norm": 5.103278160095215,
      "learning_rate": 3.169644876565824e-05,
      "loss": 1.4201,
      "step": 8860
    },
    {
      "epoch": 2.13675,
      "grad_norm": 5.4032487869262695,
      "learning_rate": 3.167653336181533e-05,
      "loss": 1.3267,
      "step": 8865
    },
    {
      "epoch": 2.137,
      "grad_norm": 5.537725448608398,
      "learning_rate": 3.165661339462481e-05,
      "loss": 1.4413,
      "step": 8870
    },
    {
      "epoch": 2.13725,
      "grad_norm": 5.042974472045898,
      "learning_rate": 3.163668887770181e-05,
      "loss": 1.4264,
      "step": 8875
    },
    {
      "epoch": 2.1375,
      "grad_norm": 6.0649237632751465,
      "learning_rate": 3.161675982466454e-05,
      "loss": 1.1227,
      "step": 8880
    },
    {
      "epoch": 2.13775,
      "grad_norm": 7.259181976318359,
      "learning_rate": 3.1596826249134324e-05,
      "loss": 1.2938,
      "step": 8885
    },
    {
      "epoch": 2.138,
      "grad_norm": 4.058316230773926,
      "learning_rate": 3.1576888164735575e-05,
      "loss": 1.3622,
      "step": 8890
    },
    {
      "epoch": 2.13825,
      "grad_norm": 5.547089099884033,
      "learning_rate": 3.155694558509577e-05,
      "loss": 1.2922,
      "step": 8895
    },
    {
      "epoch": 2.1385,
      "grad_norm": 7.543015480041504,
      "learning_rate": 3.1536998523845494e-05,
      "loss": 1.4621,
      "step": 8900
    },
    {
      "epoch": 2.13875,
      "grad_norm": 5.390803337097168,
      "learning_rate": 3.151704699461837e-05,
      "loss": 1.3999,
      "step": 8905
    },
    {
      "epoch": 2.1390000000000002,
      "grad_norm": 4.757044792175293,
      "learning_rate": 3.149709101105107e-05,
      "loss": 1.2967,
      "step": 8910
    },
    {
      "epoch": 2.13925,
      "grad_norm": 4.695324897766113,
      "learning_rate": 3.147713058678334e-05,
      "loss": 1.3264,
      "step": 8915
    },
    {
      "epoch": 2.1395,
      "grad_norm": 4.616851329803467,
      "learning_rate": 3.145716573545792e-05,
      "loss": 1.1939,
      "step": 8920
    },
    {
      "epoch": 2.13975,
      "grad_norm": 4.340921401977539,
      "learning_rate": 3.14371964707206e-05,
      "loss": 1.2743,
      "step": 8925
    },
    {
      "epoch": 2.14,
      "grad_norm": 7.042118549346924,
      "learning_rate": 3.141722280622021e-05,
      "loss": 1.1843,
      "step": 8930
    },
    {
      "epoch": 2.14025,
      "grad_norm": 5.997080326080322,
      "learning_rate": 3.1397244755608526e-05,
      "loss": 1.3793,
      "step": 8935
    },
    {
      "epoch": 2.1405,
      "grad_norm": 5.275651454925537,
      "learning_rate": 3.137726233254038e-05,
      "loss": 1.1406,
      "step": 8940
    },
    {
      "epoch": 2.14075,
      "grad_norm": 5.901891231536865,
      "learning_rate": 3.1357275550673565e-05,
      "loss": 1.3436,
      "step": 8945
    },
    {
      "epoch": 2.141,
      "grad_norm": 5.04050874710083,
      "learning_rate": 3.133728442366885e-05,
      "loss": 1.2128,
      "step": 8950
    },
    {
      "epoch": 2.14125,
      "grad_norm": 5.245988845825195,
      "learning_rate": 3.131728896519e-05,
      "loss": 1.3285,
      "step": 8955
    },
    {
      "epoch": 2.1415,
      "grad_norm": 4.506762981414795,
      "learning_rate": 3.129728918890371e-05,
      "loss": 1.1174,
      "step": 8960
    },
    {
      "epoch": 2.14175,
      "grad_norm": 4.76501989364624,
      "learning_rate": 3.127728510847963e-05,
      "loss": 1.1141,
      "step": 8965
    },
    {
      "epoch": 2.142,
      "grad_norm": 5.558198928833008,
      "learning_rate": 3.1257276737590365e-05,
      "loss": 1.3628,
      "step": 8970
    },
    {
      "epoch": 2.1422499999999998,
      "grad_norm": 7.5997724533081055,
      "learning_rate": 3.1237264089911465e-05,
      "loss": 1.3394,
      "step": 8975
    },
    {
      "epoch": 2.1425,
      "grad_norm": 4.132594585418701,
      "learning_rate": 3.121724717912138e-05,
      "loss": 1.1407,
      "step": 8980
    },
    {
      "epoch": 2.14275,
      "grad_norm": 3.7047653198242188,
      "learning_rate": 3.119722601890146e-05,
      "loss": 1.1657,
      "step": 8985
    },
    {
      "epoch": 2.143,
      "grad_norm": 4.42092227935791,
      "learning_rate": 3.117720062293599e-05,
      "loss": 1.0176,
      "step": 8990
    },
    {
      "epoch": 2.14325,
      "grad_norm": 5.8417768478393555,
      "learning_rate": 3.115717100491214e-05,
      "loss": 1.0656,
      "step": 8995
    },
    {
      "epoch": 2.1435,
      "grad_norm": 5.050901889801025,
      "learning_rate": 3.1137137178519985e-05,
      "loss": 1.2765,
      "step": 9000
    },
    {
      "epoch": 2.1435,
      "eval_loss": 2.064565658569336,
      "eval_runtime": 5.1654,
      "eval_samples_per_second": 198.244,
      "eval_steps_per_second": 24.78,
      "step": 9000
    },
    {
      "epoch": 2.14375,
      "grad_norm": 6.900640487670898,
      "learning_rate": 3.111709915745243e-05,
      "loss": 1.211,
      "step": 9005
    },
    {
      "epoch": 2.144,
      "grad_norm": 5.009986400604248,
      "learning_rate": 3.1097056955405274e-05,
      "loss": 1.1217,
      "step": 9010
    },
    {
      "epoch": 2.14425,
      "grad_norm": 3.6447105407714844,
      "learning_rate": 3.107701058607718e-05,
      "loss": 1.2441,
      "step": 9015
    },
    {
      "epoch": 2.1445,
      "grad_norm": 4.923092365264893,
      "learning_rate": 3.105696006316966e-05,
      "loss": 1.0013,
      "step": 9020
    },
    {
      "epoch": 2.14475,
      "grad_norm": 4.854879856109619,
      "learning_rate": 3.103690540038705e-05,
      "loss": 0.9847,
      "step": 9025
    },
    {
      "epoch": 2.145,
      "grad_norm": 5.152105808258057,
      "learning_rate": 3.101684661143653e-05,
      "loss": 1.1296,
      "step": 9030
    },
    {
      "epoch": 2.14525,
      "grad_norm": 3.920070171356201,
      "learning_rate": 3.099678371002807e-05,
      "loss": 0.9106,
      "step": 9035
    },
    {
      "epoch": 2.1455,
      "grad_norm": 5.7696428298950195,
      "learning_rate": 3.0976716709874496e-05,
      "loss": 1.1221,
      "step": 9040
    },
    {
      "epoch": 2.14575,
      "grad_norm": 3.9837491512298584,
      "learning_rate": 3.0956645624691424e-05,
      "loss": 1.2385,
      "step": 9045
    },
    {
      "epoch": 2.146,
      "grad_norm": 4.707160949707031,
      "learning_rate": 3.093657046819722e-05,
      "loss": 1.0309,
      "step": 9050
    },
    {
      "epoch": 2.14625,
      "grad_norm": 5.336588382720947,
      "learning_rate": 3.0916491254113086e-05,
      "loss": 1.1454,
      "step": 9055
    },
    {
      "epoch": 2.1465,
      "grad_norm": 8.833897590637207,
      "learning_rate": 3.0896407996162954e-05,
      "loss": 2.0831,
      "step": 9060
    },
    {
      "epoch": 2.14675,
      "grad_norm": 8.183218955993652,
      "learning_rate": 3.087632070807357e-05,
      "loss": 2.3967,
      "step": 9065
    },
    {
      "epoch": 2.147,
      "grad_norm": 7.259833812713623,
      "learning_rate": 3.08562294035744e-05,
      "loss": 2.2016,
      "step": 9070
    },
    {
      "epoch": 2.14725,
      "grad_norm": 9.133898735046387,
      "learning_rate": 3.083613409639764e-05,
      "loss": 2.0365,
      "step": 9075
    },
    {
      "epoch": 2.1475,
      "grad_norm": 6.037425518035889,
      "learning_rate": 3.081603480027826e-05,
      "loss": 1.9653,
      "step": 9080
    },
    {
      "epoch": 2.14775,
      "grad_norm": 7.4187912940979,
      "learning_rate": 3.0795931528953935e-05,
      "loss": 1.9379,
      "step": 9085
    },
    {
      "epoch": 2.148,
      "grad_norm": 6.307101249694824,
      "learning_rate": 3.077582429616506e-05,
      "loss": 1.9115,
      "step": 9090
    },
    {
      "epoch": 2.14825,
      "grad_norm": 6.6086649894714355,
      "learning_rate": 3.075571311565475e-05,
      "loss": 1.8708,
      "step": 9095
    },
    {
      "epoch": 2.1485,
      "grad_norm": 5.456751823425293,
      "learning_rate": 3.073559800116879e-05,
      "loss": 1.9351,
      "step": 9100
    },
    {
      "epoch": 2.14875,
      "grad_norm": 12.161861419677734,
      "learning_rate": 3.071547896645568e-05,
      "loss": 2.0273,
      "step": 9105
    },
    {
      "epoch": 2.149,
      "grad_norm": 6.268619060516357,
      "learning_rate": 3.06953560252666e-05,
      "loss": 1.9804,
      "step": 9110
    },
    {
      "epoch": 2.14925,
      "grad_norm": 5.062724590301514,
      "learning_rate": 3.0675229191355375e-05,
      "loss": 1.8661,
      "step": 9115
    },
    {
      "epoch": 2.1495,
      "grad_norm": 6.159068584442139,
      "learning_rate": 3.065509847847851e-05,
      "loss": 1.9104,
      "step": 9120
    },
    {
      "epoch": 2.14975,
      "grad_norm": 5.422314643859863,
      "learning_rate": 3.0634963900395155e-05,
      "loss": 1.8192,
      "step": 9125
    },
    {
      "epoch": 2.15,
      "grad_norm": 6.469110012054443,
      "learning_rate": 3.061482547086712e-05,
      "loss": 1.8291,
      "step": 9130
    },
    {
      "epoch": 2.1502499999999998,
      "grad_norm": 5.250096321105957,
      "learning_rate": 3.0594683203658813e-05,
      "loss": 1.8186,
      "step": 9135
    },
    {
      "epoch": 2.1505,
      "grad_norm": 8.477686882019043,
      "learning_rate": 3.05745371125373e-05,
      "loss": 2.0036,
      "step": 9140
    },
    {
      "epoch": 2.15075,
      "grad_norm": 7.986027240753174,
      "learning_rate": 3.055438721127222e-05,
      "loss": 1.9291,
      "step": 9145
    },
    {
      "epoch": 2.151,
      "grad_norm": 6.094897747039795,
      "learning_rate": 3.053423351363586e-05,
      "loss": 1.9016,
      "step": 9150
    },
    {
      "epoch": 2.15125,
      "grad_norm": 5.344560623168945,
      "learning_rate": 3.0514076033403087e-05,
      "loss": 1.9873,
      "step": 9155
    },
    {
      "epoch": 2.1515,
      "grad_norm": 5.541098117828369,
      "learning_rate": 3.0493914784351328e-05,
      "loss": 1.954,
      "step": 9160
    },
    {
      "epoch": 2.15175,
      "grad_norm": 6.76300573348999,
      "learning_rate": 3.047374978026063e-05,
      "loss": 1.9153,
      "step": 9165
    },
    {
      "epoch": 2.152,
      "grad_norm": 11.087247848510742,
      "learning_rate": 3.045358103491357e-05,
      "loss": 2.3138,
      "step": 9170
    },
    {
      "epoch": 2.15225,
      "grad_norm": 12.666929244995117,
      "learning_rate": 3.043340856209529e-05,
      "loss": 2.1527,
      "step": 9175
    },
    {
      "epoch": 2.1525,
      "grad_norm": 11.249287605285645,
      "learning_rate": 3.0413232375593497e-05,
      "loss": 2.002,
      "step": 9180
    },
    {
      "epoch": 2.15275,
      "grad_norm": 9.39236068725586,
      "learning_rate": 3.039305248919842e-05,
      "loss": 1.9498,
      "step": 9185
    },
    {
      "epoch": 2.153,
      "grad_norm": 8.73176097869873,
      "learning_rate": 3.037286891670281e-05,
      "loss": 2.1855,
      "step": 9190
    },
    {
      "epoch": 2.15325,
      "grad_norm": 5.536516189575195,
      "learning_rate": 3.0352681671901973e-05,
      "loss": 1.5816,
      "step": 9195
    },
    {
      "epoch": 3.00025,
      "grad_norm": 6.395699977874756,
      "learning_rate": 3.0332490768593675e-05,
      "loss": 1.251,
      "step": 9200
    },
    {
      "epoch": 3.0005,
      "grad_norm": 6.088210105895996,
      "learning_rate": 3.0312296220578225e-05,
      "loss": 1.1916,
      "step": 9205
    },
    {
      "epoch": 3.00075,
      "grad_norm": 5.4882659912109375,
      "learning_rate": 3.0292098041658397e-05,
      "loss": 1.2202,
      "step": 9210
    },
    {
      "epoch": 3.001,
      "grad_norm": 7.211801052093506,
      "learning_rate": 3.027189624563946e-05,
      "loss": 1.1075,
      "step": 9215
    },
    {
      "epoch": 3.00125,
      "grad_norm": 6.316762924194336,
      "learning_rate": 3.025169084632915e-05,
      "loss": 1.2848,
      "step": 9220
    },
    {
      "epoch": 3.0015,
      "grad_norm": 6.303474426269531,
      "learning_rate": 3.0231481857537665e-05,
      "loss": 1.3137,
      "step": 9225
    },
    {
      "epoch": 3.00175,
      "grad_norm": 5.030352592468262,
      "learning_rate": 3.021126929307766e-05,
      "loss": 1.006,
      "step": 9230
    },
    {
      "epoch": 3.002,
      "grad_norm": 5.4630208015441895,
      "learning_rate": 3.0191053166764237e-05,
      "loss": 1.121,
      "step": 9235
    },
    {
      "epoch": 3.00225,
      "grad_norm": 5.866240978240967,
      "learning_rate": 3.017083349241492e-05,
      "loss": 1.1416,
      "step": 9240
    },
    {
      "epoch": 3.0025,
      "grad_norm": 7.803157806396484,
      "learning_rate": 3.015061028384967e-05,
      "loss": 1.3729,
      "step": 9245
    },
    {
      "epoch": 3.00275,
      "grad_norm": 10.147807121276855,
      "learning_rate": 3.0130383554890856e-05,
      "loss": 1.4374,
      "step": 9250
    },
    {
      "epoch": 3.003,
      "grad_norm": 6.961977005004883,
      "learning_rate": 3.0110153319363266e-05,
      "loss": 1.3953,
      "step": 9255
    },
    {
      "epoch": 3.00325,
      "grad_norm": 6.66534423828125,
      "learning_rate": 3.008991959109406e-05,
      "loss": 1.4175,
      "step": 9260
    },
    {
      "epoch": 3.0035,
      "grad_norm": 5.593259334564209,
      "learning_rate": 3.0069682383912813e-05,
      "loss": 1.2522,
      "step": 9265
    },
    {
      "epoch": 3.00375,
      "grad_norm": 5.290047645568848,
      "learning_rate": 3.004944171165146e-05,
      "loss": 1.1469,
      "step": 9270
    },
    {
      "epoch": 3.004,
      "grad_norm": 12.362834930419922,
      "learning_rate": 3.002919758814431e-05,
      "loss": 1.3056,
      "step": 9275
    },
    {
      "epoch": 3.00425,
      "grad_norm": 11.54780387878418,
      "learning_rate": 3.0008950027228033e-05,
      "loss": 1.463,
      "step": 9280
    },
    {
      "epoch": 3.0045,
      "grad_norm": 8.221539497375488,
      "learning_rate": 2.9988699042741642e-05,
      "loss": 1.4134,
      "step": 9285
    },
    {
      "epoch": 3.00475,
      "grad_norm": 9.761457443237305,
      "learning_rate": 2.9968444648526493e-05,
      "loss": 1.4929,
      "step": 9290
    },
    {
      "epoch": 3.005,
      "grad_norm": 7.3910722732543945,
      "learning_rate": 2.9948186858426287e-05,
      "loss": 1.5132,
      "step": 9295
    },
    {
      "epoch": 3.00525,
      "grad_norm": 6.454660415649414,
      "learning_rate": 2.9927925686287006e-05,
      "loss": 1.4355,
      "step": 9300
    },
    {
      "epoch": 3.0055,
      "grad_norm": 8.080750465393066,
      "learning_rate": 2.9907661145957e-05,
      "loss": 1.6059,
      "step": 9305
    },
    {
      "epoch": 3.00575,
      "grad_norm": 7.45200777053833,
      "learning_rate": 2.988739325128687e-05,
      "loss": 1.4481,
      "step": 9310
    },
    {
      "epoch": 3.006,
      "grad_norm": 7.915075778961182,
      "learning_rate": 2.986712201612954e-05,
      "loss": 1.5925,
      "step": 9315
    },
    {
      "epoch": 3.00625,
      "grad_norm": 7.613598823547363,
      "learning_rate": 2.984684745434021e-05,
      "loss": 1.4495,
      "step": 9320
    },
    {
      "epoch": 3.0065,
      "grad_norm": 8.37912654876709,
      "learning_rate": 2.982656957977634e-05,
      "loss": 1.567,
      "step": 9325
    },
    {
      "epoch": 3.00675,
      "grad_norm": 6.894211292266846,
      "learning_rate": 2.9806288406297676e-05,
      "loss": 1.349,
      "step": 9330
    },
    {
      "epoch": 3.007,
      "grad_norm": 7.962040424346924,
      "learning_rate": 2.9786003947766212e-05,
      "loss": 1.3295,
      "step": 9335
    },
    {
      "epoch": 3.00725,
      "grad_norm": 6.466572284698486,
      "learning_rate": 2.9765716218046175e-05,
      "loss": 1.4217,
      "step": 9340
    },
    {
      "epoch": 3.0075,
      "grad_norm": 7.101039886474609,
      "learning_rate": 2.974542523100404e-05,
      "loss": 1.5153,
      "step": 9345
    },
    {
      "epoch": 3.00775,
      "grad_norm": 8.032439231872559,
      "learning_rate": 2.972513100050851e-05,
      "loss": 1.3694,
      "step": 9350
    },
    {
      "epoch": 3.008,
      "grad_norm": 6.594778060913086,
      "learning_rate": 2.9704833540430494e-05,
      "loss": 1.3717,
      "step": 9355
    },
    {
      "epoch": 3.00825,
      "grad_norm": 7.49567174911499,
      "learning_rate": 2.9684532864643122e-05,
      "loss": 1.4283,
      "step": 9360
    },
    {
      "epoch": 3.0085,
      "grad_norm": 10.030318260192871,
      "learning_rate": 2.9664228987021696e-05,
      "loss": 1.3084,
      "step": 9365
    },
    {
      "epoch": 3.00875,
      "grad_norm": 7.510721683502197,
      "learning_rate": 2.964392192144375e-05,
      "loss": 1.3302,
      "step": 9370
    },
    {
      "epoch": 3.009,
      "grad_norm": 8.074162483215332,
      "learning_rate": 2.9623611681788965e-05,
      "loss": 1.4503,
      "step": 9375
    },
    {
      "epoch": 3.00925,
      "grad_norm": 7.331204414367676,
      "learning_rate": 2.9603298281939178e-05,
      "loss": 1.3188,
      "step": 9380
    },
    {
      "epoch": 3.0095,
      "grad_norm": 8.477252006530762,
      "learning_rate": 2.958298173577844e-05,
      "loss": 1.2442,
      "step": 9385
    },
    {
      "epoch": 3.00975,
      "grad_norm": 10.225584983825684,
      "learning_rate": 2.956266205719288e-05,
      "loss": 1.4789,
      "step": 9390
    },
    {
      "epoch": 3.01,
      "grad_norm": 6.712927341461182,
      "learning_rate": 2.9542339260070845e-05,
      "loss": 1.3648,
      "step": 9395
    },
    {
      "epoch": 3.01025,
      "grad_norm": 7.877230167388916,
      "learning_rate": 2.952201335830275e-05,
      "loss": 1.3963,
      "step": 9400
    },
    {
      "epoch": 3.0105,
      "grad_norm": 5.928700923919678,
      "learning_rate": 2.950168436578116e-05,
      "loss": 1.4277,
      "step": 9405
    },
    {
      "epoch": 3.01075,
      "grad_norm": 9.359662055969238,
      "learning_rate": 2.9481352296400766e-05,
      "loss": 1.2893,
      "step": 9410
    },
    {
      "epoch": 3.011,
      "grad_norm": 7.670351505279541,
      "learning_rate": 2.9461017164058323e-05,
      "loss": 1.2613,
      "step": 9415
    },
    {
      "epoch": 3.01125,
      "grad_norm": 6.304492473602295,
      "learning_rate": 2.944067898265272e-05,
      "loss": 1.339,
      "step": 9420
    },
    {
      "epoch": 3.0115,
      "grad_norm": 7.113531589508057,
      "learning_rate": 2.9420337766084903e-05,
      "loss": 1.2916,
      "step": 9425
    },
    {
      "epoch": 3.01175,
      "grad_norm": 7.0516276359558105,
      "learning_rate": 2.9399993528257902e-05,
      "loss": 1.3938,
      "step": 9430
    },
    {
      "epoch": 3.012,
      "grad_norm": 7.122283458709717,
      "learning_rate": 2.9379646283076817e-05,
      "loss": 1.3057,
      "step": 9435
    },
    {
      "epoch": 3.01225,
      "grad_norm": 7.227494239807129,
      "learning_rate": 2.9359296044448794e-05,
      "loss": 1.5229,
      "step": 9440
    },
    {
      "epoch": 3.0125,
      "grad_norm": 7.811917304992676,
      "learning_rate": 2.9338942826283035e-05,
      "loss": 1.3143,
      "step": 9445
    },
    {
      "epoch": 3.01275,
      "grad_norm": 6.594598770141602,
      "learning_rate": 2.9318586642490763e-05,
      "loss": 1.1443,
      "step": 9450
    },
    {
      "epoch": 3.013,
      "grad_norm": 7.35490083694458,
      "learning_rate": 2.929822750698524e-05,
      "loss": 1.2973,
      "step": 9455
    },
    {
      "epoch": 3.01325,
      "grad_norm": 7.1427459716796875,
      "learning_rate": 2.927786543368175e-05,
      "loss": 1.2858,
      "step": 9460
    },
    {
      "epoch": 3.0135,
      "grad_norm": 7.087037563323975,
      "learning_rate": 2.9257500436497574e-05,
      "loss": 1.1359,
      "step": 9465
    },
    {
      "epoch": 3.01375,
      "grad_norm": 7.044985294342041,
      "learning_rate": 2.9237132529351996e-05,
      "loss": 1.0872,
      "step": 9470
    },
    {
      "epoch": 3.014,
      "grad_norm": 9.020783424377441,
      "learning_rate": 2.9216761726166287e-05,
      "loss": 1.2103,
      "step": 9475
    },
    {
      "epoch": 3.01425,
      "grad_norm": 6.209795951843262,
      "learning_rate": 2.9196388040863693e-05,
      "loss": 1.0904,
      "step": 9480
    },
    {
      "epoch": 3.0145,
      "grad_norm": 5.641483783721924,
      "learning_rate": 2.9176011487369453e-05,
      "loss": 0.8585,
      "step": 9485
    },
    {
      "epoch": 3.01475,
      "grad_norm": 7.153300762176514,
      "learning_rate": 2.915563207961074e-05,
      "loss": 0.9272,
      "step": 9490
    },
    {
      "epoch": 3.015,
      "grad_norm": 6.592777729034424,
      "learning_rate": 2.9135249831516675e-05,
      "loss": 0.8657,
      "step": 9495
    },
    {
      "epoch": 3.01525,
      "grad_norm": 7.351474285125732,
      "learning_rate": 2.9114864757018352e-05,
      "loss": 0.6767,
      "step": 9500
    },
    {
      "epoch": 3.01525,
      "eval_loss": 2.0607171058654785,
      "eval_runtime": 5.1606,
      "eval_samples_per_second": 198.428,
      "eval_steps_per_second": 24.804,
      "step": 9500
    },
    {
      "epoch": 3.0155,
      "grad_norm": 5.7105937004089355,
      "learning_rate": 2.909447687004876e-05,
      "loss": 0.6628,
      "step": 9505
    },
    {
      "epoch": 3.01575,
      "grad_norm": 4.3705363273620605,
      "learning_rate": 2.9074086184542843e-05,
      "loss": 0.5562,
      "step": 9510
    },
    {
      "epoch": 3.016,
      "grad_norm": 3.3028311729431152,
      "learning_rate": 2.9053692714437435e-05,
      "loss": 0.5017,
      "step": 9515
    },
    {
      "epoch": 3.01625,
      "grad_norm": 4.337716102600098,
      "learning_rate": 2.9033296473671278e-05,
      "loss": 0.5666,
      "step": 9520
    },
    {
      "epoch": 3.0165,
      "grad_norm": 17.10446548461914,
      "learning_rate": 2.901289747618502e-05,
      "loss": 0.8073,
      "step": 9525
    },
    {
      "epoch": 3.01675,
      "grad_norm": 12.26593017578125,
      "learning_rate": 2.8992495735921165e-05,
      "loss": 1.5775,
      "step": 9530
    },
    {
      "epoch": 3.017,
      "grad_norm": 11.990644454956055,
      "learning_rate": 2.8972091266824132e-05,
      "loss": 1.6617,
      "step": 9535
    },
    {
      "epoch": 3.01725,
      "grad_norm": 7.910018444061279,
      "learning_rate": 2.8951684082840163e-05,
      "loss": 1.5523,
      "step": 9540
    },
    {
      "epoch": 3.0175,
      "grad_norm": 9.613460540771484,
      "learning_rate": 2.893127419791739e-05,
      "loss": 1.4726,
      "step": 9545
    },
    {
      "epoch": 3.01775,
      "grad_norm": 7.423637390136719,
      "learning_rate": 2.8910861626005776e-05,
      "loss": 1.3315,
      "step": 9550
    },
    {
      "epoch": 3.018,
      "grad_norm": 6.955648899078369,
      "learning_rate": 2.8890446381057114e-05,
      "loss": 1.3726,
      "step": 9555
    },
    {
      "epoch": 3.01825,
      "grad_norm": 8.503430366516113,
      "learning_rate": 2.8870028477025042e-05,
      "loss": 1.5043,
      "step": 9560
    },
    {
      "epoch": 3.0185,
      "grad_norm": 6.985098361968994,
      "learning_rate": 2.8849607927864984e-05,
      "loss": 1.4995,
      "step": 9565
    },
    {
      "epoch": 3.01875,
      "grad_norm": 7.469512462615967,
      "learning_rate": 2.8829184747534214e-05,
      "loss": 1.3095,
      "step": 9570
    },
    {
      "epoch": 3.019,
      "grad_norm": 7.383096218109131,
      "learning_rate": 2.8808758949991777e-05,
      "loss": 1.4229,
      "step": 9575
    },
    {
      "epoch": 3.01925,
      "grad_norm": 6.696382522583008,
      "learning_rate": 2.878833054919851e-05,
      "loss": 1.3435,
      "step": 9580
    },
    {
      "epoch": 3.0195,
      "grad_norm": 7.356697082519531,
      "learning_rate": 2.8767899559117046e-05,
      "loss": 1.3714,
      "step": 9585
    },
    {
      "epoch": 3.01975,
      "grad_norm": 6.977175235748291,
      "learning_rate": 2.874746599371175e-05,
      "loss": 1.1683,
      "step": 9590
    },
    {
      "epoch": 3.02,
      "grad_norm": 7.688083171844482,
      "learning_rate": 2.8727029866948786e-05,
      "loss": 1.3253,
      "step": 9595
    },
    {
      "epoch": 3.02025,
      "grad_norm": 8.97557258605957,
      "learning_rate": 2.870659119279605e-05,
      "loss": 1.5207,
      "step": 9600
    },
    {
      "epoch": 3.0205,
      "grad_norm": 6.805866718292236,
      "learning_rate": 2.8686149985223188e-05,
      "loss": 1.4532,
      "step": 9605
    },
    {
      "epoch": 3.02075,
      "grad_norm": 8.701664924621582,
      "learning_rate": 2.8665706258201574e-05,
      "loss": 1.2522,
      "step": 9610
    },
    {
      "epoch": 3.021,
      "grad_norm": 9.953468322753906,
      "learning_rate": 2.864526002570429e-05,
      "loss": 1.4663,
      "step": 9615
    },
    {
      "epoch": 3.02125,
      "grad_norm": 6.306647777557373,
      "learning_rate": 2.862481130170615e-05,
      "loss": 1.319,
      "step": 9620
    },
    {
      "epoch": 3.0215,
      "grad_norm": 7.6830596923828125,
      "learning_rate": 2.860436010018367e-05,
      "loss": 1.27,
      "step": 9625
    },
    {
      "epoch": 3.02175,
      "grad_norm": 10.309087753295898,
      "learning_rate": 2.8583906435115047e-05,
      "loss": 1.4252,
      "step": 9630
    },
    {
      "epoch": 3.022,
      "grad_norm": 7.936703681945801,
      "learning_rate": 2.8563450320480172e-05,
      "loss": 1.4509,
      "step": 9635
    },
    {
      "epoch": 3.02225,
      "grad_norm": 11.176226615905762,
      "learning_rate": 2.8542991770260608e-05,
      "loss": 1.5703,
      "step": 9640
    },
    {
      "epoch": 3.0225,
      "grad_norm": 7.969583034515381,
      "learning_rate": 2.8522530798439567e-05,
      "loss": 1.62,
      "step": 9645
    },
    {
      "epoch": 3.02275,
      "grad_norm": 8.296619415283203,
      "learning_rate": 2.850206741900195e-05,
      "loss": 1.42,
      "step": 9650
    },
    {
      "epoch": 3.023,
      "grad_norm": 7.281173229217529,
      "learning_rate": 2.848160164593427e-05,
      "loss": 1.415,
      "step": 9655
    },
    {
      "epoch": 3.02325,
      "grad_norm": 7.024625301361084,
      "learning_rate": 2.846113349322469e-05,
      "loss": 1.1899,
      "step": 9660
    },
    {
      "epoch": 3.0235,
      "grad_norm": 8.507904052734375,
      "learning_rate": 2.8440662974863012e-05,
      "loss": 1.393,
      "step": 9665
    },
    {
      "epoch": 3.02375,
      "grad_norm": 6.451228141784668,
      "learning_rate": 2.8420190104840628e-05,
      "loss": 1.2179,
      "step": 9670
    },
    {
      "epoch": 3.024,
      "grad_norm": 7.543352127075195,
      "learning_rate": 2.839971489715057e-05,
      "loss": 1.3163,
      "step": 9675
    },
    {
      "epoch": 3.02425,
      "grad_norm": 7.03731632232666,
      "learning_rate": 2.8379237365787426e-05,
      "loss": 1.1972,
      "step": 9680
    },
    {
      "epoch": 3.0245,
      "grad_norm": 9.555696487426758,
      "learning_rate": 2.8358757524747403e-05,
      "loss": 1.5236,
      "step": 9685
    },
    {
      "epoch": 3.02475,
      "grad_norm": 7.824773788452148,
      "learning_rate": 2.8338275388028295e-05,
      "loss": 1.2945,
      "step": 9690
    },
    {
      "epoch": 3.025,
      "grad_norm": 9.193134307861328,
      "learning_rate": 2.8317790969629428e-05,
      "loss": 1.3704,
      "step": 9695
    },
    {
      "epoch": 3.02525,
      "grad_norm": 5.0643720626831055,
      "learning_rate": 2.8297304283551728e-05,
      "loss": 1.364,
      "step": 9700
    },
    {
      "epoch": 3.0255,
      "grad_norm": 8.047356605529785,
      "learning_rate": 2.8276815343797637e-05,
      "loss": 1.5168,
      "step": 9705
    },
    {
      "epoch": 3.02575,
      "grad_norm": 8.330170631408691,
      "learning_rate": 2.825632416437115e-05,
      "loss": 1.4743,
      "step": 9710
    },
    {
      "epoch": 3.026,
      "grad_norm": 7.776607036590576,
      "learning_rate": 2.823583075927781e-05,
      "loss": 1.303,
      "step": 9715
    },
    {
      "epoch": 3.02625,
      "grad_norm": 9.341608047485352,
      "learning_rate": 2.8215335142524657e-05,
      "loss": 1.6179,
      "step": 9720
    },
    {
      "epoch": 3.0265,
      "grad_norm": 6.967910289764404,
      "learning_rate": 2.8194837328120256e-05,
      "loss": 1.2418,
      "step": 9725
    },
    {
      "epoch": 3.02675,
      "grad_norm": 8.878960609436035,
      "learning_rate": 2.817433733007466e-05,
      "loss": 1.3733,
      "step": 9730
    },
    {
      "epoch": 3.027,
      "grad_norm": 9.267698287963867,
      "learning_rate": 2.815383516239943e-05,
      "loss": 1.2956,
      "step": 9735
    },
    {
      "epoch": 3.02725,
      "grad_norm": 7.7586164474487305,
      "learning_rate": 2.8133330839107608e-05,
      "loss": 1.3513,
      "step": 9740
    },
    {
      "epoch": 3.0275,
      "grad_norm": 7.89613151550293,
      "learning_rate": 2.811282437421371e-05,
      "loss": 1.2232,
      "step": 9745
    },
    {
      "epoch": 3.02775,
      "grad_norm": 7.381293773651123,
      "learning_rate": 2.8092315781733696e-05,
      "loss": 1.4086,
      "step": 9750
    },
    {
      "epoch": 3.028,
      "grad_norm": 10.049551010131836,
      "learning_rate": 2.8071805075685004e-05,
      "loss": 1.3465,
      "step": 9755
    },
    {
      "epoch": 3.02825,
      "grad_norm": 8.937177658081055,
      "learning_rate": 2.8051292270086503e-05,
      "loss": 1.4805,
      "step": 9760
    },
    {
      "epoch": 3.0285,
      "grad_norm": 7.182989597320557,
      "learning_rate": 2.8030777378958522e-05,
      "loss": 1.2536,
      "step": 9765
    },
    {
      "epoch": 3.02875,
      "grad_norm": 10.135560035705566,
      "learning_rate": 2.8010260416322774e-05,
      "loss": 1.4176,
      "step": 9770
    },
    {
      "epoch": 3.029,
      "grad_norm": 8.119650840759277,
      "learning_rate": 2.798974139620242e-05,
      "loss": 1.3595,
      "step": 9775
    },
    {
      "epoch": 3.02925,
      "grad_norm": 7.315703392028809,
      "learning_rate": 2.7969220332622003e-05,
      "loss": 1.3417,
      "step": 9780
    },
    {
      "epoch": 3.0295,
      "grad_norm": 5.089139938354492,
      "learning_rate": 2.794869723960749e-05,
      "loss": 1.1536,
      "step": 9785
    },
    {
      "epoch": 3.02975,
      "grad_norm": 9.952975273132324,
      "learning_rate": 2.792817213118623e-05,
      "loss": 1.3343,
      "step": 9790
    },
    {
      "epoch": 3.03,
      "grad_norm": 5.921784400939941,
      "learning_rate": 2.7907645021386918e-05,
      "loss": 1.246,
      "step": 9795
    },
    {
      "epoch": 3.03025,
      "grad_norm": 9.383465766906738,
      "learning_rate": 2.788711592423966e-05,
      "loss": 1.3598,
      "step": 9800
    },
    {
      "epoch": 3.0305,
      "grad_norm": 6.498730182647705,
      "learning_rate": 2.786658485377588e-05,
      "loss": 1.3786,
      "step": 9805
    },
    {
      "epoch": 3.03075,
      "grad_norm": 8.765236854553223,
      "learning_rate": 2.7846051824028386e-05,
      "loss": 1.3606,
      "step": 9810
    },
    {
      "epoch": 3.031,
      "grad_norm": 5.908558368682861,
      "learning_rate": 2.782551684903132e-05,
      "loss": 1.2655,
      "step": 9815
    },
    {
      "epoch": 3.03125,
      "grad_norm": 7.4838995933532715,
      "learning_rate": 2.7804979942820113e-05,
      "loss": 1.4566,
      "step": 9820
    },
    {
      "epoch": 3.0315,
      "grad_norm": 8.296374320983887,
      "learning_rate": 2.7784441119431574e-05,
      "loss": 1.3036,
      "step": 9825
    },
    {
      "epoch": 3.03175,
      "grad_norm": 6.034587860107422,
      "learning_rate": 2.776390039290378e-05,
      "loss": 1.3365,
      "step": 9830
    },
    {
      "epoch": 3.032,
      "grad_norm": 7.746108055114746,
      "learning_rate": 2.774335777727613e-05,
      "loss": 1.188,
      "step": 9835
    },
    {
      "epoch": 3.03225,
      "grad_norm": 8.258023262023926,
      "learning_rate": 2.7722813286589316e-05,
      "loss": 1.2403,
      "step": 9840
    },
    {
      "epoch": 3.0325,
      "grad_norm": 8.395840644836426,
      "learning_rate": 2.770226693488529e-05,
      "loss": 1.1731,
      "step": 9845
    },
    {
      "epoch": 3.03275,
      "grad_norm": 7.888128757476807,
      "learning_rate": 2.7681718736207298e-05,
      "loss": 1.1534,
      "step": 9850
    },
    {
      "epoch": 3.033,
      "grad_norm": 8.058389663696289,
      "learning_rate": 2.766116870459983e-05,
      "loss": 1.2953,
      "step": 9855
    },
    {
      "epoch": 3.03325,
      "grad_norm": 6.243638038635254,
      "learning_rate": 2.764061685410865e-05,
      "loss": 1.3234,
      "step": 9860
    },
    {
      "epoch": 3.0335,
      "grad_norm": 6.973291873931885,
      "learning_rate": 2.762006319878075e-05,
      "loss": 1.3103,
      "step": 9865
    },
    {
      "epoch": 3.03375,
      "grad_norm": 9.216142654418945,
      "learning_rate": 2.7599507752664354e-05,
      "loss": 1.3931,
      "step": 9870
    },
    {
      "epoch": 3.034,
      "grad_norm": 7.581309795379639,
      "learning_rate": 2.757895052980893e-05,
      "loss": 1.5657,
      "step": 9875
    },
    {
      "epoch": 3.03425,
      "grad_norm": 7.126036643981934,
      "learning_rate": 2.755839154426513e-05,
      "loss": 1.2022,
      "step": 9880
    },
    {
      "epoch": 3.0345,
      "grad_norm": 7.373149871826172,
      "learning_rate": 2.7537830810084836e-05,
      "loss": 1.3853,
      "step": 9885
    },
    {
      "epoch": 3.03475,
      "grad_norm": 6.2134904861450195,
      "learning_rate": 2.7517268341321112e-05,
      "loss": 1.4356,
      "step": 9890
    },
    {
      "epoch": 3.035,
      "grad_norm": 6.95482873916626,
      "learning_rate": 2.7496704152028212e-05,
      "loss": 1.5641,
      "step": 9895
    },
    {
      "epoch": 3.03525,
      "grad_norm": 6.4353203773498535,
      "learning_rate": 2.7476138256261575e-05,
      "loss": 1.4709,
      "step": 9900
    },
    {
      "epoch": 3.0355,
      "grad_norm": 5.774919033050537,
      "learning_rate": 2.7455570668077772e-05,
      "loss": 1.3895,
      "step": 9905
    },
    {
      "epoch": 3.03575,
      "grad_norm": 6.455190181732178,
      "learning_rate": 2.7435001401534586e-05,
      "loss": 1.3823,
      "step": 9910
    },
    {
      "epoch": 3.036,
      "grad_norm": 7.886350154876709,
      "learning_rate": 2.7414430470690905e-05,
      "loss": 1.6361,
      "step": 9915
    },
    {
      "epoch": 3.03625,
      "grad_norm": 6.498394012451172,
      "learning_rate": 2.7393857889606756e-05,
      "loss": 1.4327,
      "step": 9920
    },
    {
      "epoch": 3.0365,
      "grad_norm": 6.306537628173828,
      "learning_rate": 2.7373283672343313e-05,
      "loss": 1.4381,
      "step": 9925
    },
    {
      "epoch": 3.03675,
      "grad_norm": 8.00343132019043,
      "learning_rate": 2.7352707832962865e-05,
      "loss": 1.4435,
      "step": 9930
    },
    {
      "epoch": 3.037,
      "grad_norm": 5.553341865539551,
      "learning_rate": 2.7332130385528788e-05,
      "loss": 1.4915,
      "step": 9935
    },
    {
      "epoch": 3.03725,
      "grad_norm": 6.474958419799805,
      "learning_rate": 2.731155134410559e-05,
      "loss": 1.4595,
      "step": 9940
    },
    {
      "epoch": 3.0375,
      "grad_norm": 7.8577375411987305,
      "learning_rate": 2.729097072275884e-05,
      "loss": 1.6688,
      "step": 9945
    },
    {
      "epoch": 3.03775,
      "grad_norm": 6.238348484039307,
      "learning_rate": 2.727038853555521e-05,
      "loss": 1.4181,
      "step": 9950
    },
    {
      "epoch": 3.038,
      "grad_norm": 6.003233909606934,
      "learning_rate": 2.7249804796562424e-05,
      "loss": 1.4068,
      "step": 9955
    },
    {
      "epoch": 3.03825,
      "grad_norm": 9.241667747497559,
      "learning_rate": 2.722921951984927e-05,
      "loss": 1.4749,
      "step": 9960
    },
    {
      "epoch": 3.0385,
      "grad_norm": 6.662079811096191,
      "learning_rate": 2.7208632719485594e-05,
      "loss": 1.4582,
      "step": 9965
    },
    {
      "epoch": 3.03875,
      "grad_norm": 6.87570858001709,
      "learning_rate": 2.7188044409542278e-05,
      "loss": 1.5964,
      "step": 9970
    },
    {
      "epoch": 3.039,
      "grad_norm": 6.404355049133301,
      "learning_rate": 2.7167454604091248e-05,
      "loss": 1.4237,
      "step": 9975
    },
    {
      "epoch": 3.03925,
      "grad_norm": 6.43510103225708,
      "learning_rate": 2.7146863317205427e-05,
      "loss": 1.41,
      "step": 9980
    },
    {
      "epoch": 3.0395,
      "grad_norm": 8.0402250289917,
      "learning_rate": 2.7126270562958777e-05,
      "loss": 1.464,
      "step": 9985
    },
    {
      "epoch": 3.03975,
      "grad_norm": 5.8385796546936035,
      "learning_rate": 2.7105676355426248e-05,
      "loss": 1.361,
      "step": 9990
    },
    {
      "epoch": 3.04,
      "grad_norm": 7.355503559112549,
      "learning_rate": 2.708508070868378e-05,
      "loss": 1.398,
      "step": 9995
    },
    {
      "epoch": 3.04025,
      "grad_norm": 5.741751670837402,
      "learning_rate": 2.7064483636808313e-05,
      "loss": 1.4546,
      "step": 10000
    },
    {
      "epoch": 3.04025,
      "eval_loss": 1.8688220977783203,
      "eval_runtime": 5.1232,
      "eval_samples_per_second": 199.875,
      "eval_steps_per_second": 24.984,
      "step": 10000
    },
    {
      "epoch": 3.0405,
      "grad_norm": 7.149292945861816,
      "learning_rate": 2.7043885153877747e-05,
      "loss": 1.3289,
      "step": 10005
    },
    {
      "epoch": 3.04075,
      "grad_norm": 5.3997297286987305,
      "learning_rate": 2.7023285273970945e-05,
      "loss": 1.2542,
      "step": 10010
    },
    {
      "epoch": 3.041,
      "grad_norm": 7.013234615325928,
      "learning_rate": 2.7002684011167744e-05,
      "loss": 1.5343,
      "step": 10015
    },
    {
      "epoch": 3.04125,
      "grad_norm": 7.497434616088867,
      "learning_rate": 2.6982081379548896e-05,
      "loss": 1.4326,
      "step": 10020
    },
    {
      "epoch": 3.0415,
      "grad_norm": 6.537264347076416,
      "learning_rate": 2.6961477393196126e-05,
      "loss": 1.4754,
      "step": 10025
    },
    {
      "epoch": 3.04175,
      "grad_norm": 5.987546920776367,
      "learning_rate": 2.6940872066192052e-05,
      "loss": 1.5282,
      "step": 10030
    },
    {
      "epoch": 3.042,
      "grad_norm": 8.480766296386719,
      "learning_rate": 2.6920265412620216e-05,
      "loss": 1.4468,
      "step": 10035
    },
    {
      "epoch": 3.04225,
      "grad_norm": 8.532293319702148,
      "learning_rate": 2.689965744656508e-05,
      "loss": 1.4295,
      "step": 10040
    },
    {
      "epoch": 3.0425,
      "grad_norm": 6.86662483215332,
      "learning_rate": 2.6879048182111995e-05,
      "loss": 1.5187,
      "step": 10045
    },
    {
      "epoch": 3.04275,
      "grad_norm": 7.279136657714844,
      "learning_rate": 2.6858437633347194e-05,
      "loss": 1.459,
      "step": 10050
    },
    {
      "epoch": 3.043,
      "grad_norm": 10.107657432556152,
      "learning_rate": 2.683782581435779e-05,
      "loss": 1.4197,
      "step": 10055
    },
    {
      "epoch": 3.04325,
      "grad_norm": 6.546870708465576,
      "learning_rate": 2.681721273923178e-05,
      "loss": 1.6339,
      "step": 10060
    },
    {
      "epoch": 3.0435,
      "grad_norm": 8.266746520996094,
      "learning_rate": 2.6796598422057996e-05,
      "loss": 1.648,
      "step": 10065
    },
    {
      "epoch": 3.04375,
      "grad_norm": 6.849856376647949,
      "learning_rate": 2.6775982876926126e-05,
      "loss": 1.3358,
      "step": 10070
    },
    {
      "epoch": 3.044,
      "grad_norm": 6.967376232147217,
      "learning_rate": 2.6755366117926707e-05,
      "loss": 1.4194,
      "step": 10075
    },
    {
      "epoch": 3.04425,
      "grad_norm": 5.588397979736328,
      "learning_rate": 2.6734748159151102e-05,
      "loss": 1.3598,
      "step": 10080
    },
    {
      "epoch": 3.0445,
      "grad_norm": 6.204470157623291,
      "learning_rate": 2.6714129014691487e-05,
      "loss": 1.4041,
      "step": 10085
    },
    {
      "epoch": 3.04475,
      "grad_norm": 7.947201728820801,
      "learning_rate": 2.6693508698640852e-05,
      "loss": 1.5247,
      "step": 10090
    },
    {
      "epoch": 3.045,
      "grad_norm": 6.4239501953125,
      "learning_rate": 2.6672887225092996e-05,
      "loss": 1.4398,
      "step": 10095
    },
    {
      "epoch": 3.04525,
      "grad_norm": 7.135522842407227,
      "learning_rate": 2.6652264608142484e-05,
      "loss": 1.4066,
      "step": 10100
    },
    {
      "epoch": 3.0455,
      "grad_norm": 8.081324577331543,
      "learning_rate": 2.6631640861884705e-05,
      "loss": 1.3829,
      "step": 10105
    },
    {
      "epoch": 3.04575,
      "grad_norm": 6.386754989624023,
      "learning_rate": 2.661101600041577e-05,
      "loss": 1.4064,
      "step": 10110
    },
    {
      "epoch": 3.046,
      "grad_norm": 6.2028422355651855,
      "learning_rate": 2.6590390037832603e-05,
      "loss": 1.3672,
      "step": 10115
    },
    {
      "epoch": 3.04625,
      "grad_norm": 7.432344436645508,
      "learning_rate": 2.656976298823284e-05,
      "loss": 1.5881,
      "step": 10120
    },
    {
      "epoch": 3.0465,
      "grad_norm": 5.930569648742676,
      "learning_rate": 2.6549134865714868e-05,
      "loss": 1.3266,
      "step": 10125
    },
    {
      "epoch": 3.04675,
      "grad_norm": 6.327096939086914,
      "learning_rate": 2.652850568437783e-05,
      "loss": 1.3505,
      "step": 10130
    },
    {
      "epoch": 3.047,
      "grad_norm": 7.422862529754639,
      "learning_rate": 2.650787545832156e-05,
      "loss": 1.3685,
      "step": 10135
    },
    {
      "epoch": 3.04725,
      "grad_norm": 6.556601047515869,
      "learning_rate": 2.6487244201646645e-05,
      "loss": 1.4513,
      "step": 10140
    },
    {
      "epoch": 3.0475,
      "grad_norm": 6.6858978271484375,
      "learning_rate": 2.6466611928454337e-05,
      "loss": 1.2912,
      "step": 10145
    },
    {
      "epoch": 3.04775,
      "grad_norm": 7.321056842803955,
      "learning_rate": 2.6445978652846602e-05,
      "loss": 1.4676,
      "step": 10150
    },
    {
      "epoch": 3.048,
      "grad_norm": 7.0233473777771,
      "learning_rate": 2.6425344388926097e-05,
      "loss": 1.5289,
      "step": 10155
    },
    {
      "epoch": 3.04825,
      "grad_norm": 8.197766304016113,
      "learning_rate": 2.6404709150796137e-05,
      "loss": 1.5664,
      "step": 10160
    },
    {
      "epoch": 3.0485,
      "grad_norm": 5.889864444732666,
      "learning_rate": 2.6384072952560724e-05,
      "loss": 1.4812,
      "step": 10165
    },
    {
      "epoch": 3.04875,
      "grad_norm": 5.4608049392700195,
      "learning_rate": 2.63634358083245e-05,
      "loss": 1.4972,
      "step": 10170
    },
    {
      "epoch": 3.049,
      "grad_norm": 7.768179893493652,
      "learning_rate": 2.634279773219275e-05,
      "loss": 1.521,
      "step": 10175
    },
    {
      "epoch": 3.04925,
      "grad_norm": 6.526345252990723,
      "learning_rate": 2.632215873827142e-05,
      "loss": 1.5009,
      "step": 10180
    },
    {
      "epoch": 3.0495,
      "grad_norm": 10.2233247756958,
      "learning_rate": 2.630151884066705e-05,
      "loss": 1.4898,
      "step": 10185
    },
    {
      "epoch": 3.04975,
      "grad_norm": 5.432093143463135,
      "learning_rate": 2.6280878053486828e-05,
      "loss": 1.313,
      "step": 10190
    },
    {
      "epoch": 3.05,
      "grad_norm": 7.392266273498535,
      "learning_rate": 2.6260236390838544e-05,
      "loss": 1.3593,
      "step": 10195
    },
    {
      "epoch": 3.05025,
      "grad_norm": 6.5120110511779785,
      "learning_rate": 2.623959386683056e-05,
      "loss": 1.4613,
      "step": 10200
    },
    {
      "epoch": 3.0505,
      "grad_norm": 6.555337905883789,
      "learning_rate": 2.621895049557186e-05,
      "loss": 1.4642,
      "step": 10205
    },
    {
      "epoch": 3.05075,
      "grad_norm": 6.124914169311523,
      "learning_rate": 2.6198306291171993e-05,
      "loss": 1.5619,
      "step": 10210
    },
    {
      "epoch": 3.051,
      "grad_norm": 5.6118292808532715,
      "learning_rate": 2.6177661267741065e-05,
      "loss": 1.3316,
      "step": 10215
    },
    {
      "epoch": 3.05125,
      "grad_norm": 5.78299617767334,
      "learning_rate": 2.6157015439389774e-05,
      "loss": 1.4477,
      "step": 10220
    },
    {
      "epoch": 3.0515,
      "grad_norm": 5.370274066925049,
      "learning_rate": 2.613636882022934e-05,
      "loss": 1.2951,
      "step": 10225
    },
    {
      "epoch": 3.05175,
      "grad_norm": 7.3620758056640625,
      "learning_rate": 2.6115721424371532e-05,
      "loss": 1.4677,
      "step": 10230
    },
    {
      "epoch": 3.052,
      "grad_norm": 6.296382427215576,
      "learning_rate": 2.6095073265928653e-05,
      "loss": 1.3243,
      "step": 10235
    },
    {
      "epoch": 3.05225,
      "grad_norm": 6.3323283195495605,
      "learning_rate": 2.6074424359013517e-05,
      "loss": 1.3709,
      "step": 10240
    },
    {
      "epoch": 3.0525,
      "grad_norm": 6.259681701660156,
      "learning_rate": 2.6053774717739467e-05,
      "loss": 1.3963,
      "step": 10245
    },
    {
      "epoch": 3.05275,
      "grad_norm": 7.4621076583862305,
      "learning_rate": 2.6033124356220328e-05,
      "loss": 1.369,
      "step": 10250
    },
    {
      "epoch": 3.053,
      "grad_norm": 7.128533363342285,
      "learning_rate": 2.6012473288570442e-05,
      "loss": 1.355,
      "step": 10255
    },
    {
      "epoch": 3.05325,
      "grad_norm": 6.375155448913574,
      "learning_rate": 2.599182152890461e-05,
      "loss": 1.378,
      "step": 10260
    },
    {
      "epoch": 3.0535,
      "grad_norm": 7.452795505523682,
      "learning_rate": 2.597116909133811e-05,
      "loss": 1.2872,
      "step": 10265
    },
    {
      "epoch": 3.05375,
      "grad_norm": 6.2052202224731445,
      "learning_rate": 2.5950515989986697e-05,
      "loss": 1.2733,
      "step": 10270
    },
    {
      "epoch": 3.054,
      "grad_norm": 6.737959384918213,
      "learning_rate": 2.592986223896656e-05,
      "loss": 1.2378,
      "step": 10275
    },
    {
      "epoch": 3.05425,
      "grad_norm": 6.9065842628479,
      "learning_rate": 2.5909207852394363e-05,
      "loss": 1.2603,
      "step": 10280
    },
    {
      "epoch": 3.0545,
      "grad_norm": 7.319299697875977,
      "learning_rate": 2.5888552844387165e-05,
      "loss": 1.5399,
      "step": 10285
    },
    {
      "epoch": 3.05475,
      "grad_norm": 5.6619462966918945,
      "learning_rate": 2.5867897229062478e-05,
      "loss": 1.5222,
      "step": 10290
    },
    {
      "epoch": 3.055,
      "grad_norm": 7.5726752281188965,
      "learning_rate": 2.5847241020538216e-05,
      "loss": 1.3716,
      "step": 10295
    },
    {
      "epoch": 3.05525,
      "grad_norm": 5.335969924926758,
      "learning_rate": 2.5826584232932706e-05,
      "loss": 1.3839,
      "step": 10300
    },
    {
      "epoch": 3.0555,
      "grad_norm": 6.556778907775879,
      "learning_rate": 2.5805926880364667e-05,
      "loss": 1.3167,
      "step": 10305
    },
    {
      "epoch": 3.05575,
      "grad_norm": 6.466006755828857,
      "learning_rate": 2.578526897695321e-05,
      "loss": 1.4159,
      "step": 10310
    },
    {
      "epoch": 3.056,
      "grad_norm": 6.323899745941162,
      "learning_rate": 2.5764610536817808e-05,
      "loss": 1.3875,
      "step": 10315
    },
    {
      "epoch": 3.05625,
      "grad_norm": 8.547119140625,
      "learning_rate": 2.5743951574078314e-05,
      "loss": 1.4736,
      "step": 10320
    },
    {
      "epoch": 3.0565,
      "grad_norm": 5.281199932098389,
      "learning_rate": 2.572329210285493e-05,
      "loss": 1.2333,
      "step": 10325
    },
    {
      "epoch": 3.05675,
      "grad_norm": 8.741852760314941,
      "learning_rate": 2.5702632137268223e-05,
      "loss": 1.4014,
      "step": 10330
    },
    {
      "epoch": 3.057,
      "grad_norm": 5.466772079467773,
      "learning_rate": 2.5681971691439073e-05,
      "loss": 1.22,
      "step": 10335
    },
    {
      "epoch": 3.05725,
      "grad_norm": 5.192073822021484,
      "learning_rate": 2.5661310779488695e-05,
      "loss": 1.3859,
      "step": 10340
    },
    {
      "epoch": 3.0575,
      "grad_norm": 6.946819305419922,
      "learning_rate": 2.5640649415538643e-05,
      "loss": 1.3934,
      "step": 10345
    },
    {
      "epoch": 3.05775,
      "grad_norm": 6.9402947425842285,
      "learning_rate": 2.5619987613710756e-05,
      "loss": 1.2352,
      "step": 10350
    },
    {
      "epoch": 3.058,
      "grad_norm": 6.154059886932373,
      "learning_rate": 2.5599325388127175e-05,
      "loss": 1.1922,
      "step": 10355
    },
    {
      "epoch": 3.05825,
      "grad_norm": 6.837372303009033,
      "learning_rate": 2.5578662752910347e-05,
      "loss": 1.2184,
      "step": 10360
    },
    {
      "epoch": 3.0585,
      "grad_norm": 6.210599899291992,
      "learning_rate": 2.5557999722182983e-05,
      "loss": 1.3763,
      "step": 10365
    },
    {
      "epoch": 3.05875,
      "grad_norm": 8.442010879516602,
      "learning_rate": 2.553733631006807e-05,
      "loss": 1.2952,
      "step": 10370
    },
    {
      "epoch": 3.059,
      "grad_norm": 8.196372032165527,
      "learning_rate": 2.551667253068886e-05,
      "loss": 1.5186,
      "step": 10375
    },
    {
      "epoch": 3.05925,
      "grad_norm": 5.0653557777404785,
      "learning_rate": 2.5496008398168843e-05,
      "loss": 1.3001,
      "step": 10380
    },
    {
      "epoch": 3.0595,
      "grad_norm": 7.115592956542969,
      "learning_rate": 2.5475343926631768e-05,
      "loss": 1.4856,
      "step": 10385
    },
    {
      "epoch": 3.05975,
      "grad_norm": 8.246061325073242,
      "learning_rate": 2.5454679130201593e-05,
      "loss": 1.3814,
      "step": 10390
    },
    {
      "epoch": 3.06,
      "grad_norm": 7.785389423370361,
      "learning_rate": 2.5434014023002524e-05,
      "loss": 1.5451,
      "step": 10395
    },
    {
      "epoch": 3.06025,
      "grad_norm": 6.667870044708252,
      "learning_rate": 2.5413348619158967e-05,
      "loss": 1.4086,
      "step": 10400
    },
    {
      "epoch": 3.0605,
      "grad_norm": 7.792492866516113,
      "learning_rate": 2.539268293279552e-05,
      "loss": 1.5759,
      "step": 10405
    },
    {
      "epoch": 3.06075,
      "grad_norm": 6.5733795166015625,
      "learning_rate": 2.5372016978036995e-05,
      "loss": 1.3494,
      "step": 10410
    },
    {
      "epoch": 3.061,
      "grad_norm": 6.742259979248047,
      "learning_rate": 2.5351350769008364e-05,
      "loss": 1.3423,
      "step": 10415
    },
    {
      "epoch": 3.06125,
      "grad_norm": 7.746342182159424,
      "learning_rate": 2.5330684319834814e-05,
      "loss": 1.3271,
      "step": 10420
    },
    {
      "epoch": 3.0615,
      "grad_norm": 5.605429649353027,
      "learning_rate": 2.5310017644641638e-05,
      "loss": 1.3843,
      "step": 10425
    },
    {
      "epoch": 3.06175,
      "grad_norm": 7.143620014190674,
      "learning_rate": 2.528935075755432e-05,
      "loss": 1.332,
      "step": 10430
    },
    {
      "epoch": 3.062,
      "grad_norm": 6.116764545440674,
      "learning_rate": 2.5268683672698494e-05,
      "loss": 1.4005,
      "step": 10435
    },
    {
      "epoch": 3.06225,
      "grad_norm": 8.230877876281738,
      "learning_rate": 2.5248016404199908e-05,
      "loss": 1.4315,
      "step": 10440
    },
    {
      "epoch": 3.0625,
      "grad_norm": 5.639559268951416,
      "learning_rate": 2.522734896618446e-05,
      "loss": 1.1811,
      "step": 10445
    },
    {
      "epoch": 3.06275,
      "grad_norm": 7.9141845703125,
      "learning_rate": 2.5206681372778124e-05,
      "loss": 1.2517,
      "step": 10450
    },
    {
      "epoch": 3.063,
      "grad_norm": 7.0268473625183105,
      "learning_rate": 2.518601363810702e-05,
      "loss": 1.4158,
      "step": 10455
    },
    {
      "epoch": 3.06325,
      "grad_norm": 7.224320411682129,
      "learning_rate": 2.5165345776297355e-05,
      "loss": 1.4987,
      "step": 10460
    },
    {
      "epoch": 3.0635,
      "grad_norm": 5.719693183898926,
      "learning_rate": 2.514467780147541e-05,
      "loss": 1.2057,
      "step": 10465
    },
    {
      "epoch": 3.06375,
      "grad_norm": 6.770814418792725,
      "learning_rate": 2.512400972776755e-05,
      "loss": 1.3313,
      "step": 10470
    },
    {
      "epoch": 3.064,
      "grad_norm": 8.133658409118652,
      "learning_rate": 2.5103341569300208e-05,
      "loss": 1.2855,
      "step": 10475
    },
    {
      "epoch": 3.06425,
      "grad_norm": 9.28123950958252,
      "learning_rate": 2.508267334019988e-05,
      "loss": 1.4426,
      "step": 10480
    },
    {
      "epoch": 3.0645,
      "grad_norm": 4.7501702308654785,
      "learning_rate": 2.50620050545931e-05,
      "loss": 1.2712,
      "step": 10485
    },
    {
      "epoch": 3.06475,
      "grad_norm": 7.726480960845947,
      "learning_rate": 2.5041336726606457e-05,
      "loss": 1.4592,
      "step": 10490
    },
    {
      "epoch": 3.065,
      "grad_norm": 8.565584182739258,
      "learning_rate": 2.502066837036655e-05,
      "loss": 1.4906,
      "step": 10495
    },
    {
      "epoch": 3.06525,
      "grad_norm": 8.782578468322754,
      "learning_rate": 2.5e-05,
      "loss": 1.5196,
      "step": 10500
    },
    {
      "epoch": 3.06525,
      "eval_loss": 1.9050081968307495,
      "eval_runtime": 5.1661,
      "eval_samples_per_second": 198.216,
      "eval_steps_per_second": 24.777,
      "step": 10500
    },
    {
      "epoch": 3.0655,
      "grad_norm": 7.272725582122803,
      "learning_rate": 2.4979331629633455e-05,
      "loss": 1.3689,
      "step": 10505
    },
    {
      "epoch": 3.06575,
      "grad_norm": 7.104881286621094,
      "learning_rate": 2.4958663273393546e-05,
      "loss": 1.3172,
      "step": 10510
    },
    {
      "epoch": 3.066,
      "grad_norm": 6.523171901702881,
      "learning_rate": 2.4937994945406894e-05,
      "loss": 1.337,
      "step": 10515
    },
    {
      "epoch": 3.06625,
      "grad_norm": 8.441786766052246,
      "learning_rate": 2.4917326659800123e-05,
      "loss": 1.5825,
      "step": 10520
    },
    {
      "epoch": 3.0665,
      "grad_norm": 7.7033281326293945,
      "learning_rate": 2.48966584306998e-05,
      "loss": 1.3658,
      "step": 10525
    },
    {
      "epoch": 3.06675,
      "grad_norm": 7.96065092086792,
      "learning_rate": 2.487599027223246e-05,
      "loss": 1.3371,
      "step": 10530
    },
    {
      "epoch": 3.067,
      "grad_norm": 6.520547866821289,
      "learning_rate": 2.48553221985246e-05,
      "loss": 1.3158,
      "step": 10535
    },
    {
      "epoch": 3.06725,
      "grad_norm": 5.719448566436768,
      "learning_rate": 2.483465422370265e-05,
      "loss": 1.2221,
      "step": 10540
    },
    {
      "epoch": 3.0675,
      "grad_norm": 6.342881679534912,
      "learning_rate": 2.4813986361892982e-05,
      "loss": 1.2117,
      "step": 10545
    },
    {
      "epoch": 3.06775,
      "grad_norm": 6.315143585205078,
      "learning_rate": 2.4793318627221878e-05,
      "loss": 1.1701,
      "step": 10550
    },
    {
      "epoch": 3.068,
      "grad_norm": 5.144096374511719,
      "learning_rate": 2.4772651033815544e-05,
      "loss": 1.4157,
      "step": 10555
    },
    {
      "epoch": 3.06825,
      "grad_norm": 5.623209476470947,
      "learning_rate": 2.475198359580009e-05,
      "loss": 1.3198,
      "step": 10560
    },
    {
      "epoch": 3.0685000000000002,
      "grad_norm": 5.255921840667725,
      "learning_rate": 2.4731316327301505e-05,
      "loss": 1.2942,
      "step": 10565
    },
    {
      "epoch": 3.06875,
      "grad_norm": 5.109464168548584,
      "learning_rate": 2.4710649242445686e-05,
      "loss": 1.2079,
      "step": 10570
    },
    {
      "epoch": 3.069,
      "grad_norm": 4.287025451660156,
      "learning_rate": 2.4689982355358375e-05,
      "loss": 1.1888,
      "step": 10575
    },
    {
      "epoch": 3.06925,
      "grad_norm": 6.97625207901001,
      "learning_rate": 2.46693156801652e-05,
      "loss": 1.2183,
      "step": 10580
    },
    {
      "epoch": 3.0695,
      "grad_norm": 4.249688625335693,
      "learning_rate": 2.4648649230991638e-05,
      "loss": 1.1893,
      "step": 10585
    },
    {
      "epoch": 3.06975,
      "grad_norm": 4.153488636016846,
      "learning_rate": 2.4627983021963014e-05,
      "loss": 1.246,
      "step": 10590
    },
    {
      "epoch": 3.07,
      "grad_norm": 5.722542762756348,
      "learning_rate": 2.460731706720449e-05,
      "loss": 1.2908,
      "step": 10595
    },
    {
      "epoch": 3.07025,
      "grad_norm": 5.230871677398682,
      "learning_rate": 2.458665138084104e-05,
      "loss": 1.122,
      "step": 10600
    },
    {
      "epoch": 3.0705,
      "grad_norm": 4.284809589385986,
      "learning_rate": 2.4565985976997475e-05,
      "loss": 1.2466,
      "step": 10605
    },
    {
      "epoch": 3.07075,
      "grad_norm": 5.101102352142334,
      "learning_rate": 2.4545320869798406e-05,
      "loss": 1.1798,
      "step": 10610
    },
    {
      "epoch": 3.071,
      "grad_norm": 5.3183274269104,
      "learning_rate": 2.4524656073368234e-05,
      "loss": 1.0804,
      "step": 10615
    },
    {
      "epoch": 3.07125,
      "grad_norm": 4.620340824127197,
      "learning_rate": 2.4503991601831163e-05,
      "loss": 1.111,
      "step": 10620
    },
    {
      "epoch": 3.0715,
      "grad_norm": 5.746389389038086,
      "learning_rate": 2.4483327469311148e-05,
      "loss": 1.2014,
      "step": 10625
    },
    {
      "epoch": 3.07175,
      "grad_norm": 5.838804721832275,
      "learning_rate": 2.4462663689931935e-05,
      "loss": 1.463,
      "step": 10630
    },
    {
      "epoch": 3.072,
      "grad_norm": 5.01365327835083,
      "learning_rate": 2.4442000277817023e-05,
      "loss": 1.2804,
      "step": 10635
    },
    {
      "epoch": 3.07225,
      "grad_norm": 4.8325934410095215,
      "learning_rate": 2.4421337247089655e-05,
      "loss": 1.1715,
      "step": 10640
    },
    {
      "epoch": 3.0725,
      "grad_norm": 5.312079429626465,
      "learning_rate": 2.4400674611872827e-05,
      "loss": 1.0542,
      "step": 10645
    },
    {
      "epoch": 3.07275,
      "grad_norm": 5.151944637298584,
      "learning_rate": 2.438001238628925e-05,
      "loss": 1.2559,
      "step": 10650
    },
    {
      "epoch": 3.073,
      "grad_norm": 4.684701919555664,
      "learning_rate": 2.435935058446136e-05,
      "loss": 1.2034,
      "step": 10655
    },
    {
      "epoch": 3.07325,
      "grad_norm": 6.371712684631348,
      "learning_rate": 2.4338689220511304e-05,
      "loss": 1.1352,
      "step": 10660
    },
    {
      "epoch": 3.0735,
      "grad_norm": 5.2905659675598145,
      "learning_rate": 2.431802830856094e-05,
      "loss": 1.0448,
      "step": 10665
    },
    {
      "epoch": 3.07375,
      "grad_norm": 4.43856143951416,
      "learning_rate": 2.4297367862731783e-05,
      "loss": 1.2844,
      "step": 10670
    },
    {
      "epoch": 3.074,
      "grad_norm": 5.868048191070557,
      "learning_rate": 2.4276707897145073e-05,
      "loss": 1.1378,
      "step": 10675
    },
    {
      "epoch": 3.07425,
      "grad_norm": 4.895822525024414,
      "learning_rate": 2.425604842592169e-05,
      "loss": 1.1674,
      "step": 10680
    },
    {
      "epoch": 3.0745,
      "grad_norm": 6.620644569396973,
      "learning_rate": 2.4235389463182198e-05,
      "loss": 1.2786,
      "step": 10685
    },
    {
      "epoch": 3.07475,
      "grad_norm": 4.1239848136901855,
      "learning_rate": 2.4214731023046793e-05,
      "loss": 1.0334,
      "step": 10690
    },
    {
      "epoch": 3.075,
      "grad_norm": 4.34718656539917,
      "learning_rate": 2.4194073119635335e-05,
      "loss": 1.0397,
      "step": 10695
    },
    {
      "epoch": 3.07525,
      "grad_norm": 6.193322658538818,
      "learning_rate": 2.4173415767067297e-05,
      "loss": 1.1923,
      "step": 10700
    },
    {
      "epoch": 3.0755,
      "grad_norm": 5.57265567779541,
      "learning_rate": 2.4152758979461783e-05,
      "loss": 1.2871,
      "step": 10705
    },
    {
      "epoch": 3.07575,
      "grad_norm": 5.68934965133667,
      "learning_rate": 2.413210277093753e-05,
      "loss": 1.1987,
      "step": 10710
    },
    {
      "epoch": 3.076,
      "grad_norm": 5.834832191467285,
      "learning_rate": 2.4111447155612847e-05,
      "loss": 1.3188,
      "step": 10715
    },
    {
      "epoch": 3.07625,
      "grad_norm": 4.896517276763916,
      "learning_rate": 2.4090792147605647e-05,
      "loss": 1.2256,
      "step": 10720
    },
    {
      "epoch": 3.0765,
      "grad_norm": 4.936000823974609,
      "learning_rate": 2.4070137761033444e-05,
      "loss": 1.1543,
      "step": 10725
    },
    {
      "epoch": 3.07675,
      "grad_norm": 5.31756591796875,
      "learning_rate": 2.404948401001331e-05,
      "loss": 1.1573,
      "step": 10730
    },
    {
      "epoch": 3.077,
      "grad_norm": 5.092043876647949,
      "learning_rate": 2.4028830908661897e-05,
      "loss": 1.091,
      "step": 10735
    },
    {
      "epoch": 3.07725,
      "grad_norm": 4.898284912109375,
      "learning_rate": 2.4008178471095397e-05,
      "loss": 1.1464,
      "step": 10740
    },
    {
      "epoch": 3.0775,
      "grad_norm": 5.924495697021484,
      "learning_rate": 2.398752671142956e-05,
      "loss": 1.2405,
      "step": 10745
    },
    {
      "epoch": 3.07775,
      "grad_norm": 4.851766586303711,
      "learning_rate": 2.3966875643779667e-05,
      "loss": 1.1251,
      "step": 10750
    },
    {
      "epoch": 3.078,
      "grad_norm": 5.257874011993408,
      "learning_rate": 2.3946225282260532e-05,
      "loss": 1.2216,
      "step": 10755
    },
    {
      "epoch": 3.07825,
      "grad_norm": 4.544848918914795,
      "learning_rate": 2.392557564098649e-05,
      "loss": 1.1187,
      "step": 10760
    },
    {
      "epoch": 3.0785,
      "grad_norm": 5.801175594329834,
      "learning_rate": 2.390492673407136e-05,
      "loss": 1.0654,
      "step": 10765
    },
    {
      "epoch": 3.07875,
      "grad_norm": 5.138978481292725,
      "learning_rate": 2.388427857562847e-05,
      "loss": 1.11,
      "step": 10770
    },
    {
      "epoch": 3.079,
      "grad_norm": 7.241718769073486,
      "learning_rate": 2.3863631179770666e-05,
      "loss": 1.1285,
      "step": 10775
    },
    {
      "epoch": 3.07925,
      "grad_norm": 5.8735432624816895,
      "learning_rate": 2.3842984560610228e-05,
      "loss": 1.2386,
      "step": 10780
    },
    {
      "epoch": 3.0795,
      "grad_norm": 5.175800323486328,
      "learning_rate": 2.3822338732258937e-05,
      "loss": 1.1021,
      "step": 10785
    },
    {
      "epoch": 3.07975,
      "grad_norm": 6.992315769195557,
      "learning_rate": 2.3801693708828013e-05,
      "loss": 1.1926,
      "step": 10790
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.0947675704956055,
      "learning_rate": 2.378104950442814e-05,
      "loss": 1.1597,
      "step": 10795
    },
    {
      "epoch": 3.08025,
      "grad_norm": 5.077978134155273,
      "learning_rate": 2.3760406133169443e-05,
      "loss": 1.2597,
      "step": 10800
    },
    {
      "epoch": 3.0805,
      "grad_norm": 5.707054138183594,
      "learning_rate": 2.373976360916147e-05,
      "loss": 1.2087,
      "step": 10805
    },
    {
      "epoch": 3.08075,
      "grad_norm": 6.896867752075195,
      "learning_rate": 2.3719121946513174e-05,
      "loss": 1.2257,
      "step": 10810
    },
    {
      "epoch": 3.081,
      "grad_norm": 4.586944103240967,
      "learning_rate": 2.3698481159332957e-05,
      "loss": 1.2139,
      "step": 10815
    },
    {
      "epoch": 3.08125,
      "grad_norm": 5.023406028747559,
      "learning_rate": 2.367784126172859e-05,
      "loss": 1.2538,
      "step": 10820
    },
    {
      "epoch": 3.0815,
      "grad_norm": 4.6349897384643555,
      "learning_rate": 2.3657202267807257e-05,
      "loss": 1.1977,
      "step": 10825
    },
    {
      "epoch": 3.08175,
      "grad_norm": 4.340579509735107,
      "learning_rate": 2.3636564191675507e-05,
      "loss": 1.2023,
      "step": 10830
    },
    {
      "epoch": 3.082,
      "grad_norm": 4.452878475189209,
      "learning_rate": 2.3615927047439282e-05,
      "loss": 1.2648,
      "step": 10835
    },
    {
      "epoch": 3.08225,
      "grad_norm": 4.98613977432251,
      "learning_rate": 2.3595290849203862e-05,
      "loss": 1.164,
      "step": 10840
    },
    {
      "epoch": 3.0825,
      "grad_norm": 5.029144287109375,
      "learning_rate": 2.3574655611073905e-05,
      "loss": 1.2364,
      "step": 10845
    },
    {
      "epoch": 3.08275,
      "grad_norm": 4.36344575881958,
      "learning_rate": 2.3554021347153403e-05,
      "loss": 1.1822,
      "step": 10850
    },
    {
      "epoch": 3.083,
      "grad_norm": 4.89879035949707,
      "learning_rate": 2.3533388071545672e-05,
      "loss": 1.1423,
      "step": 10855
    },
    {
      "epoch": 3.08325,
      "grad_norm": 5.922097206115723,
      "learning_rate": 2.351275579835336e-05,
      "loss": 1.1185,
      "step": 10860
    },
    {
      "epoch": 3.0835,
      "grad_norm": 6.897795677185059,
      "learning_rate": 2.349212454167844e-05,
      "loss": 1.3085,
      "step": 10865
    },
    {
      "epoch": 3.08375,
      "grad_norm": 4.438516139984131,
      "learning_rate": 2.3471494315622177e-05,
      "loss": 1.072,
      "step": 10870
    },
    {
      "epoch": 3.084,
      "grad_norm": 6.63950252532959,
      "learning_rate": 2.3450865134285138e-05,
      "loss": 1.0083,
      "step": 10875
    },
    {
      "epoch": 3.08425,
      "grad_norm": 3.7729954719543457,
      "learning_rate": 2.3430237011767167e-05,
      "loss": 0.9439,
      "step": 10880
    },
    {
      "epoch": 3.0845,
      "grad_norm": 7.0810346603393555,
      "learning_rate": 2.34096099621674e-05,
      "loss": 1.1942,
      "step": 10885
    },
    {
      "epoch": 3.08475,
      "grad_norm": 4.141407489776611,
      "learning_rate": 2.3388983999584224e-05,
      "loss": 0.9807,
      "step": 10890
    },
    {
      "epoch": 3.085,
      "grad_norm": 5.387132167816162,
      "learning_rate": 2.336835913811529e-05,
      "loss": 1.0112,
      "step": 10895
    },
    {
      "epoch": 3.08525,
      "grad_norm": 5.029997825622559,
      "learning_rate": 2.334773539185752e-05,
      "loss": 1.0279,
      "step": 10900
    },
    {
      "epoch": 3.0855,
      "grad_norm": 4.472046375274658,
      "learning_rate": 2.3327112774907016e-05,
      "loss": 0.9294,
      "step": 10905
    },
    {
      "epoch": 3.08575,
      "grad_norm": 4.869704246520996,
      "learning_rate": 2.330649130135915e-05,
      "loss": 1.0842,
      "step": 10910
    },
    {
      "epoch": 3.086,
      "grad_norm": 5.285022735595703,
      "learning_rate": 2.328587098530852e-05,
      "loss": 1.15,
      "step": 10915
    },
    {
      "epoch": 3.08625,
      "grad_norm": 5.104526996612549,
      "learning_rate": 2.32652518408489e-05,
      "loss": 0.9626,
      "step": 10920
    },
    {
      "epoch": 3.0865,
      "grad_norm": 5.0314812660217285,
      "learning_rate": 2.3244633882073296e-05,
      "loss": 1.0082,
      "step": 10925
    },
    {
      "epoch": 3.08675,
      "grad_norm": 4.864810943603516,
      "learning_rate": 2.3224017123073877e-05,
      "loss": 1.0256,
      "step": 10930
    },
    {
      "epoch": 3.087,
      "grad_norm": 6.037816524505615,
      "learning_rate": 2.3203401577942013e-05,
      "loss": 1.1438,
      "step": 10935
    },
    {
      "epoch": 3.08725,
      "grad_norm": 5.385046482086182,
      "learning_rate": 2.3182787260768223e-05,
      "loss": 1.0597,
      "step": 10940
    },
    {
      "epoch": 3.0875,
      "grad_norm": 5.932366847991943,
      "learning_rate": 2.3162174185642214e-05,
      "loss": 1.0657,
      "step": 10945
    },
    {
      "epoch": 3.0877499999999998,
      "grad_norm": 5.4291534423828125,
      "learning_rate": 2.3141562366652812e-05,
      "loss": 0.9731,
      "step": 10950
    },
    {
      "epoch": 3.088,
      "grad_norm": 6.080336093902588,
      "learning_rate": 2.3120951817888014e-05,
      "loss": 1.0169,
      "step": 10955
    },
    {
      "epoch": 3.08825,
      "grad_norm": 5.148892402648926,
      "learning_rate": 2.3100342553434924e-05,
      "loss": 1.0116,
      "step": 10960
    },
    {
      "epoch": 3.0885,
      "grad_norm": 6.044371128082275,
      "learning_rate": 2.307973458737979e-05,
      "loss": 0.9469,
      "step": 10965
    },
    {
      "epoch": 3.08875,
      "grad_norm": 5.0270514488220215,
      "learning_rate": 2.3059127933807954e-05,
      "loss": 1.1223,
      "step": 10970
    },
    {
      "epoch": 3.089,
      "grad_norm": 5.090008735656738,
      "learning_rate": 2.303852260680388e-05,
      "loss": 1.0732,
      "step": 10975
    },
    {
      "epoch": 3.08925,
      "grad_norm": 5.401270866394043,
      "learning_rate": 2.30179186204511e-05,
      "loss": 1.0133,
      "step": 10980
    },
    {
      "epoch": 3.0895,
      "grad_norm": 6.197673320770264,
      "learning_rate": 2.299731598883226e-05,
      "loss": 1.0418,
      "step": 10985
    },
    {
      "epoch": 3.08975,
      "grad_norm": 5.543561935424805,
      "learning_rate": 2.2976714726029068e-05,
      "loss": 0.9364,
      "step": 10990
    },
    {
      "epoch": 3.09,
      "grad_norm": 6.323537349700928,
      "learning_rate": 2.2956114846122265e-05,
      "loss": 1.0986,
      "step": 10995
    },
    {
      "epoch": 3.09025,
      "grad_norm": 5.949553966522217,
      "learning_rate": 2.2935516363191693e-05,
      "loss": 1.0514,
      "step": 11000
    },
    {
      "epoch": 3.09025,
      "eval_loss": 2.0292234420776367,
      "eval_runtime": 5.2532,
      "eval_samples_per_second": 194.93,
      "eval_steps_per_second": 24.366,
      "step": 11000
    },
    {
      "epoch": 3.0905,
      "grad_norm": 5.625827789306641,
      "learning_rate": 2.2914919291316228e-05,
      "loss": 0.9273,
      "step": 11005
    },
    {
      "epoch": 3.09075,
      "grad_norm": 5.621026992797852,
      "learning_rate": 2.2894323644573758e-05,
      "loss": 0.8674,
      "step": 11010
    },
    {
      "epoch": 3.091,
      "grad_norm": 4.98321008682251,
      "learning_rate": 2.2873729437041232e-05,
      "loss": 1.0066,
      "step": 11015
    },
    {
      "epoch": 3.09125,
      "grad_norm": 5.134775638580322,
      "learning_rate": 2.2853136682794575e-05,
      "loss": 1.0421,
      "step": 11020
    },
    {
      "epoch": 3.0915,
      "grad_norm": 6.074800968170166,
      "learning_rate": 2.2832545395908758e-05,
      "loss": 1.187,
      "step": 11025
    },
    {
      "epoch": 3.09175,
      "grad_norm": 4.4471354484558105,
      "learning_rate": 2.281195559045772e-05,
      "loss": 1.2437,
      "step": 11030
    },
    {
      "epoch": 3.092,
      "grad_norm": 4.704685688018799,
      "learning_rate": 2.279136728051441e-05,
      "loss": 1.0069,
      "step": 11035
    },
    {
      "epoch": 3.09225,
      "grad_norm": 5.403308868408203,
      "learning_rate": 2.2770780480150744e-05,
      "loss": 1.1636,
      "step": 11040
    },
    {
      "epoch": 3.0925,
      "grad_norm": 5.245677471160889,
      "learning_rate": 2.275019520343759e-05,
      "loss": 1.0496,
      "step": 11045
    },
    {
      "epoch": 3.09275,
      "grad_norm": 4.40708065032959,
      "learning_rate": 2.2729611464444794e-05,
      "loss": 1.1441,
      "step": 11050
    },
    {
      "epoch": 3.093,
      "grad_norm": 6.01447868347168,
      "learning_rate": 2.2709029277241163e-05,
      "loss": 1.0555,
      "step": 11055
    },
    {
      "epoch": 3.09325,
      "grad_norm": 4.56278133392334,
      "learning_rate": 2.2688448655894415e-05,
      "loss": 1.1281,
      "step": 11060
    },
    {
      "epoch": 3.0935,
      "grad_norm": 5.821682929992676,
      "learning_rate": 2.2667869614471214e-05,
      "loss": 1.1518,
      "step": 11065
    },
    {
      "epoch": 3.09375,
      "grad_norm": 5.667253494262695,
      "learning_rate": 2.2647292167037144e-05,
      "loss": 1.3249,
      "step": 11070
    },
    {
      "epoch": 3.094,
      "grad_norm": 4.776267051696777,
      "learning_rate": 2.262671632765669e-05,
      "loss": 1.041,
      "step": 11075
    },
    {
      "epoch": 3.09425,
      "grad_norm": 5.950267791748047,
      "learning_rate": 2.2606142110393247e-05,
      "loss": 1.0144,
      "step": 11080
    },
    {
      "epoch": 3.0945,
      "grad_norm": 4.0275774002075195,
      "learning_rate": 2.2585569529309104e-05,
      "loss": 0.9931,
      "step": 11085
    },
    {
      "epoch": 3.09475,
      "grad_norm": 5.766414165496826,
      "learning_rate": 2.2564998598465423e-05,
      "loss": 1.1382,
      "step": 11090
    },
    {
      "epoch": 3.095,
      "grad_norm": 6.146126747131348,
      "learning_rate": 2.254442933192223e-05,
      "loss": 1.1383,
      "step": 11095
    },
    {
      "epoch": 3.09525,
      "grad_norm": 5.347612380981445,
      "learning_rate": 2.2523861743738434e-05,
      "loss": 1.0922,
      "step": 11100
    },
    {
      "epoch": 3.0955,
      "grad_norm": 5.570993423461914,
      "learning_rate": 2.2503295847971793e-05,
      "loss": 1.1737,
      "step": 11105
    },
    {
      "epoch": 3.09575,
      "grad_norm": 6.301734924316406,
      "learning_rate": 2.248273165867889e-05,
      "loss": 1.2184,
      "step": 11110
    },
    {
      "epoch": 3.096,
      "grad_norm": 5.898129940032959,
      "learning_rate": 2.2462169189915173e-05,
      "loss": 1.2249,
      "step": 11115
    },
    {
      "epoch": 3.09625,
      "grad_norm": 5.445471286773682,
      "learning_rate": 2.2441608455734873e-05,
      "loss": 1.1537,
      "step": 11120
    },
    {
      "epoch": 3.0965,
      "grad_norm": 4.8386006355285645,
      "learning_rate": 2.2421049470191077e-05,
      "loss": 1.1359,
      "step": 11125
    },
    {
      "epoch": 3.09675,
      "grad_norm": 5.853489398956299,
      "learning_rate": 2.240049224733566e-05,
      "loss": 1.1442,
      "step": 11130
    },
    {
      "epoch": 3.097,
      "grad_norm": 6.161493301391602,
      "learning_rate": 2.237993680121926e-05,
      "loss": 1.0489,
      "step": 11135
    },
    {
      "epoch": 3.09725,
      "grad_norm": 4.813571453094482,
      "learning_rate": 2.2359383145891364e-05,
      "loss": 1.0402,
      "step": 11140
    },
    {
      "epoch": 3.0975,
      "grad_norm": 10.984758377075195,
      "learning_rate": 2.2338831295400177e-05,
      "loss": 1.146,
      "step": 11145
    },
    {
      "epoch": 3.09775,
      "grad_norm": 7.305635929107666,
      "learning_rate": 2.231828126379271e-05,
      "loss": 1.1117,
      "step": 11150
    },
    {
      "epoch": 3.098,
      "grad_norm": 6.398528575897217,
      "learning_rate": 2.2297733065114718e-05,
      "loss": 1.1773,
      "step": 11155
    },
    {
      "epoch": 3.09825,
      "grad_norm": 5.466715335845947,
      "learning_rate": 2.2277186713410687e-05,
      "loss": 1.0292,
      "step": 11160
    },
    {
      "epoch": 3.0985,
      "grad_norm": 5.477066516876221,
      "learning_rate": 2.225664222272387e-05,
      "loss": 1.17,
      "step": 11165
    },
    {
      "epoch": 3.09875,
      "grad_norm": 5.65326452255249,
      "learning_rate": 2.223609960709622e-05,
      "loss": 1.1756,
      "step": 11170
    },
    {
      "epoch": 3.099,
      "grad_norm": 4.955517292022705,
      "learning_rate": 2.221555888056843e-05,
      "loss": 1.0714,
      "step": 11175
    },
    {
      "epoch": 3.09925,
      "grad_norm": 7.399542331695557,
      "learning_rate": 2.2195020057179896e-05,
      "loss": 1.2314,
      "step": 11180
    },
    {
      "epoch": 3.0995,
      "grad_norm": 4.217686653137207,
      "learning_rate": 2.2174483150968694e-05,
      "loss": 1.109,
      "step": 11185
    },
    {
      "epoch": 3.0997500000000002,
      "grad_norm": 4.428978443145752,
      "learning_rate": 2.215394817597162e-05,
      "loss": 1.0115,
      "step": 11190
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.872554302215576,
      "learning_rate": 2.2133415146224126e-05,
      "loss": 1.2135,
      "step": 11195
    },
    {
      "epoch": 3.10025,
      "grad_norm": 6.715046405792236,
      "learning_rate": 2.2112884075760347e-05,
      "loss": 1.2374,
      "step": 11200
    },
    {
      "epoch": 3.1005,
      "grad_norm": 5.195040225982666,
      "learning_rate": 2.2092354978613088e-05,
      "loss": 1.0451,
      "step": 11205
    },
    {
      "epoch": 3.10075,
      "grad_norm": 5.707400798797607,
      "learning_rate": 2.2071827868813774e-05,
      "loss": 1.0637,
      "step": 11210
    },
    {
      "epoch": 3.101,
      "grad_norm": 7.007715225219727,
      "learning_rate": 2.2051302760392507e-05,
      "loss": 1.1469,
      "step": 11215
    },
    {
      "epoch": 3.10125,
      "grad_norm": 6.401312351226807,
      "learning_rate": 2.2030779667377996e-05,
      "loss": 1.3112,
      "step": 11220
    },
    {
      "epoch": 3.1015,
      "grad_norm": 4.253535270690918,
      "learning_rate": 2.2010258603797594e-05,
      "loss": 1.0247,
      "step": 11225
    },
    {
      "epoch": 3.10175,
      "grad_norm": 4.224027633666992,
      "learning_rate": 2.1989739583677238e-05,
      "loss": 1.051,
      "step": 11230
    },
    {
      "epoch": 3.102,
      "grad_norm": 6.005809307098389,
      "learning_rate": 2.1969222621041484e-05,
      "loss": 1.0143,
      "step": 11235
    },
    {
      "epoch": 3.10225,
      "grad_norm": 4.885697364807129,
      "learning_rate": 2.19487077299135e-05,
      "loss": 1.0902,
      "step": 11240
    },
    {
      "epoch": 3.1025,
      "grad_norm": 4.143281936645508,
      "learning_rate": 2.1928194924315e-05,
      "loss": 1.0248,
      "step": 11245
    },
    {
      "epoch": 3.10275,
      "grad_norm": 5.636343479156494,
      "learning_rate": 2.190768421826631e-05,
      "loss": 1.0053,
      "step": 11250
    },
    {
      "epoch": 3.103,
      "grad_norm": 5.456111431121826,
      "learning_rate": 2.18871756257863e-05,
      "loss": 1.1707,
      "step": 11255
    },
    {
      "epoch": 3.10325,
      "grad_norm": 4.8014912605285645,
      "learning_rate": 2.186666916089239e-05,
      "loss": 0.886,
      "step": 11260
    },
    {
      "epoch": 3.1035,
      "grad_norm": 6.212276935577393,
      "learning_rate": 2.1846164837600574e-05,
      "loss": 1.1124,
      "step": 11265
    },
    {
      "epoch": 3.10375,
      "grad_norm": 3.97623872756958,
      "learning_rate": 2.1825662669925354e-05,
      "loss": 0.8709,
      "step": 11270
    },
    {
      "epoch": 3.104,
      "grad_norm": 4.906498908996582,
      "learning_rate": 2.180516267187976e-05,
      "loss": 1.1882,
      "step": 11275
    },
    {
      "epoch": 3.10425,
      "grad_norm": 6.089207649230957,
      "learning_rate": 2.1784664857475352e-05,
      "loss": 1.1542,
      "step": 11280
    },
    {
      "epoch": 3.1045,
      "grad_norm": 4.894771099090576,
      "learning_rate": 2.1764169240722196e-05,
      "loss": 1.0582,
      "step": 11285
    },
    {
      "epoch": 3.10475,
      "grad_norm": 5.764650344848633,
      "learning_rate": 2.1743675835628856e-05,
      "loss": 0.9805,
      "step": 11290
    },
    {
      "epoch": 3.105,
      "grad_norm": 5.274710655212402,
      "learning_rate": 2.1723184656202372e-05,
      "loss": 1.1048,
      "step": 11295
    },
    {
      "epoch": 3.10525,
      "grad_norm": 6.230652332305908,
      "learning_rate": 2.1702695716448278e-05,
      "loss": 1.0496,
      "step": 11300
    },
    {
      "epoch": 3.1055,
      "grad_norm": 6.790695667266846,
      "learning_rate": 2.1682209030370575e-05,
      "loss": 0.9939,
      "step": 11305
    },
    {
      "epoch": 3.10575,
      "grad_norm": 7.501018524169922,
      "learning_rate": 2.1661724611971708e-05,
      "loss": 1.023,
      "step": 11310
    },
    {
      "epoch": 3.106,
      "grad_norm": 5.771183490753174,
      "learning_rate": 2.16412424752526e-05,
      "loss": 0.974,
      "step": 11315
    },
    {
      "epoch": 3.10625,
      "grad_norm": 4.604712009429932,
      "learning_rate": 2.1620762634212586e-05,
      "loss": 1.0039,
      "step": 11320
    },
    {
      "epoch": 3.1065,
      "grad_norm": 6.564167499542236,
      "learning_rate": 2.160028510284944e-05,
      "loss": 1.0663,
      "step": 11325
    },
    {
      "epoch": 3.10675,
      "grad_norm": 6.179981708526611,
      "learning_rate": 2.1579809895159375e-05,
      "loss": 1.0629,
      "step": 11330
    },
    {
      "epoch": 3.107,
      "grad_norm": 6.41206693649292,
      "learning_rate": 2.155933702513699e-05,
      "loss": 1.1547,
      "step": 11335
    },
    {
      "epoch": 3.10725,
      "grad_norm": 5.820188522338867,
      "learning_rate": 2.153886650677531e-05,
      "loss": 0.8964,
      "step": 11340
    },
    {
      "epoch": 3.1075,
      "grad_norm": 4.707630634307861,
      "learning_rate": 2.1518398354065737e-05,
      "loss": 1.0886,
      "step": 11345
    },
    {
      "epoch": 3.10775,
      "grad_norm": 11.5386323928833,
      "learning_rate": 2.1497932580998053e-05,
      "loss": 0.9859,
      "step": 11350
    },
    {
      "epoch": 3.108,
      "grad_norm": 5.094888687133789,
      "learning_rate": 2.1477469201560435e-05,
      "loss": 1.0,
      "step": 11355
    },
    {
      "epoch": 3.10825,
      "grad_norm": 5.40806770324707,
      "learning_rate": 2.1457008229739394e-05,
      "loss": 1.0332,
      "step": 11360
    },
    {
      "epoch": 3.1085,
      "grad_norm": 5.228901386260986,
      "learning_rate": 2.1436549679519833e-05,
      "loss": 0.967,
      "step": 11365
    },
    {
      "epoch": 3.10875,
      "grad_norm": 5.977280616760254,
      "learning_rate": 2.141609356488496e-05,
      "loss": 0.9802,
      "step": 11370
    },
    {
      "epoch": 3.109,
      "grad_norm": 4.558788776397705,
      "learning_rate": 2.1395639899816333e-05,
      "loss": 1.074,
      "step": 11375
    },
    {
      "epoch": 3.10925,
      "grad_norm": 5.30532169342041,
      "learning_rate": 2.1375188698293855e-05,
      "loss": 1.0251,
      "step": 11380
    },
    {
      "epoch": 3.1095,
      "grad_norm": 5.784440994262695,
      "learning_rate": 2.1354739974295718e-05,
      "loss": 0.9078,
      "step": 11385
    },
    {
      "epoch": 3.10975,
      "grad_norm": 4.18223762512207,
      "learning_rate": 2.1334293741798432e-05,
      "loss": 0.9092,
      "step": 11390
    },
    {
      "epoch": 3.11,
      "grad_norm": 5.412683963775635,
      "learning_rate": 2.1313850014776814e-05,
      "loss": 1.0548,
      "step": 11395
    },
    {
      "epoch": 3.11025,
      "grad_norm": 6.161335468292236,
      "learning_rate": 2.1293408807203947e-05,
      "loss": 0.997,
      "step": 11400
    },
    {
      "epoch": 3.1105,
      "grad_norm": 5.199070930480957,
      "learning_rate": 2.1272970133051216e-05,
      "loss": 1.0388,
      "step": 11405
    },
    {
      "epoch": 3.11075,
      "grad_norm": 5.835044860839844,
      "learning_rate": 2.1252534006288264e-05,
      "loss": 1.2918,
      "step": 11410
    },
    {
      "epoch": 3.111,
      "grad_norm": 5.194528102874756,
      "learning_rate": 2.1232100440882966e-05,
      "loss": 1.0905,
      "step": 11415
    },
    {
      "epoch": 3.11125,
      "grad_norm": 6.945114612579346,
      "learning_rate": 2.1211669450801493e-05,
      "loss": 1.2915,
      "step": 11420
    },
    {
      "epoch": 3.1115,
      "grad_norm": 6.610467433929443,
      "learning_rate": 2.1191241050008226e-05,
      "loss": 1.1365,
      "step": 11425
    },
    {
      "epoch": 3.11175,
      "grad_norm": 6.086646556854248,
      "learning_rate": 2.117081525246579e-05,
      "loss": 1.1046,
      "step": 11430
    },
    {
      "epoch": 3.112,
      "grad_norm": 5.457919120788574,
      "learning_rate": 2.115039207213502e-05,
      "loss": 1.2063,
      "step": 11435
    },
    {
      "epoch": 3.11225,
      "grad_norm": 5.485562324523926,
      "learning_rate": 2.1129971522974967e-05,
      "loss": 1.08,
      "step": 11440
    },
    {
      "epoch": 3.1125,
      "grad_norm": 4.815193176269531,
      "learning_rate": 2.110955361894289e-05,
      "loss": 1.3874,
      "step": 11445
    },
    {
      "epoch": 3.11275,
      "grad_norm": 5.1420722007751465,
      "learning_rate": 2.1089138373994223e-05,
      "loss": 1.0939,
      "step": 11450
    },
    {
      "epoch": 3.113,
      "grad_norm": 5.441068649291992,
      "learning_rate": 2.106872580208262e-05,
      "loss": 1.1212,
      "step": 11455
    },
    {
      "epoch": 3.11325,
      "grad_norm": 4.771064758300781,
      "learning_rate": 2.1048315917159846e-05,
      "loss": 1.1525,
      "step": 11460
    },
    {
      "epoch": 3.1135,
      "grad_norm": 4.739680767059326,
      "learning_rate": 2.1027908733175877e-05,
      "loss": 1.084,
      "step": 11465
    },
    {
      "epoch": 3.11375,
      "grad_norm": 5.3128132820129395,
      "learning_rate": 2.100750426407884e-05,
      "loss": 1.0866,
      "step": 11470
    },
    {
      "epoch": 3.114,
      "grad_norm": 4.592545509338379,
      "learning_rate": 2.098710252381499e-05,
      "loss": 1.0642,
      "step": 11475
    },
    {
      "epoch": 3.11425,
      "grad_norm": 7.275015354156494,
      "learning_rate": 2.0966703526328728e-05,
      "loss": 1.0914,
      "step": 11480
    },
    {
      "epoch": 3.1145,
      "grad_norm": 4.924958229064941,
      "learning_rate": 2.0946307285562568e-05,
      "loss": 1.275,
      "step": 11485
    },
    {
      "epoch": 3.11475,
      "grad_norm": 6.168416976928711,
      "learning_rate": 2.0925913815457153e-05,
      "loss": 1.0627,
      "step": 11490
    },
    {
      "epoch": 3.115,
      "grad_norm": 7.090635299682617,
      "learning_rate": 2.0905523129951237e-05,
      "loss": 1.2636,
      "step": 11495
    },
    {
      "epoch": 3.11525,
      "grad_norm": 8.025328636169434,
      "learning_rate": 2.088513524298165e-05,
      "loss": 1.2472,
      "step": 11500
    },
    {
      "epoch": 3.11525,
      "eval_loss": 2.056354284286499,
      "eval_runtime": 5.1868,
      "eval_samples_per_second": 197.423,
      "eval_steps_per_second": 24.678,
      "step": 11500
    },
    {
      "epoch": 3.1155,
      "grad_norm": 5.2353949546813965,
      "learning_rate": 2.086475016848333e-05,
      "loss": 0.8621,
      "step": 11505
    },
    {
      "epoch": 3.11575,
      "grad_norm": 5.6005330085754395,
      "learning_rate": 2.0844367920389273e-05,
      "loss": 1.043,
      "step": 11510
    },
    {
      "epoch": 3.116,
      "grad_norm": 5.396213054656982,
      "learning_rate": 2.0823988512630553e-05,
      "loss": 1.1821,
      "step": 11515
    },
    {
      "epoch": 3.11625,
      "grad_norm": 6.019960403442383,
      "learning_rate": 2.080361195913631e-05,
      "loss": 1.0832,
      "step": 11520
    },
    {
      "epoch": 3.1165,
      "grad_norm": 5.940325736999512,
      "learning_rate": 2.078323827383372e-05,
      "loss": 1.0766,
      "step": 11525
    },
    {
      "epoch": 3.11675,
      "grad_norm": 5.189648151397705,
      "learning_rate": 2.0762867470648013e-05,
      "loss": 1.0692,
      "step": 11530
    },
    {
      "epoch": 3.117,
      "grad_norm": 4.826473712921143,
      "learning_rate": 2.0742499563502428e-05,
      "loss": 1.0988,
      "step": 11535
    },
    {
      "epoch": 3.11725,
      "grad_norm": 4.685450077056885,
      "learning_rate": 2.072213456631825e-05,
      "loss": 1.1306,
      "step": 11540
    },
    {
      "epoch": 3.1175,
      "grad_norm": 4.656534671783447,
      "learning_rate": 2.070177249301476e-05,
      "loss": 1.0149,
      "step": 11545
    },
    {
      "epoch": 3.11775,
      "grad_norm": 5.738691329956055,
      "learning_rate": 2.068141335750925e-05,
      "loss": 0.9873,
      "step": 11550
    },
    {
      "epoch": 3.118,
      "grad_norm": 6.149901390075684,
      "learning_rate": 2.0661057173716974e-05,
      "loss": 1.0268,
      "step": 11555
    },
    {
      "epoch": 3.11825,
      "grad_norm": 5.452388286590576,
      "learning_rate": 2.0640703955551212e-05,
      "loss": 1.053,
      "step": 11560
    },
    {
      "epoch": 3.1185,
      "grad_norm": 4.772693157196045,
      "learning_rate": 2.0620353716923186e-05,
      "loss": 0.8963,
      "step": 11565
    },
    {
      "epoch": 3.11875,
      "grad_norm": 6.233482360839844,
      "learning_rate": 2.0600006471742104e-05,
      "loss": 1.0867,
      "step": 11570
    },
    {
      "epoch": 3.1189999999999998,
      "grad_norm": 5.987630844116211,
      "learning_rate": 2.0579662233915102e-05,
      "loss": 1.1065,
      "step": 11575
    },
    {
      "epoch": 3.11925,
      "grad_norm": 5.536596775054932,
      "learning_rate": 2.0559321017347285e-05,
      "loss": 1.0481,
      "step": 11580
    },
    {
      "epoch": 3.1195,
      "grad_norm": 7.531809329986572,
      "learning_rate": 2.053898283594168e-05,
      "loss": 1.0173,
      "step": 11585
    },
    {
      "epoch": 3.11975,
      "grad_norm": 5.02925443649292,
      "learning_rate": 2.0518647703599236e-05,
      "loss": 1.1159,
      "step": 11590
    },
    {
      "epoch": 3.12,
      "grad_norm": 4.479163646697998,
      "learning_rate": 2.0498315634218844e-05,
      "loss": 1.059,
      "step": 11595
    },
    {
      "epoch": 3.12025,
      "grad_norm": 5.125873565673828,
      "learning_rate": 2.047798664169726e-05,
      "loss": 0.908,
      "step": 11600
    },
    {
      "epoch": 3.1205,
      "grad_norm": 6.17039155960083,
      "learning_rate": 2.0457660739929164e-05,
      "loss": 1.0475,
      "step": 11605
    },
    {
      "epoch": 3.12075,
      "grad_norm": 9.374716758728027,
      "learning_rate": 2.043733794280712e-05,
      "loss": 1.1644,
      "step": 11610
    },
    {
      "epoch": 3.121,
      "grad_norm": 4.856693744659424,
      "learning_rate": 2.041701826422157e-05,
      "loss": 1.1085,
      "step": 11615
    },
    {
      "epoch": 3.12125,
      "grad_norm": 4.584056854248047,
      "learning_rate": 2.0396701718060824e-05,
      "loss": 0.9589,
      "step": 11620
    },
    {
      "epoch": 3.1215,
      "grad_norm": 5.83646297454834,
      "learning_rate": 2.037638831821104e-05,
      "loss": 1.1518,
      "step": 11625
    },
    {
      "epoch": 3.12175,
      "grad_norm": 5.7440361976623535,
      "learning_rate": 2.035607807855625e-05,
      "loss": 1.0032,
      "step": 11630
    },
    {
      "epoch": 3.122,
      "grad_norm": 5.3786492347717285,
      "learning_rate": 2.03357710129783e-05,
      "loss": 1.1197,
      "step": 11635
    },
    {
      "epoch": 3.12225,
      "grad_norm": 5.400034427642822,
      "learning_rate": 2.031546713535688e-05,
      "loss": 1.0586,
      "step": 11640
    },
    {
      "epoch": 3.1225,
      "grad_norm": 5.13981819152832,
      "learning_rate": 2.029516645956951e-05,
      "loss": 1.0901,
      "step": 11645
    },
    {
      "epoch": 3.12275,
      "grad_norm": 5.703810691833496,
      "learning_rate": 2.02748689994915e-05,
      "loss": 1.079,
      "step": 11650
    },
    {
      "epoch": 3.123,
      "grad_norm": 5.508815288543701,
      "learning_rate": 2.0254574768995964e-05,
      "loss": 1.0027,
      "step": 11655
    },
    {
      "epoch": 3.12325,
      "grad_norm": 5.522457122802734,
      "learning_rate": 2.0234283781953834e-05,
      "loss": 0.9617,
      "step": 11660
    },
    {
      "epoch": 3.1235,
      "grad_norm": 4.574572563171387,
      "learning_rate": 2.021399605223379e-05,
      "loss": 1.0635,
      "step": 11665
    },
    {
      "epoch": 3.12375,
      "grad_norm": 5.220967769622803,
      "learning_rate": 2.0193711593702326e-05,
      "loss": 1.0203,
      "step": 11670
    },
    {
      "epoch": 3.124,
      "grad_norm": 5.345688819885254,
      "learning_rate": 2.017343042022366e-05,
      "loss": 1.002,
      "step": 11675
    },
    {
      "epoch": 3.12425,
      "grad_norm": 5.772975444793701,
      "learning_rate": 2.0153152545659798e-05,
      "loss": 1.0118,
      "step": 11680
    },
    {
      "epoch": 3.1245,
      "grad_norm": 4.901127815246582,
      "learning_rate": 2.013287798387046e-05,
      "loss": 1.0663,
      "step": 11685
    },
    {
      "epoch": 3.12475,
      "grad_norm": 5.2854509353637695,
      "learning_rate": 2.0112606748713138e-05,
      "loss": 0.9172,
      "step": 11690
    },
    {
      "epoch": 3.125,
      "grad_norm": 6.85689115524292,
      "learning_rate": 2.0092338854043007e-05,
      "loss": 1.1404,
      "step": 11695
    },
    {
      "epoch": 3.12525,
      "grad_norm": 4.8497772216796875,
      "learning_rate": 2.0072074313712997e-05,
      "loss": 1.0562,
      "step": 11700
    },
    {
      "epoch": 3.1255,
      "grad_norm": 5.043266296386719,
      "learning_rate": 2.0051813141573723e-05,
      "loss": 1.1113,
      "step": 11705
    },
    {
      "epoch": 3.12575,
      "grad_norm": 6.117198944091797,
      "learning_rate": 2.003155535147351e-05,
      "loss": 0.9518,
      "step": 11710
    },
    {
      "epoch": 3.126,
      "grad_norm": 5.599653720855713,
      "learning_rate": 2.001130095725836e-05,
      "loss": 1.0022,
      "step": 11715
    },
    {
      "epoch": 3.12625,
      "grad_norm": 4.858382701873779,
      "learning_rate": 1.9991049972771972e-05,
      "loss": 1.0022,
      "step": 11720
    },
    {
      "epoch": 3.1265,
      "grad_norm": 9.552124977111816,
      "learning_rate": 1.997080241185569e-05,
      "loss": 1.0231,
      "step": 11725
    },
    {
      "epoch": 3.12675,
      "grad_norm": 5.970799922943115,
      "learning_rate": 1.9950558288348542e-05,
      "loss": 1.0036,
      "step": 11730
    },
    {
      "epoch": 3.127,
      "grad_norm": 4.876722812652588,
      "learning_rate": 1.9930317616087196e-05,
      "loss": 0.9894,
      "step": 11735
    },
    {
      "epoch": 3.12725,
      "grad_norm": 6.987173557281494,
      "learning_rate": 1.9910080408905944e-05,
      "loss": 0.9101,
      "step": 11740
    },
    {
      "epoch": 3.1275,
      "grad_norm": 4.986797332763672,
      "learning_rate": 1.988984668063674e-05,
      "loss": 0.9317,
      "step": 11745
    },
    {
      "epoch": 3.12775,
      "grad_norm": 5.070286273956299,
      "learning_rate": 1.9869616445109147e-05,
      "loss": 1.0674,
      "step": 11750
    },
    {
      "epoch": 3.128,
      "grad_norm": 5.236165523529053,
      "learning_rate": 1.984938971615033e-05,
      "loss": 0.9763,
      "step": 11755
    },
    {
      "epoch": 3.12825,
      "grad_norm": 8.534849166870117,
      "learning_rate": 1.9829166507585083e-05,
      "loss": 1.0791,
      "step": 11760
    },
    {
      "epoch": 3.1285,
      "grad_norm": 5.5367960929870605,
      "learning_rate": 1.9808946833235765e-05,
      "loss": 1.0472,
      "step": 11765
    },
    {
      "epoch": 3.12875,
      "grad_norm": 4.90974760055542,
      "learning_rate": 1.9788730706922342e-05,
      "loss": 1.275,
      "step": 11770
    },
    {
      "epoch": 3.129,
      "grad_norm": 4.503045082092285,
      "learning_rate": 1.9768518142462337e-05,
      "loss": 0.8911,
      "step": 11775
    },
    {
      "epoch": 3.12925,
      "grad_norm": 4.947056770324707,
      "learning_rate": 1.974830915367086e-05,
      "loss": 0.9421,
      "step": 11780
    },
    {
      "epoch": 3.1295,
      "grad_norm": 4.12790060043335,
      "learning_rate": 1.9728103754360556e-05,
      "loss": 0.9766,
      "step": 11785
    },
    {
      "epoch": 3.12975,
      "grad_norm": 6.413208484649658,
      "learning_rate": 1.9707901958341612e-05,
      "loss": 0.8948,
      "step": 11790
    },
    {
      "epoch": 3.13,
      "grad_norm": 5.724032402038574,
      "learning_rate": 1.9687703779421784e-05,
      "loss": 1.0234,
      "step": 11795
    },
    {
      "epoch": 3.13025,
      "grad_norm": 5.833649158477783,
      "learning_rate": 1.9667509231406334e-05,
      "loss": 0.9581,
      "step": 11800
    },
    {
      "epoch": 3.1305,
      "grad_norm": 5.488544940948486,
      "learning_rate": 1.9647318328098036e-05,
      "loss": 1.0781,
      "step": 11805
    },
    {
      "epoch": 3.13075,
      "grad_norm": 5.47231912612915,
      "learning_rate": 1.962713108329719e-05,
      "loss": 1.0443,
      "step": 11810
    },
    {
      "epoch": 3.1310000000000002,
      "grad_norm": 5.5905842781066895,
      "learning_rate": 1.9606947510801588e-05,
      "loss": 0.8685,
      "step": 11815
    },
    {
      "epoch": 3.13125,
      "grad_norm": 5.943565845489502,
      "learning_rate": 1.958676762440651e-05,
      "loss": 0.9326,
      "step": 11820
    },
    {
      "epoch": 3.1315,
      "grad_norm": 4.885004043579102,
      "learning_rate": 1.956659143790471e-05,
      "loss": 0.8551,
      "step": 11825
    },
    {
      "epoch": 3.13175,
      "grad_norm": 5.772515773773193,
      "learning_rate": 1.9546418965086442e-05,
      "loss": 0.9473,
      "step": 11830
    },
    {
      "epoch": 3.132,
      "grad_norm": 5.019501209259033,
      "learning_rate": 1.952625021973938e-05,
      "loss": 0.9188,
      "step": 11835
    },
    {
      "epoch": 3.13225,
      "grad_norm": 7.520683288574219,
      "learning_rate": 1.9506085215648675e-05,
      "loss": 0.9324,
      "step": 11840
    },
    {
      "epoch": 3.1325,
      "grad_norm": 4.539143085479736,
      "learning_rate": 1.948592396659692e-05,
      "loss": 0.9117,
      "step": 11845
    },
    {
      "epoch": 3.13275,
      "grad_norm": 5.404232025146484,
      "learning_rate": 1.9465766486364143e-05,
      "loss": 0.9212,
      "step": 11850
    },
    {
      "epoch": 3.133,
      "grad_norm": 3.7442095279693604,
      "learning_rate": 1.9445612788727782e-05,
      "loss": 0.7372,
      "step": 11855
    },
    {
      "epoch": 3.13325,
      "grad_norm": 7.951744556427002,
      "learning_rate": 1.9425462887462712e-05,
      "loss": 1.0007,
      "step": 11860
    },
    {
      "epoch": 3.1335,
      "grad_norm": 4.767939567565918,
      "learning_rate": 1.940531679634119e-05,
      "loss": 0.7883,
      "step": 11865
    },
    {
      "epoch": 3.13375,
      "grad_norm": 3.858240842819214,
      "learning_rate": 1.9385174529132884e-05,
      "loss": 0.722,
      "step": 11870
    },
    {
      "epoch": 3.134,
      "grad_norm": 5.265965461730957,
      "learning_rate": 1.936503609960485e-05,
      "loss": 0.9291,
      "step": 11875
    },
    {
      "epoch": 3.13425,
      "grad_norm": 4.575642108917236,
      "learning_rate": 1.93449015215215e-05,
      "loss": 0.9156,
      "step": 11880
    },
    {
      "epoch": 3.1345,
      "grad_norm": 4.319554805755615,
      "learning_rate": 1.9324770808644638e-05,
      "loss": 0.9144,
      "step": 11885
    },
    {
      "epoch": 3.13475,
      "grad_norm": 6.369237899780273,
      "learning_rate": 1.930464397473341e-05,
      "loss": 1.0047,
      "step": 11890
    },
    {
      "epoch": 3.135,
      "grad_norm": 5.998871326446533,
      "learning_rate": 1.9284521033544316e-05,
      "loss": 1.0524,
      "step": 11895
    },
    {
      "epoch": 3.13525,
      "grad_norm": 8.458409309387207,
      "learning_rate": 1.9264401998831213e-05,
      "loss": 1.0662,
      "step": 11900
    },
    {
      "epoch": 3.1355,
      "grad_norm": 5.271052360534668,
      "learning_rate": 1.9244286884345253e-05,
      "loss": 1.0413,
      "step": 11905
    },
    {
      "epoch": 3.13575,
      "grad_norm": 6.541161060333252,
      "learning_rate": 1.922417570383494e-05,
      "loss": 1.0766,
      "step": 11910
    },
    {
      "epoch": 3.136,
      "grad_norm": 6.493252754211426,
      "learning_rate": 1.9204068471046068e-05,
      "loss": 0.9021,
      "step": 11915
    },
    {
      "epoch": 3.13625,
      "grad_norm": 5.548253536224365,
      "learning_rate": 1.9183965199721745e-05,
      "loss": 0.9564,
      "step": 11920
    },
    {
      "epoch": 3.1365,
      "grad_norm": 5.197599411010742,
      "learning_rate": 1.9163865903602374e-05,
      "loss": 1.1309,
      "step": 11925
    },
    {
      "epoch": 3.13675,
      "grad_norm": 5.537666320800781,
      "learning_rate": 1.9143770596425615e-05,
      "loss": 1.0433,
      "step": 11930
    },
    {
      "epoch": 3.137,
      "grad_norm": 6.6844916343688965,
      "learning_rate": 1.9123679291926436e-05,
      "loss": 1.1664,
      "step": 11935
    },
    {
      "epoch": 3.13725,
      "grad_norm": 5.906510829925537,
      "learning_rate": 1.9103592003837045e-05,
      "loss": 1.1438,
      "step": 11940
    },
    {
      "epoch": 3.1375,
      "grad_norm": 5.958322525024414,
      "learning_rate": 1.9083508745886923e-05,
      "loss": 0.8657,
      "step": 11945
    },
    {
      "epoch": 3.13775,
      "grad_norm": 6.681537628173828,
      "learning_rate": 1.9063429531802786e-05,
      "loss": 1.0067,
      "step": 11950
    },
    {
      "epoch": 3.138,
      "grad_norm": 4.610492706298828,
      "learning_rate": 1.9043354375308585e-05,
      "loss": 1.0706,
      "step": 11955
    },
    {
      "epoch": 3.13825,
      "grad_norm": 6.423435211181641,
      "learning_rate": 1.90232832901255e-05,
      "loss": 0.9858,
      "step": 11960
    },
    {
      "epoch": 3.1385,
      "grad_norm": 7.212949275970459,
      "learning_rate": 1.9003216289971926e-05,
      "loss": 1.1657,
      "step": 11965
    },
    {
      "epoch": 3.13875,
      "grad_norm": 6.126312732696533,
      "learning_rate": 1.8983153388563486e-05,
      "loss": 1.1133,
      "step": 11970
    },
    {
      "epoch": 3.1390000000000002,
      "grad_norm": 5.090535640716553,
      "learning_rate": 1.8963094599612958e-05,
      "loss": 0.9967,
      "step": 11975
    },
    {
      "epoch": 3.13925,
      "grad_norm": 5.340310573577881,
      "learning_rate": 1.8943039936830344e-05,
      "loss": 1.0662,
      "step": 11980
    },
    {
      "epoch": 3.1395,
      "grad_norm": 4.983394622802734,
      "learning_rate": 1.8922989413922828e-05,
      "loss": 0.9184,
      "step": 11985
    },
    {
      "epoch": 3.13975,
      "grad_norm": 4.782709121704102,
      "learning_rate": 1.8902943044594735e-05,
      "loss": 1.0125,
      "step": 11990
    },
    {
      "epoch": 3.14,
      "grad_norm": 7.3580641746521,
      "learning_rate": 1.888290084254758e-05,
      "loss": 0.9005,
      "step": 11995
    },
    {
      "epoch": 3.14025,
      "grad_norm": 6.580699920654297,
      "learning_rate": 1.8862862821480025e-05,
      "loss": 1.0634,
      "step": 12000
    },
    {
      "epoch": 3.14025,
      "eval_loss": 2.0887560844421387,
      "eval_runtime": 5.8784,
      "eval_samples_per_second": 174.198,
      "eval_steps_per_second": 21.775,
      "step": 12000
    },
    {
      "epoch": 3.1405,
      "grad_norm": 5.645153045654297,
      "learning_rate": 1.8842828995087854e-05,
      "loss": 0.8854,
      "step": 12005
    },
    {
      "epoch": 3.14075,
      "grad_norm": 6.421511173248291,
      "learning_rate": 1.8822799377064014e-05,
      "loss": 1.0333,
      "step": 12010
    },
    {
      "epoch": 3.141,
      "grad_norm": 5.375082969665527,
      "learning_rate": 1.8802773981098556e-05,
      "loss": 0.9458,
      "step": 12015
    },
    {
      "epoch": 3.14125,
      "grad_norm": 5.961006164550781,
      "learning_rate": 1.8782752820878634e-05,
      "loss": 1.0149,
      "step": 12020
    },
    {
      "epoch": 3.1415,
      "grad_norm": 5.4687700271606445,
      "learning_rate": 1.876273591008854e-05,
      "loss": 0.8723,
      "step": 12025
    },
    {
      "epoch": 3.14175,
      "grad_norm": 5.094484329223633,
      "learning_rate": 1.8742723262409634e-05,
      "loss": 0.8662,
      "step": 12030
    },
    {
      "epoch": 3.142,
      "grad_norm": 5.985758304595947,
      "learning_rate": 1.8722714891520376e-05,
      "loss": 1.0574,
      "step": 12035
    },
    {
      "epoch": 3.1422499999999998,
      "grad_norm": 7.599667549133301,
      "learning_rate": 1.87027108110963e-05,
      "loss": 1.0231,
      "step": 12040
    },
    {
      "epoch": 3.1425,
      "grad_norm": 4.657685279846191,
      "learning_rate": 1.868271103481e-05,
      "loss": 0.8747,
      "step": 12045
    },
    {
      "epoch": 3.14275,
      "grad_norm": 3.917048454284668,
      "learning_rate": 1.866271557633115e-05,
      "loss": 0.9086,
      "step": 12050
    },
    {
      "epoch": 3.143,
      "grad_norm": 4.744060039520264,
      "learning_rate": 1.8642724449326437e-05,
      "loss": 0.8122,
      "step": 12055
    },
    {
      "epoch": 3.14325,
      "grad_norm": 5.5190324783325195,
      "learning_rate": 1.8622737667459623e-05,
      "loss": 0.8513,
      "step": 12060
    },
    {
      "epoch": 3.1435,
      "grad_norm": 5.372178077697754,
      "learning_rate": 1.8602755244391483e-05,
      "loss": 1.0342,
      "step": 12065
    },
    {
      "epoch": 3.14375,
      "grad_norm": 7.06058406829834,
      "learning_rate": 1.8582777193779805e-05,
      "loss": 0.9091,
      "step": 12070
    },
    {
      "epoch": 3.144,
      "grad_norm": 5.294774532318115,
      "learning_rate": 1.8562803529279406e-05,
      "loss": 0.8675,
      "step": 12075
    },
    {
      "epoch": 3.14425,
      "grad_norm": 4.136539459228516,
      "learning_rate": 1.8542834264542092e-05,
      "loss": 0.9793,
      "step": 12080
    },
    {
      "epoch": 3.1445,
      "grad_norm": 5.347861289978027,
      "learning_rate": 1.8522869413216672e-05,
      "loss": 0.7756,
      "step": 12085
    },
    {
      "epoch": 3.14475,
      "grad_norm": 4.913912773132324,
      "learning_rate": 1.850290898894893e-05,
      "loss": 0.7739,
      "step": 12090
    },
    {
      "epoch": 3.145,
      "grad_norm": 5.586280822753906,
      "learning_rate": 1.848295300538163e-05,
      "loss": 0.9005,
      "step": 12095
    },
    {
      "epoch": 3.14525,
      "grad_norm": 4.129271507263184,
      "learning_rate": 1.8463001476154508e-05,
      "loss": 0.7019,
      "step": 12100
    },
    {
      "epoch": 3.1455,
      "grad_norm": 6.734477519989014,
      "learning_rate": 1.8443054414904226e-05,
      "loss": 0.8497,
      "step": 12105
    },
    {
      "epoch": 3.14575,
      "grad_norm": 4.459752559661865,
      "learning_rate": 1.8423111835264434e-05,
      "loss": 0.9661,
      "step": 12110
    },
    {
      "epoch": 3.146,
      "grad_norm": 4.692432403564453,
      "learning_rate": 1.8403173750865685e-05,
      "loss": 0.7841,
      "step": 12115
    },
    {
      "epoch": 3.14625,
      "grad_norm": 5.165052890777588,
      "learning_rate": 1.8383240175335464e-05,
      "loss": 0.8438,
      "step": 12120
    },
    {
      "epoch": 3.1465,
      "grad_norm": 10.514190673828125,
      "learning_rate": 1.83633111222982e-05,
      "loss": 1.7578,
      "step": 12125
    },
    {
      "epoch": 3.14675,
      "grad_norm": 11.111289978027344,
      "learning_rate": 1.8343386605375192e-05,
      "loss": 2.0961,
      "step": 12130
    },
    {
      "epoch": 3.147,
      "grad_norm": 8.909433364868164,
      "learning_rate": 1.8323466638184677e-05,
      "loss": 1.8818,
      "step": 12135
    },
    {
      "epoch": 3.14725,
      "grad_norm": 10.4632568359375,
      "learning_rate": 1.8303551234341763e-05,
      "loss": 1.7337,
      "step": 12140
    },
    {
      "epoch": 3.1475,
      "grad_norm": 8.705974578857422,
      "learning_rate": 1.828364040745843e-05,
      "loss": 1.6351,
      "step": 12145
    },
    {
      "epoch": 3.14775,
      "grad_norm": 8.935604095458984,
      "learning_rate": 1.826373417114355e-05,
      "loss": 1.5987,
      "step": 12150
    },
    {
      "epoch": 3.148,
      "grad_norm": 8.083688735961914,
      "learning_rate": 1.8243832539002854e-05,
      "loss": 1.5731,
      "step": 12155
    },
    {
      "epoch": 3.14825,
      "grad_norm": 8.17944622039795,
      "learning_rate": 1.8223935524638898e-05,
      "loss": 1.5171,
      "step": 12160
    },
    {
      "epoch": 3.1485,
      "grad_norm": 6.77176570892334,
      "learning_rate": 1.8204043141651124e-05,
      "loss": 1.5918,
      "step": 12165
    },
    {
      "epoch": 3.14875,
      "grad_norm": 12.896607398986816,
      "learning_rate": 1.818415540363577e-05,
      "loss": 1.6693,
      "step": 12170
    },
    {
      "epoch": 3.149,
      "grad_norm": 7.380170822143555,
      "learning_rate": 1.816427232418594e-05,
      "loss": 1.6239,
      "step": 12175
    },
    {
      "epoch": 3.14925,
      "grad_norm": 6.346738338470459,
      "learning_rate": 1.814439391689151e-05,
      "loss": 1.5206,
      "step": 12180
    },
    {
      "epoch": 3.1495,
      "grad_norm": 7.628025531768799,
      "learning_rate": 1.8124520195339195e-05,
      "loss": 1.5661,
      "step": 12185
    },
    {
      "epoch": 3.14975,
      "grad_norm": 6.873398303985596,
      "learning_rate": 1.8104651173112503e-05,
      "loss": 1.4587,
      "step": 12190
    },
    {
      "epoch": 3.15,
      "grad_norm": 7.001654624938965,
      "learning_rate": 1.8084786863791703e-05,
      "loss": 1.4731,
      "step": 12195
    },
    {
      "epoch": 3.1502499999999998,
      "grad_norm": 6.378613471984863,
      "learning_rate": 1.806492728095389e-05,
      "loss": 1.456,
      "step": 12200
    },
    {
      "epoch": 3.1505,
      "grad_norm": 10.102519989013672,
      "learning_rate": 1.804507243817288e-05,
      "loss": 1.6434,
      "step": 12205
    },
    {
      "epoch": 3.15075,
      "grad_norm": 10.316278457641602,
      "learning_rate": 1.802522234901927e-05,
      "loss": 1.5474,
      "step": 12210
    },
    {
      "epoch": 3.151,
      "grad_norm": 7.85686731338501,
      "learning_rate": 1.800537702706043e-05,
      "loss": 1.556,
      "step": 12215
    },
    {
      "epoch": 3.15125,
      "grad_norm": 6.8733134269714355,
      "learning_rate": 1.798553648586042e-05,
      "loss": 1.6846,
      "step": 12220
    },
    {
      "epoch": 3.1515,
      "grad_norm": 6.744451522827148,
      "learning_rate": 1.796570073898009e-05,
      "loss": 1.5617,
      "step": 12225
    },
    {
      "epoch": 3.15175,
      "grad_norm": 8.598942756652832,
      "learning_rate": 1.7945869799976973e-05,
      "loss": 1.5382,
      "step": 12230
    },
    {
      "epoch": 3.152,
      "grad_norm": 12.112372398376465,
      "learning_rate": 1.7926043682405326e-05,
      "loss": 1.7337,
      "step": 12235
    },
    {
      "epoch": 3.15225,
      "grad_norm": 13.904322624206543,
      "learning_rate": 1.7906222399816124e-05,
      "loss": 1.609,
      "step": 12240
    },
    {
      "epoch": 3.1525,
      "grad_norm": 14.417909622192383,
      "learning_rate": 1.7886405965757018e-05,
      "loss": 1.4955,
      "step": 12245
    },
    {
      "epoch": 3.15275,
      "grad_norm": 10.195308685302734,
      "learning_rate": 1.7866594393772373e-05,
      "loss": 1.6257,
      "step": 12250
    },
    {
      "epoch": 3.153,
      "grad_norm": 10.308987617492676,
      "learning_rate": 1.7846787697403182e-05,
      "loss": 1.9324,
      "step": 12255
    },
    {
      "epoch": 3.15325,
      "grad_norm": 7.356778621673584,
      "learning_rate": 1.7826985890187148e-05,
      "loss": 1.279,
      "step": 12260
    },
    {
      "epoch": 4.00025,
      "grad_norm": 7.802103519439697,
      "learning_rate": 1.7807188985658625e-05,
      "loss": 1.0159,
      "step": 12265
    },
    {
      "epoch": 4.0005,
      "grad_norm": 6.769071102142334,
      "learning_rate": 1.7787396997348604e-05,
      "loss": 0.9653,
      "step": 12270
    },
    {
      "epoch": 4.00075,
      "grad_norm": 5.842394828796387,
      "learning_rate": 1.7767609938784725e-05,
      "loss": 0.9697,
      "step": 12275
    },
    {
      "epoch": 4.001,
      "grad_norm": 7.7007737159729,
      "learning_rate": 1.7747827823491252e-05,
      "loss": 0.8877,
      "step": 12280
    },
    {
      "epoch": 4.00125,
      "grad_norm": 6.778079032897949,
      "learning_rate": 1.772805066498908e-05,
      "loss": 1.0131,
      "step": 12285
    },
    {
      "epoch": 4.0015,
      "grad_norm": 6.590765476226807,
      "learning_rate": 1.770827847679571e-05,
      "loss": 1.0251,
      "step": 12290
    },
    {
      "epoch": 4.00175,
      "grad_norm": 5.493185043334961,
      "learning_rate": 1.7688511272425252e-05,
      "loss": 0.805,
      "step": 12295
    },
    {
      "epoch": 4.002,
      "grad_norm": 6.00890588760376,
      "learning_rate": 1.7668749065388385e-05,
      "loss": 0.8786,
      "step": 12300
    },
    {
      "epoch": 4.00225,
      "grad_norm": 6.450648784637451,
      "learning_rate": 1.7648991869192405e-05,
      "loss": 0.9014,
      "step": 12305
    },
    {
      "epoch": 4.0025,
      "grad_norm": 9.278042793273926,
      "learning_rate": 1.7629239697341165e-05,
      "loss": 1.1109,
      "step": 12310
    },
    {
      "epoch": 4.00275,
      "grad_norm": 11.049043655395508,
      "learning_rate": 1.7609492563335094e-05,
      "loss": 1.1068,
      "step": 12315
    },
    {
      "epoch": 4.003,
      "grad_norm": 8.807904243469238,
      "learning_rate": 1.758975048067116e-05,
      "loss": 1.1066,
      "step": 12320
    },
    {
      "epoch": 4.00325,
      "grad_norm": 7.640552997589111,
      "learning_rate": 1.7570013462842904e-05,
      "loss": 1.1071,
      "step": 12325
    },
    {
      "epoch": 4.0035,
      "grad_norm": 6.345745086669922,
      "learning_rate": 1.7550281523340382e-05,
      "loss": 0.9875,
      "step": 12330
    },
    {
      "epoch": 4.00375,
      "grad_norm": 5.459925174713135,
      "learning_rate": 1.7530554675650195e-05,
      "loss": 0.8819,
      "step": 12335
    },
    {
      "epoch": 4.004,
      "grad_norm": 10.213881492614746,
      "learning_rate": 1.7510832933255463e-05,
      "loss": 0.9939,
      "step": 12340
    },
    {
      "epoch": 4.00425,
      "grad_norm": 12.514668464660645,
      "learning_rate": 1.749111630963579e-05,
      "loss": 1.1264,
      "step": 12345
    },
    {
      "epoch": 4.0045,
      "grad_norm": 8.701897621154785,
      "learning_rate": 1.7471404818267316e-05,
      "loss": 1.0848,
      "step": 12350
    },
    {
      "epoch": 4.00475,
      "grad_norm": 11.123260498046875,
      "learning_rate": 1.7451698472622662e-05,
      "loss": 1.1746,
      "step": 12355
    },
    {
      "epoch": 4.005,
      "grad_norm": 8.969432830810547,
      "learning_rate": 1.7431997286170922e-05,
      "loss": 1.1771,
      "step": 12360
    },
    {
      "epoch": 4.00525,
      "grad_norm": 8.0382080078125,
      "learning_rate": 1.741230127237768e-05,
      "loss": 1.1424,
      "step": 12365
    },
    {
      "epoch": 4.0055,
      "grad_norm": 8.350624084472656,
      "learning_rate": 1.7392610444704966e-05,
      "loss": 1.2296,
      "step": 12370
    },
    {
      "epoch": 4.00575,
      "grad_norm": 8.386251449584961,
      "learning_rate": 1.7372924816611285e-05,
      "loss": 1.1085,
      "step": 12375
    },
    {
      "epoch": 4.006,
      "grad_norm": 8.174755096435547,
      "learning_rate": 1.7353244401551566e-05,
      "loss": 1.1981,
      "step": 12380
    },
    {
      "epoch": 4.00625,
      "grad_norm": 8.23887825012207,
      "learning_rate": 1.733356921297719e-05,
      "loss": 1.1317,
      "step": 12385
    },
    {
      "epoch": 4.0065,
      "grad_norm": 9.024131774902344,
      "learning_rate": 1.7313899264335985e-05,
      "loss": 1.2167,
      "step": 12390
    },
    {
      "epoch": 4.00675,
      "grad_norm": 7.885456562042236,
      "learning_rate": 1.7294234569072148e-05,
      "loss": 1.0544,
      "step": 12395
    },
    {
      "epoch": 4.007,
      "grad_norm": 9.436687469482422,
      "learning_rate": 1.7274575140626318e-05,
      "loss": 1.0316,
      "step": 12400
    },
    {
      "epoch": 4.00725,
      "grad_norm": 7.628448963165283,
      "learning_rate": 1.7254920992435536e-05,
      "loss": 1.0986,
      "step": 12405
    },
    {
      "epoch": 4.0075,
      "grad_norm": 7.554205417633057,
      "learning_rate": 1.723527213793322e-05,
      "loss": 1.1611,
      "step": 12410
    },
    {
      "epoch": 4.00775,
      "grad_norm": 8.046198844909668,
      "learning_rate": 1.7215628590549187e-05,
      "loss": 1.0643,
      "step": 12415
    },
    {
      "epoch": 4.008,
      "grad_norm": 7.045677661895752,
      "learning_rate": 1.7195990363709604e-05,
      "loss": 1.0607,
      "step": 12420
    },
    {
      "epoch": 4.00825,
      "grad_norm": 7.9509077072143555,
      "learning_rate": 1.7176357470837022e-05,
      "loss": 1.0898,
      "step": 12425
    },
    {
      "epoch": 4.0085,
      "grad_norm": 10.099099159240723,
      "learning_rate": 1.7156729925350336e-05,
      "loss": 0.9962,
      "step": 12430
    },
    {
      "epoch": 4.00875,
      "grad_norm": 7.884652614593506,
      "learning_rate": 1.7137107740664798e-05,
      "loss": 1.0036,
      "step": 12435
    },
    {
      "epoch": 4.009,
      "grad_norm": 9.534829139709473,
      "learning_rate": 1.7117490930191965e-05,
      "loss": 1.1032,
      "step": 12440
    },
    {
      "epoch": 4.00925,
      "grad_norm": 7.019514560699463,
      "learning_rate": 1.709787950733976e-05,
      "loss": 0.9956,
      "step": 12445
    },
    {
      "epoch": 4.0095,
      "grad_norm": 8.432245254516602,
      "learning_rate": 1.7078273485512392e-05,
      "loss": 0.9401,
      "step": 12450
    },
    {
      "epoch": 4.00975,
      "grad_norm": 10.915977478027344,
      "learning_rate": 1.7058672878110403e-05,
      "loss": 1.1178,
      "step": 12455
    },
    {
      "epoch": 4.01,
      "grad_norm": 7.445137023925781,
      "learning_rate": 1.703907769853062e-05,
      "loss": 1.0601,
      "step": 12460
    },
    {
      "epoch": 4.01025,
      "grad_norm": 8.65144157409668,
      "learning_rate": 1.7019487960166164e-05,
      "loss": 1.0822,
      "step": 12465
    },
    {
      "epoch": 4.0105,
      "grad_norm": 7.280984878540039,
      "learning_rate": 1.699990367640643e-05,
      "loss": 1.0749,
      "step": 12470
    },
    {
      "epoch": 4.01075,
      "grad_norm": 9.767057418823242,
      "learning_rate": 1.6980324860637106e-05,
      "loss": 0.9664,
      "step": 12475
    },
    {
      "epoch": 4.011,
      "grad_norm": 7.935267448425293,
      "learning_rate": 1.696075152624012e-05,
      "loss": 0.9586,
      "step": 12480
    },
    {
      "epoch": 4.01125,
      "grad_norm": 6.697587966918945,
      "learning_rate": 1.6941183686593655e-05,
      "loss": 0.9964,
      "step": 12485
    },
    {
      "epoch": 4.0115,
      "grad_norm": 7.691375255584717,
      "learning_rate": 1.6921621355072144e-05,
      "loss": 0.9839,
      "step": 12490
    },
    {
      "epoch": 4.01175,
      "grad_norm": 8.077540397644043,
      "learning_rate": 1.690206454504627e-05,
      "loss": 1.0729,
      "step": 12495
    },
    {
      "epoch": 4.012,
      "grad_norm": 7.426833152770996,
      "learning_rate": 1.6882513269882917e-05,
      "loss": 1.0343,
      "step": 12500
    },
    {
      "epoch": 4.012,
      "eval_loss": 1.9722234010696411,
      "eval_runtime": 5.7139,
      "eval_samples_per_second": 179.213,
      "eval_steps_per_second": 22.402,
      "step": 12500
    },
    {
      "epoch": 4.01225,
      "grad_norm": 7.589644432067871,
      "learning_rate": 1.6862967542945203e-05,
      "loss": 1.185,
      "step": 12505
    },
    {
      "epoch": 4.0125,
      "grad_norm": 7.431906223297119,
      "learning_rate": 1.684342737759244e-05,
      "loss": 1.0242,
      "step": 12510
    },
    {
      "epoch": 4.01275,
      "grad_norm": 6.988979339599609,
      "learning_rate": 1.682389278718016e-05,
      "loss": 0.897,
      "step": 12515
    },
    {
      "epoch": 4.013,
      "grad_norm": 8.79536247253418,
      "learning_rate": 1.6804363785060056e-05,
      "loss": 1.0295,
      "step": 12520
    },
    {
      "epoch": 4.01325,
      "grad_norm": 7.832751274108887,
      "learning_rate": 1.678484038458003e-05,
      "loss": 1.0102,
      "step": 12525
    },
    {
      "epoch": 4.0135,
      "grad_norm": 6.926747798919678,
      "learning_rate": 1.6765322599084147e-05,
      "loss": 0.8777,
      "step": 12530
    },
    {
      "epoch": 4.01375,
      "grad_norm": 7.347692489624023,
      "learning_rate": 1.6745810441912605e-05,
      "loss": 0.8565,
      "step": 12535
    },
    {
      "epoch": 4.014,
      "grad_norm": 9.525482177734375,
      "learning_rate": 1.6726303926401792e-05,
      "loss": 0.8489,
      "step": 12540
    },
    {
      "epoch": 4.01425,
      "grad_norm": 5.831007480621338,
      "learning_rate": 1.6706803065884237e-05,
      "loss": 0.7645,
      "step": 12545
    },
    {
      "epoch": 4.0145,
      "grad_norm": 4.851991653442383,
      "learning_rate": 1.668730787368858e-05,
      "loss": 0.6342,
      "step": 12550
    },
    {
      "epoch": 4.01475,
      "grad_norm": 5.244834899902344,
      "learning_rate": 1.6667818363139615e-05,
      "loss": 0.6435,
      "step": 12555
    },
    {
      "epoch": 4.015,
      "grad_norm": 4.665693283081055,
      "learning_rate": 1.6648334547558226e-05,
      "loss": 0.5759,
      "step": 12560
    },
    {
      "epoch": 4.01525,
      "grad_norm": 7.073149681091309,
      "learning_rate": 1.6628856440261423e-05,
      "loss": 0.5898,
      "step": 12565
    },
    {
      "epoch": 4.0155,
      "grad_norm": 7.413788318634033,
      "learning_rate": 1.6609384054562305e-05,
      "loss": 0.5389,
      "step": 12570
    },
    {
      "epoch": 4.01575,
      "grad_norm": 3.0557563304901123,
      "learning_rate": 1.6589917403770077e-05,
      "loss": 0.4333,
      "step": 12575
    },
    {
      "epoch": 4.016,
      "grad_norm": 2.3813679218292236,
      "learning_rate": 1.6570456501189998e-05,
      "loss": 0.4326,
      "step": 12580
    },
    {
      "epoch": 4.01625,
      "grad_norm": 2.9981601238250732,
      "learning_rate": 1.6551001360123407e-05,
      "loss": 0.4568,
      "step": 12585
    },
    {
      "epoch": 4.0165,
      "grad_norm": 12.11585807800293,
      "learning_rate": 1.6531551993867717e-05,
      "loss": 0.6113,
      "step": 12590
    },
    {
      "epoch": 4.01675,
      "grad_norm": 10.425503730773926,
      "learning_rate": 1.6512108415716394e-05,
      "loss": 1.1829,
      "step": 12595
    },
    {
      "epoch": 4.017,
      "grad_norm": 15.563427925109863,
      "learning_rate": 1.6492670638958924e-05,
      "loss": 1.266,
      "step": 12600
    },
    {
      "epoch": 4.01725,
      "grad_norm": 11.85165786743164,
      "learning_rate": 1.6473238676880858e-05,
      "loss": 1.2551,
      "step": 12605
    },
    {
      "epoch": 4.0175,
      "grad_norm": 11.642291069030762,
      "learning_rate": 1.6453812542763752e-05,
      "loss": 1.121,
      "step": 12610
    },
    {
      "epoch": 4.01775,
      "grad_norm": 9.160658836364746,
      "learning_rate": 1.6434392249885193e-05,
      "loss": 1.0501,
      "step": 12615
    },
    {
      "epoch": 4.018,
      "grad_norm": 8.698882102966309,
      "learning_rate": 1.641497781151877e-05,
      "loss": 1.0912,
      "step": 12620
    },
    {
      "epoch": 4.01825,
      "grad_norm": 10.384227752685547,
      "learning_rate": 1.639556924093404e-05,
      "loss": 1.1807,
      "step": 12625
    },
    {
      "epoch": 4.0185,
      "grad_norm": 7.473915100097656,
      "learning_rate": 1.6376166551396607e-05,
      "loss": 1.1337,
      "step": 12630
    },
    {
      "epoch": 4.01875,
      "grad_norm": 7.806779861450195,
      "learning_rate": 1.635676975616802e-05,
      "loss": 0.9902,
      "step": 12635
    },
    {
      "epoch": 4.019,
      "grad_norm": 8.461479187011719,
      "learning_rate": 1.6337378868505805e-05,
      "loss": 1.0597,
      "step": 12640
    },
    {
      "epoch": 4.01925,
      "grad_norm": 6.661793231964111,
      "learning_rate": 1.6317993901663448e-05,
      "loss": 1.0201,
      "step": 12645
    },
    {
      "epoch": 4.0195,
      "grad_norm": 8.120903968811035,
      "learning_rate": 1.6298614868890387e-05,
      "loss": 1.0452,
      "step": 12650
    },
    {
      "epoch": 4.01975,
      "grad_norm": 7.5421671867370605,
      "learning_rate": 1.6279241783432025e-05,
      "loss": 0.9015,
      "step": 12655
    },
    {
      "epoch": 4.02,
      "grad_norm": 8.06120777130127,
      "learning_rate": 1.6259874658529663e-05,
      "loss": 1.0236,
      "step": 12660
    },
    {
      "epoch": 4.02025,
      "grad_norm": 9.292019844055176,
      "learning_rate": 1.6240513507420563e-05,
      "loss": 1.1465,
      "step": 12665
    },
    {
      "epoch": 4.0205,
      "grad_norm": 7.59504508972168,
      "learning_rate": 1.622115834333789e-05,
      "loss": 1.1089,
      "step": 12670
    },
    {
      "epoch": 4.02075,
      "grad_norm": 8.184638977050781,
      "learning_rate": 1.6201809179510702e-05,
      "loss": 0.9579,
      "step": 12675
    },
    {
      "epoch": 4.021,
      "grad_norm": 10.822710037231445,
      "learning_rate": 1.6182466029163975e-05,
      "loss": 1.1373,
      "step": 12680
    },
    {
      "epoch": 4.02125,
      "grad_norm": 6.828304767608643,
      "learning_rate": 1.6163128905518578e-05,
      "loss": 0.9774,
      "step": 12685
    },
    {
      "epoch": 4.0215,
      "grad_norm": 8.959074974060059,
      "learning_rate": 1.614379782179124e-05,
      "loss": 0.9987,
      "step": 12690
    },
    {
      "epoch": 4.02175,
      "grad_norm": 11.953930854797363,
      "learning_rate": 1.612447279119459e-05,
      "loss": 1.104,
      "step": 12695
    },
    {
      "epoch": 4.022,
      "grad_norm": 9.078313827514648,
      "learning_rate": 1.6105153826937085e-05,
      "loss": 1.0852,
      "step": 12700
    },
    {
      "epoch": 4.02225,
      "grad_norm": 11.301229476928711,
      "learning_rate": 1.608584094222308e-05,
      "loss": 1.2069,
      "step": 12705
    },
    {
      "epoch": 4.0225,
      "grad_norm": 7.865999221801758,
      "learning_rate": 1.6066534150252727e-05,
      "loss": 1.2401,
      "step": 12710
    },
    {
      "epoch": 4.02275,
      "grad_norm": 8.540346145629883,
      "learning_rate": 1.604723346422205e-05,
      "loss": 1.0795,
      "step": 12715
    },
    {
      "epoch": 4.023,
      "grad_norm": 7.868548393249512,
      "learning_rate": 1.602793889732288e-05,
      "loss": 1.073,
      "step": 12720
    },
    {
      "epoch": 4.02325,
      "grad_norm": 7.8516764640808105,
      "learning_rate": 1.600865046274287e-05,
      "loss": 0.918,
      "step": 12725
    },
    {
      "epoch": 4.0235,
      "grad_norm": 7.722693920135498,
      "learning_rate": 1.598936817366548e-05,
      "loss": 1.066,
      "step": 12730
    },
    {
      "epoch": 4.02375,
      "grad_norm": 7.265649318695068,
      "learning_rate": 1.5970092043269986e-05,
      "loss": 0.9308,
      "step": 12735
    },
    {
      "epoch": 4.024,
      "grad_norm": 7.3358635902404785,
      "learning_rate": 1.5950822084731426e-05,
      "loss": 1.0197,
      "step": 12740
    },
    {
      "epoch": 4.02425,
      "grad_norm": 6.72845458984375,
      "learning_rate": 1.593155831122065e-05,
      "loss": 0.9159,
      "step": 12745
    },
    {
      "epoch": 4.0245,
      "grad_norm": 9.492093086242676,
      "learning_rate": 1.591230073590425e-05,
      "loss": 1.1834,
      "step": 12750
    },
    {
      "epoch": 4.02475,
      "grad_norm": 8.413219451904297,
      "learning_rate": 1.5893049371944614e-05,
      "loss": 0.9743,
      "step": 12755
    },
    {
      "epoch": 4.025,
      "grad_norm": 10.572583198547363,
      "learning_rate": 1.5873804232499863e-05,
      "loss": 1.0324,
      "step": 12760
    },
    {
      "epoch": 4.02525,
      "grad_norm": 5.585312366485596,
      "learning_rate": 1.585456533072385e-05,
      "loss": 1.0516,
      "step": 12765
    },
    {
      "epoch": 4.0255,
      "grad_norm": 10.095787048339844,
      "learning_rate": 1.583533267976621e-05,
      "loss": 1.1604,
      "step": 12770
    },
    {
      "epoch": 4.02575,
      "grad_norm": 9.541301727294922,
      "learning_rate": 1.5816106292772255e-05,
      "loss": 1.1344,
      "step": 12775
    },
    {
      "epoch": 4.026,
      "grad_norm": 8.438746452331543,
      "learning_rate": 1.5796886182883053e-05,
      "loss": 1.0106,
      "step": 12780
    },
    {
      "epoch": 4.02625,
      "grad_norm": 8.287273406982422,
      "learning_rate": 1.5777672363235368e-05,
      "loss": 1.2362,
      "step": 12785
    },
    {
      "epoch": 4.0265,
      "grad_norm": 7.334263324737549,
      "learning_rate": 1.5758464846961657e-05,
      "loss": 0.9354,
      "step": 12790
    },
    {
      "epoch": 4.02675,
      "grad_norm": 8.273730278015137,
      "learning_rate": 1.5739263647190085e-05,
      "loss": 1.0767,
      "step": 12795
    },
    {
      "epoch": 4.027,
      "grad_norm": 8.238245964050293,
      "learning_rate": 1.5720068777044476e-05,
      "loss": 1.0169,
      "step": 12800
    },
    {
      "epoch": 4.02725,
      "grad_norm": 7.7981085777282715,
      "learning_rate": 1.5700880249644366e-05,
      "loss": 1.0347,
      "step": 12805
    },
    {
      "epoch": 4.0275,
      "grad_norm": 8.426196098327637,
      "learning_rate": 1.5681698078104926e-05,
      "loss": 0.9529,
      "step": 12810
    },
    {
      "epoch": 4.02775,
      "grad_norm": 8.3305025100708,
      "learning_rate": 1.5662522275536966e-05,
      "loss": 1.081,
      "step": 12815
    },
    {
      "epoch": 4.028,
      "grad_norm": 10.247254371643066,
      "learning_rate": 1.5643352855046996e-05,
      "loss": 1.043,
      "step": 12820
    },
    {
      "epoch": 4.02825,
      "grad_norm": 10.07483196258545,
      "learning_rate": 1.5624189829737112e-05,
      "loss": 1.1266,
      "step": 12825
    },
    {
      "epoch": 4.0285,
      "grad_norm": 7.580399513244629,
      "learning_rate": 1.560503321270507e-05,
      "loss": 0.9576,
      "step": 12830
    },
    {
      "epoch": 4.02875,
      "grad_norm": 10.759471893310547,
      "learning_rate": 1.558588301704425e-05,
      "loss": 1.0848,
      "step": 12835
    },
    {
      "epoch": 4.029,
      "grad_norm": 8.794000625610352,
      "learning_rate": 1.5566739255843606e-05,
      "loss": 1.0388,
      "step": 12840
    },
    {
      "epoch": 4.02925,
      "grad_norm": 8.117692947387695,
      "learning_rate": 1.554760194218774e-05,
      "loss": 1.037,
      "step": 12845
    },
    {
      "epoch": 4.0295,
      "grad_norm": 5.885335445404053,
      "learning_rate": 1.5528471089156804e-05,
      "loss": 0.8984,
      "step": 12850
    },
    {
      "epoch": 4.02975,
      "grad_norm": 10.097021102905273,
      "learning_rate": 1.5509346709826583e-05,
      "loss": 1.0183,
      "step": 12855
    },
    {
      "epoch": 4.03,
      "grad_norm": 6.446589469909668,
      "learning_rate": 1.549022881726839e-05,
      "loss": 0.9555,
      "step": 12860
    },
    {
      "epoch": 4.03025,
      "grad_norm": 9.381878852844238,
      "learning_rate": 1.547111742454912e-05,
      "loss": 1.0397,
      "step": 12865
    },
    {
      "epoch": 4.0305,
      "grad_norm": 7.054198741912842,
      "learning_rate": 1.5452012544731245e-05,
      "loss": 1.0536,
      "step": 12870
    },
    {
      "epoch": 4.03075,
      "grad_norm": 8.77481746673584,
      "learning_rate": 1.5432914190872757e-05,
      "loss": 1.0465,
      "step": 12875
    },
    {
      "epoch": 4.031,
      "grad_norm": 6.127184867858887,
      "learning_rate": 1.541382237602721e-05,
      "loss": 0.9686,
      "step": 12880
    },
    {
      "epoch": 4.03125,
      "grad_norm": 8.575458526611328,
      "learning_rate": 1.5394737113243678e-05,
      "loss": 1.1046,
      "step": 12885
    },
    {
      "epoch": 4.0315,
      "grad_norm": 8.43717098236084,
      "learning_rate": 1.537565841556676e-05,
      "loss": 1.0162,
      "step": 12890
    },
    {
      "epoch": 4.03175,
      "grad_norm": 6.671054363250732,
      "learning_rate": 1.5356586296036558e-05,
      "loss": 1.0429,
      "step": 12895
    },
    {
      "epoch": 4.032,
      "grad_norm": 9.071619033813477,
      "learning_rate": 1.5337520767688703e-05,
      "loss": 0.9255,
      "step": 12900
    },
    {
      "epoch": 4.03225,
      "grad_norm": 8.311017990112305,
      "learning_rate": 1.5318461843554277e-05,
      "loss": 0.9384,
      "step": 12905
    },
    {
      "epoch": 4.0325,
      "grad_norm": 9.006087303161621,
      "learning_rate": 1.5299409536659895e-05,
      "loss": 0.9239,
      "step": 12910
    },
    {
      "epoch": 4.03275,
      "grad_norm": 9.526872634887695,
      "learning_rate": 1.5280363860027618e-05,
      "loss": 0.9267,
      "step": 12915
    },
    {
      "epoch": 4.033,
      "grad_norm": 8.410670280456543,
      "learning_rate": 1.5261324826675e-05,
      "loss": 1.0075,
      "step": 12920
    },
    {
      "epoch": 4.03325,
      "grad_norm": 6.160112380981445,
      "learning_rate": 1.5242292449615025e-05,
      "loss": 1.0268,
      "step": 12925
    },
    {
      "epoch": 4.0335,
      "grad_norm": 7.493654251098633,
      "learning_rate": 1.5223266741856152e-05,
      "loss": 1.0135,
      "step": 12930
    },
    {
      "epoch": 4.03375,
      "grad_norm": 11.099430084228516,
      "learning_rate": 1.5204247716402279e-05,
      "loss": 1.0404,
      "step": 12935
    },
    {
      "epoch": 4.034,
      "grad_norm": 7.719606399536133,
      "learning_rate": 1.5185235386252717e-05,
      "loss": 1.218,
      "step": 12940
    },
    {
      "epoch": 4.03425,
      "grad_norm": 7.347239971160889,
      "learning_rate": 1.5166229764402229e-05,
      "loss": 0.9193,
      "step": 12945
    },
    {
      "epoch": 4.0345,
      "grad_norm": 8.36843490600586,
      "learning_rate": 1.5147230863840966e-05,
      "loss": 1.0725,
      "step": 12950
    },
    {
      "epoch": 4.03475,
      "grad_norm": 6.811784267425537,
      "learning_rate": 1.5128238697554498e-05,
      "loss": 1.1412,
      "step": 12955
    },
    {
      "epoch": 4.035,
      "grad_norm": 7.334437370300293,
      "learning_rate": 1.5109253278523799e-05,
      "loss": 1.2427,
      "step": 12960
    },
    {
      "epoch": 4.03525,
      "grad_norm": 6.7263383865356445,
      "learning_rate": 1.5090274619725214e-05,
      "loss": 1.1538,
      "step": 12965
    },
    {
      "epoch": 4.0355,
      "grad_norm": 6.492527008056641,
      "learning_rate": 1.5071302734130489e-05,
      "loss": 1.0667,
      "step": 12970
    },
    {
      "epoch": 4.03575,
      "grad_norm": 6.970434665679932,
      "learning_rate": 1.505233763470672e-05,
      "loss": 1.0684,
      "step": 12975
    },
    {
      "epoch": 4.036,
      "grad_norm": 9.232405662536621,
      "learning_rate": 1.5033379334416375e-05,
      "loss": 1.2759,
      "step": 12980
    },
    {
      "epoch": 4.03625,
      "grad_norm": 6.694869041442871,
      "learning_rate": 1.501442784621728e-05,
      "loss": 1.0576,
      "step": 12985
    },
    {
      "epoch": 4.0365,
      "grad_norm": 7.435342311859131,
      "learning_rate": 1.499548318306259e-05,
      "loss": 1.1307,
      "step": 12990
    },
    {
      "epoch": 4.03675,
      "grad_norm": 7.558204650878906,
      "learning_rate": 1.4976545357900817e-05,
      "loss": 1.1035,
      "step": 12995
    },
    {
      "epoch": 4.037,
      "grad_norm": 6.407999038696289,
      "learning_rate": 1.495761438367577e-05,
      "loss": 1.1777,
      "step": 13000
    },
    {
      "epoch": 4.037,
      "eval_loss": 1.945876121520996,
      "eval_runtime": 5.648,
      "eval_samples_per_second": 181.302,
      "eval_steps_per_second": 22.663,
      "step": 13000
    },
    {
      "epoch": 4.03725,
      "grad_norm": 7.087948322296143,
      "learning_rate": 1.4938690273326594e-05,
      "loss": 1.1461,
      "step": 13005
    },
    {
      "epoch": 4.0375,
      "grad_norm": 8.770746231079102,
      "learning_rate": 1.4919773039787748e-05,
      "loss": 1.3521,
      "step": 13010
    },
    {
      "epoch": 4.03775,
      "grad_norm": 7.3350348472595215,
      "learning_rate": 1.4900862695988974e-05,
      "loss": 1.1296,
      "step": 13015
    },
    {
      "epoch": 4.038,
      "grad_norm": 7.002337455749512,
      "learning_rate": 1.4881959254855324e-05,
      "loss": 1.1163,
      "step": 13020
    },
    {
      "epoch": 4.03825,
      "grad_norm": 9.762962341308594,
      "learning_rate": 1.4863062729307109e-05,
      "loss": 1.135,
      "step": 13025
    },
    {
      "epoch": 4.0385,
      "grad_norm": 7.962286949157715,
      "learning_rate": 1.4844173132259933e-05,
      "loss": 1.1434,
      "step": 13030
    },
    {
      "epoch": 4.03875,
      "grad_norm": 7.323617935180664,
      "learning_rate": 1.4825290476624665e-05,
      "loss": 1.2428,
      "step": 13035
    },
    {
      "epoch": 4.039,
      "grad_norm": 6.443578243255615,
      "learning_rate": 1.4806414775307418e-05,
      "loss": 1.1342,
      "step": 13040
    },
    {
      "epoch": 4.03925,
      "grad_norm": 7.561845779418945,
      "learning_rate": 1.4787546041209543e-05,
      "loss": 1.1274,
      "step": 13045
    },
    {
      "epoch": 4.0395,
      "grad_norm": 8.212010383605957,
      "learning_rate": 1.4768684287227652e-05,
      "loss": 1.1306,
      "step": 13050
    },
    {
      "epoch": 4.03975,
      "grad_norm": 6.392111301422119,
      "learning_rate": 1.4749829526253576e-05,
      "loss": 1.0604,
      "step": 13055
    },
    {
      "epoch": 4.04,
      "grad_norm": 7.857274055480957,
      "learning_rate": 1.4730981771174369e-05,
      "loss": 1.0852,
      "step": 13060
    },
    {
      "epoch": 4.04025,
      "grad_norm": 5.719918727874756,
      "learning_rate": 1.4712141034872282e-05,
      "loss": 1.1383,
      "step": 13065
    },
    {
      "epoch": 4.0405,
      "grad_norm": 7.553372383117676,
      "learning_rate": 1.4693307330224798e-05,
      "loss": 1.0411,
      "step": 13070
    },
    {
      "epoch": 4.04075,
      "grad_norm": 5.8881964683532715,
      "learning_rate": 1.467448067010456e-05,
      "loss": 0.9718,
      "step": 13075
    },
    {
      "epoch": 4.041,
      "grad_norm": 7.952657222747803,
      "learning_rate": 1.465566106737942e-05,
      "loss": 1.1934,
      "step": 13080
    },
    {
      "epoch": 4.04125,
      "grad_norm": 7.830841064453125,
      "learning_rate": 1.4636848534912409e-05,
      "loss": 1.0677,
      "step": 13085
    },
    {
      "epoch": 4.0415,
      "grad_norm": 7.255121231079102,
      "learning_rate": 1.4618043085561702e-05,
      "loss": 1.1423,
      "step": 13090
    },
    {
      "epoch": 4.04175,
      "grad_norm": 6.548537254333496,
      "learning_rate": 1.4599244732180644e-05,
      "loss": 1.1755,
      "step": 13095
    },
    {
      "epoch": 4.042,
      "grad_norm": 9.06385326385498,
      "learning_rate": 1.4580453487617745e-05,
      "loss": 1.1234,
      "step": 13100
    },
    {
      "epoch": 4.04225,
      "grad_norm": 9.188831329345703,
      "learning_rate": 1.4561669364716629e-05,
      "loss": 1.1273,
      "step": 13105
    },
    {
      "epoch": 4.0425,
      "grad_norm": 7.415701389312744,
      "learning_rate": 1.4542892376316078e-05,
      "loss": 1.157,
      "step": 13110
    },
    {
      "epoch": 4.04275,
      "grad_norm": 7.761357307434082,
      "learning_rate": 1.452412253524999e-05,
      "loss": 1.1222,
      "step": 13115
    },
    {
      "epoch": 4.043,
      "grad_norm": 10.787611961364746,
      "learning_rate": 1.4505359854347361e-05,
      "loss": 1.1094,
      "step": 13120
    },
    {
      "epoch": 4.04325,
      "grad_norm": 7.188796043395996,
      "learning_rate": 1.4486604346432312e-05,
      "loss": 1.241,
      "step": 13125
    },
    {
      "epoch": 4.0435,
      "grad_norm": 9.147198677062988,
      "learning_rate": 1.4467856024324056e-05,
      "loss": 1.3001,
      "step": 13130
    },
    {
      "epoch": 4.04375,
      "grad_norm": 6.921168327331543,
      "learning_rate": 1.4449114900836902e-05,
      "loss": 1.0209,
      "step": 13135
    },
    {
      "epoch": 4.044,
      "grad_norm": 7.8324666023254395,
      "learning_rate": 1.4430380988780218e-05,
      "loss": 1.0898,
      "step": 13140
    },
    {
      "epoch": 4.04425,
      "grad_norm": 5.69038724899292,
      "learning_rate": 1.4411654300958474e-05,
      "loss": 1.0636,
      "step": 13145
    },
    {
      "epoch": 4.0445,
      "grad_norm": 6.759932994842529,
      "learning_rate": 1.439293485017116e-05,
      "loss": 1.0845,
      "step": 13150
    },
    {
      "epoch": 4.04475,
      "grad_norm": 8.259103775024414,
      "learning_rate": 1.437422264921286e-05,
      "loss": 1.1768,
      "step": 13155
    },
    {
      "epoch": 4.045,
      "grad_norm": 7.107217788696289,
      "learning_rate": 1.4355517710873184e-05,
      "loss": 1.1006,
      "step": 13160
    },
    {
      "epoch": 4.04525,
      "grad_norm": 7.041530609130859,
      "learning_rate": 1.4336820047936789e-05,
      "loss": 1.1027,
      "step": 13165
    },
    {
      "epoch": 4.0455,
      "grad_norm": 8.204425811767578,
      "learning_rate": 1.4318129673183333e-05,
      "loss": 1.0712,
      "step": 13170
    },
    {
      "epoch": 4.04575,
      "grad_norm": 6.676623821258545,
      "learning_rate": 1.4299446599387522e-05,
      "loss": 1.1042,
      "step": 13175
    },
    {
      "epoch": 4.046,
      "grad_norm": 7.164371013641357,
      "learning_rate": 1.4280770839319071e-05,
      "loss": 1.0855,
      "step": 13180
    },
    {
      "epoch": 4.04625,
      "grad_norm": 8.151658058166504,
      "learning_rate": 1.4262102405742667e-05,
      "loss": 1.2619,
      "step": 13185
    },
    {
      "epoch": 4.0465,
      "grad_norm": 6.758504390716553,
      "learning_rate": 1.4243441311418013e-05,
      "loss": 1.0191,
      "step": 13190
    },
    {
      "epoch": 4.04675,
      "grad_norm": 6.549086093902588,
      "learning_rate": 1.4224787569099807e-05,
      "loss": 1.0704,
      "step": 13195
    },
    {
      "epoch": 4.047,
      "grad_norm": 8.218101501464844,
      "learning_rate": 1.4206141191537682e-05,
      "loss": 1.0902,
      "step": 13200
    },
    {
      "epoch": 4.04725,
      "grad_norm": 7.496697425842285,
      "learning_rate": 1.4187502191476271e-05,
      "loss": 1.1236,
      "step": 13205
    },
    {
      "epoch": 4.0475,
      "grad_norm": 7.203683376312256,
      "learning_rate": 1.4168870581655159e-05,
      "loss": 1.0018,
      "step": 13210
    },
    {
      "epoch": 4.04775,
      "grad_norm": 7.929101467132568,
      "learning_rate": 1.4150246374808882e-05,
      "loss": 1.1483,
      "step": 13215
    },
    {
      "epoch": 4.048,
      "grad_norm": 7.60128116607666,
      "learning_rate": 1.4131629583666888e-05,
      "loss": 1.2159,
      "step": 13220
    },
    {
      "epoch": 4.04825,
      "grad_norm": 8.724313735961914,
      "learning_rate": 1.4113020220953604e-05,
      "loss": 1.2146,
      "step": 13225
    },
    {
      "epoch": 4.0485,
      "grad_norm": 7.141274929046631,
      "learning_rate": 1.4094418299388331e-05,
      "loss": 1.173,
      "step": 13230
    },
    {
      "epoch": 4.04875,
      "grad_norm": 6.8499627113342285,
      "learning_rate": 1.4075823831685316e-05,
      "loss": 1.2072,
      "step": 13235
    },
    {
      "epoch": 4.049,
      "grad_norm": 8.469295501708984,
      "learning_rate": 1.4057236830553704e-05,
      "loss": 1.1876,
      "step": 13240
    },
    {
      "epoch": 4.04925,
      "grad_norm": 7.389737606048584,
      "learning_rate": 1.4038657308697545e-05,
      "loss": 1.2098,
      "step": 13245
    },
    {
      "epoch": 4.0495,
      "grad_norm": 12.730027198791504,
      "learning_rate": 1.4020085278815745e-05,
      "loss": 1.1735,
      "step": 13250
    },
    {
      "epoch": 4.04975,
      "grad_norm": 6.298370361328125,
      "learning_rate": 1.4001520753602121e-05,
      "loss": 1.0461,
      "step": 13255
    },
    {
      "epoch": 4.05,
      "grad_norm": 7.618393421173096,
      "learning_rate": 1.3982963745745352e-05,
      "loss": 1.0774,
      "step": 13260
    },
    {
      "epoch": 4.05025,
      "grad_norm": 6.990222930908203,
      "learning_rate": 1.3964414267928994e-05,
      "loss": 1.1389,
      "step": 13265
    },
    {
      "epoch": 4.0505,
      "grad_norm": 7.410702228546143,
      "learning_rate": 1.3945872332831412e-05,
      "loss": 1.1604,
      "step": 13270
    },
    {
      "epoch": 4.05075,
      "grad_norm": 7.962705135345459,
      "learning_rate": 1.3927337953125863e-05,
      "loss": 1.2369,
      "step": 13275
    },
    {
      "epoch": 4.051,
      "grad_norm": 6.018550395965576,
      "learning_rate": 1.3908811141480408e-05,
      "loss": 1.0292,
      "step": 13280
    },
    {
      "epoch": 4.05125,
      "grad_norm": 6.684244632720947,
      "learning_rate": 1.389029191055795e-05,
      "loss": 1.131,
      "step": 13285
    },
    {
      "epoch": 4.0515,
      "grad_norm": 5.835720062255859,
      "learning_rate": 1.3871780273016215e-05,
      "loss": 0.982,
      "step": 13290
    },
    {
      "epoch": 4.05175,
      "grad_norm": 7.83029317855835,
      "learning_rate": 1.3853276241507743e-05,
      "loss": 1.1414,
      "step": 13295
    },
    {
      "epoch": 4.052,
      "grad_norm": 5.987643718719482,
      "learning_rate": 1.383477982867984e-05,
      "loss": 1.0309,
      "step": 13300
    },
    {
      "epoch": 4.05225,
      "grad_norm": 6.732628345489502,
      "learning_rate": 1.3816291047174643e-05,
      "loss": 1.0396,
      "step": 13305
    },
    {
      "epoch": 4.0525,
      "grad_norm": 7.455763339996338,
      "learning_rate": 1.3797809909629058e-05,
      "loss": 1.0828,
      "step": 13310
    },
    {
      "epoch": 4.05275,
      "grad_norm": 7.5293378829956055,
      "learning_rate": 1.3779336428674783e-05,
      "loss": 1.0351,
      "step": 13315
    },
    {
      "epoch": 4.053,
      "grad_norm": 7.967874050140381,
      "learning_rate": 1.3760870616938248e-05,
      "loss": 1.0488,
      "step": 13320
    },
    {
      "epoch": 4.05325,
      "grad_norm": 7.232010841369629,
      "learning_rate": 1.3742412487040662e-05,
      "loss": 1.0923,
      "step": 13325
    },
    {
      "epoch": 4.0535,
      "grad_norm": 8.265387535095215,
      "learning_rate": 1.3723962051597988e-05,
      "loss": 0.9858,
      "step": 13330
    },
    {
      "epoch": 4.05375,
      "grad_norm": 6.775749683380127,
      "learning_rate": 1.3705519323220928e-05,
      "loss": 0.9792,
      "step": 13335
    },
    {
      "epoch": 4.054,
      "grad_norm": 8.545899391174316,
      "learning_rate": 1.3687084314514907e-05,
      "loss": 0.9793,
      "step": 13340
    },
    {
      "epoch": 4.05425,
      "grad_norm": 7.443105697631836,
      "learning_rate": 1.366865703808009e-05,
      "loss": 0.9893,
      "step": 13345
    },
    {
      "epoch": 4.0545,
      "grad_norm": 8.21528434753418,
      "learning_rate": 1.3650237506511331e-05,
      "loss": 1.2367,
      "step": 13350
    },
    {
      "epoch": 4.05475,
      "grad_norm": 6.893204212188721,
      "learning_rate": 1.3631825732398218e-05,
      "loss": 1.1524,
      "step": 13355
    },
    {
      "epoch": 4.055,
      "grad_norm": 8.602781295776367,
      "learning_rate": 1.3613421728325018e-05,
      "loss": 1.0584,
      "step": 13360
    },
    {
      "epoch": 4.05525,
      "grad_norm": 6.13994026184082,
      "learning_rate": 1.3595025506870707e-05,
      "loss": 1.0808,
      "step": 13365
    },
    {
      "epoch": 4.0555,
      "grad_norm": 7.40170955657959,
      "learning_rate": 1.3576637080608923e-05,
      "loss": 1.0021,
      "step": 13370
    },
    {
      "epoch": 4.05575,
      "grad_norm": 7.588743686676025,
      "learning_rate": 1.3558256462107965e-05,
      "loss": 1.1157,
      "step": 13375
    },
    {
      "epoch": 4.056,
      "grad_norm": 7.025635719299316,
      "learning_rate": 1.353988366393083e-05,
      "loss": 1.1176,
      "step": 13380
    },
    {
      "epoch": 4.05625,
      "grad_norm": 9.2094087600708,
      "learning_rate": 1.3521518698635143e-05,
      "loss": 1.1257,
      "step": 13385
    },
    {
      "epoch": 4.0565,
      "grad_norm": 5.587883472442627,
      "learning_rate": 1.3503161578773193e-05,
      "loss": 0.9502,
      "step": 13390
    },
    {
      "epoch": 4.05675,
      "grad_norm": 8.961861610412598,
      "learning_rate": 1.3484812316891903e-05,
      "loss": 1.0723,
      "step": 13395
    },
    {
      "epoch": 4.057,
      "grad_norm": 5.655673503875732,
      "learning_rate": 1.346647092553281e-05,
      "loss": 0.9494,
      "step": 13400
    },
    {
      "epoch": 4.05725,
      "grad_norm": 5.0782389640808105,
      "learning_rate": 1.3448137417232076e-05,
      "loss": 1.0806,
      "step": 13405
    },
    {
      "epoch": 4.0575,
      "grad_norm": 7.997102737426758,
      "learning_rate": 1.3429811804520492e-05,
      "loss": 1.0969,
      "step": 13410
    },
    {
      "epoch": 4.05775,
      "grad_norm": 7.428718090057373,
      "learning_rate": 1.3411494099923452e-05,
      "loss": 0.9433,
      "step": 13415
    },
    {
      "epoch": 4.058,
      "grad_norm": 6.816636085510254,
      "learning_rate": 1.3393184315960918e-05,
      "loss": 0.9121,
      "step": 13420
    },
    {
      "epoch": 4.05825,
      "grad_norm": 6.85653018951416,
      "learning_rate": 1.3374882465147454e-05,
      "loss": 0.9563,
      "step": 13425
    },
    {
      "epoch": 4.0585,
      "grad_norm": 6.457423686981201,
      "learning_rate": 1.33565885599922e-05,
      "loss": 1.0522,
      "step": 13430
    },
    {
      "epoch": 4.05875,
      "grad_norm": 9.024065971374512,
      "learning_rate": 1.3338302612998877e-05,
      "loss": 1.0149,
      "step": 13435
    },
    {
      "epoch": 4.059,
      "grad_norm": 9.465810775756836,
      "learning_rate": 1.3320024636665757e-05,
      "loss": 1.2179,
      "step": 13440
    },
    {
      "epoch": 4.05925,
      "grad_norm": 5.529541015625,
      "learning_rate": 1.330175464348567e-05,
      "loss": 1.0246,
      "step": 13445
    },
    {
      "epoch": 4.0595,
      "grad_norm": 7.6868577003479,
      "learning_rate": 1.3283492645945966e-05,
      "loss": 1.1571,
      "step": 13450
    },
    {
      "epoch": 4.05975,
      "grad_norm": 8.236936569213867,
      "learning_rate": 1.3265238656528561e-05,
      "loss": 1.117,
      "step": 13455
    },
    {
      "epoch": 4.06,
      "grad_norm": 8.3075532913208,
      "learning_rate": 1.3246992687709889e-05,
      "loss": 1.2533,
      "step": 13460
    },
    {
      "epoch": 4.06025,
      "grad_norm": 7.598972320556641,
      "learning_rate": 1.3228754751960882e-05,
      "loss": 1.0958,
      "step": 13465
    },
    {
      "epoch": 4.0605,
      "grad_norm": 9.612754821777344,
      "learning_rate": 1.3210524861747015e-05,
      "loss": 1.2258,
      "step": 13470
    },
    {
      "epoch": 4.06075,
      "grad_norm": 7.4851603507995605,
      "learning_rate": 1.319230302952823e-05,
      "loss": 1.061,
      "step": 13475
    },
    {
      "epoch": 4.061,
      "grad_norm": 7.584892272949219,
      "learning_rate": 1.3174089267758983e-05,
      "loss": 1.0509,
      "step": 13480
    },
    {
      "epoch": 4.06125,
      "grad_norm": 8.83179759979248,
      "learning_rate": 1.3155883588888207e-05,
      "loss": 1.0209,
      "step": 13485
    },
    {
      "epoch": 4.0615,
      "grad_norm": 6.692699909210205,
      "learning_rate": 1.3137686005359318e-05,
      "loss": 1.0933,
      "step": 13490
    },
    {
      "epoch": 4.06175,
      "grad_norm": 6.736690998077393,
      "learning_rate": 1.3119496529610197e-05,
      "loss": 1.0389,
      "step": 13495
    },
    {
      "epoch": 4.062,
      "grad_norm": 6.232082366943359,
      "learning_rate": 1.3101315174073162e-05,
      "loss": 1.0918,
      "step": 13500
    },
    {
      "epoch": 4.062,
      "eval_loss": 1.9605326652526855,
      "eval_runtime": 5.2498,
      "eval_samples_per_second": 195.053,
      "eval_steps_per_second": 24.382,
      "step": 13500
    },
    {
      "epoch": 4.06225,
      "grad_norm": 9.439051628112793,
      "learning_rate": 1.3083141951175019e-05,
      "loss": 1.1162,
      "step": 13505
    },
    {
      "epoch": 4.0625,
      "grad_norm": 5.894465446472168,
      "learning_rate": 1.306497687333697e-05,
      "loss": 0.9314,
      "step": 13510
    },
    {
      "epoch": 4.06275,
      "grad_norm": 8.837571144104004,
      "learning_rate": 1.3046819952974692e-05,
      "loss": 0.9478,
      "step": 13515
    },
    {
      "epoch": 4.063,
      "grad_norm": 7.7613115310668945,
      "learning_rate": 1.3028671202498261e-05,
      "loss": 1.1104,
      "step": 13520
    },
    {
      "epoch": 4.06325,
      "grad_norm": 8.537784576416016,
      "learning_rate": 1.301053063431219e-05,
      "loss": 1.2196,
      "step": 13525
    },
    {
      "epoch": 4.0635,
      "grad_norm": 6.043214797973633,
      "learning_rate": 1.2992398260815369e-05,
      "loss": 0.9332,
      "step": 13530
    },
    {
      "epoch": 4.06375,
      "grad_norm": 6.829021453857422,
      "learning_rate": 1.2974274094401111e-05,
      "loss": 1.0695,
      "step": 13535
    },
    {
      "epoch": 4.064,
      "grad_norm": 8.440218925476074,
      "learning_rate": 1.2956158147457115e-05,
      "loss": 1.0087,
      "step": 13540
    },
    {
      "epoch": 4.06425,
      "grad_norm": 10.136274337768555,
      "learning_rate": 1.2938050432365466e-05,
      "loss": 1.1193,
      "step": 13545
    },
    {
      "epoch": 4.0645,
      "grad_norm": 6.3567657470703125,
      "learning_rate": 1.2919950961502603e-05,
      "loss": 0.9869,
      "step": 13550
    },
    {
      "epoch": 4.06475,
      "grad_norm": 8.573307037353516,
      "learning_rate": 1.2901859747239353e-05,
      "loss": 1.1421,
      "step": 13555
    },
    {
      "epoch": 4.065,
      "grad_norm": 9.20040512084961,
      "learning_rate": 1.2883776801940884e-05,
      "loss": 1.1844,
      "step": 13560
    },
    {
      "epoch": 4.06525,
      "grad_norm": 9.505245208740234,
      "learning_rate": 1.2865702137966717e-05,
      "loss": 1.2141,
      "step": 13565
    },
    {
      "epoch": 4.0655,
      "grad_norm": 8.110444068908691,
      "learning_rate": 1.2847635767670722e-05,
      "loss": 1.0764,
      "step": 13570
    },
    {
      "epoch": 4.06575,
      "grad_norm": 7.289112567901611,
      "learning_rate": 1.2829577703401096e-05,
      "loss": 1.017,
      "step": 13575
    },
    {
      "epoch": 4.066,
      "grad_norm": 6.806513786315918,
      "learning_rate": 1.2811527957500345e-05,
      "loss": 1.0754,
      "step": 13580
    },
    {
      "epoch": 4.06625,
      "grad_norm": 9.75177001953125,
      "learning_rate": 1.27934865423053e-05,
      "loss": 1.2685,
      "step": 13585
    },
    {
      "epoch": 4.0665,
      "grad_norm": 7.882388591766357,
      "learning_rate": 1.2775453470147106e-05,
      "loss": 1.0495,
      "step": 13590
    },
    {
      "epoch": 4.06675,
      "grad_norm": 8.628165245056152,
      "learning_rate": 1.2757428753351202e-05,
      "loss": 1.0353,
      "step": 13595
    },
    {
      "epoch": 4.067,
      "grad_norm": 6.190789699554443,
      "learning_rate": 1.2739412404237306e-05,
      "loss": 0.9997,
      "step": 13600
    },
    {
      "epoch": 4.06725,
      "grad_norm": 6.041135311126709,
      "learning_rate": 1.2721404435119411e-05,
      "loss": 0.9481,
      "step": 13605
    },
    {
      "epoch": 4.0675,
      "grad_norm": 6.567789554595947,
      "learning_rate": 1.2703404858305806e-05,
      "loss": 0.9277,
      "step": 13610
    },
    {
      "epoch": 4.06775,
      "grad_norm": 6.948050022125244,
      "learning_rate": 1.268541368609903e-05,
      "loss": 0.8722,
      "step": 13615
    },
    {
      "epoch": 4.068,
      "grad_norm": 6.0085954666137695,
      "learning_rate": 1.2667430930795877e-05,
      "loss": 1.1765,
      "step": 13620
    },
    {
      "epoch": 4.06825,
      "grad_norm": 7.230889797210693,
      "learning_rate": 1.2649456604687405e-05,
      "loss": 1.0838,
      "step": 13625
    },
    {
      "epoch": 4.0685,
      "grad_norm": 6.8332929611206055,
      "learning_rate": 1.2631490720058875e-05,
      "loss": 1.0635,
      "step": 13630
    },
    {
      "epoch": 4.06875,
      "grad_norm": 5.549591064453125,
      "learning_rate": 1.261353328918981e-05,
      "loss": 0.9794,
      "step": 13635
    },
    {
      "epoch": 4.069,
      "grad_norm": 5.000978469848633,
      "learning_rate": 1.2595584324353943e-05,
      "loss": 0.9617,
      "step": 13640
    },
    {
      "epoch": 4.06925,
      "grad_norm": 7.825014114379883,
      "learning_rate": 1.2577643837819237e-05,
      "loss": 0.9803,
      "step": 13645
    },
    {
      "epoch": 4.0695,
      "grad_norm": 5.127893447875977,
      "learning_rate": 1.255971184184783e-05,
      "loss": 0.9737,
      "step": 13650
    },
    {
      "epoch": 4.06975,
      "grad_norm": 4.706044673919678,
      "learning_rate": 1.2541788348696066e-05,
      "loss": 1.0169,
      "step": 13655
    },
    {
      "epoch": 4.07,
      "grad_norm": 6.356651782989502,
      "learning_rate": 1.2523873370614489e-05,
      "loss": 1.0586,
      "step": 13660
    },
    {
      "epoch": 4.07025,
      "grad_norm": 5.677122116088867,
      "learning_rate": 1.2505966919847822e-05,
      "loss": 0.9299,
      "step": 13665
    },
    {
      "epoch": 4.0705,
      "grad_norm": 4.383760452270508,
      "learning_rate": 1.2488069008634954e-05,
      "loss": 1.0287,
      "step": 13670
    },
    {
      "epoch": 4.07075,
      "grad_norm": 5.457507610321045,
      "learning_rate": 1.2470179649208947e-05,
      "loss": 0.9402,
      "step": 13675
    },
    {
      "epoch": 4.071,
      "grad_norm": 6.016468524932861,
      "learning_rate": 1.245229885379699e-05,
      "loss": 0.8906,
      "step": 13680
    },
    {
      "epoch": 4.07125,
      "grad_norm": 4.787084579467773,
      "learning_rate": 1.2434426634620449e-05,
      "loss": 0.8879,
      "step": 13685
    },
    {
      "epoch": 4.0715,
      "grad_norm": 6.101531505584717,
      "learning_rate": 1.2416563003894826e-05,
      "loss": 0.9558,
      "step": 13690
    },
    {
      "epoch": 4.07175,
      "grad_norm": 6.466144561767578,
      "learning_rate": 1.2398707973829728e-05,
      "loss": 1.1961,
      "step": 13695
    },
    {
      "epoch": 4.072,
      "grad_norm": 5.7858381271362305,
      "learning_rate": 1.2380861556628915e-05,
      "loss": 1.0244,
      "step": 13700
    },
    {
      "epoch": 4.07225,
      "grad_norm": 5.496766567230225,
      "learning_rate": 1.2363023764490228e-05,
      "loss": 0.9326,
      "step": 13705
    },
    {
      "epoch": 4.0725,
      "grad_norm": 5.505505084991455,
      "learning_rate": 1.2345194609605636e-05,
      "loss": 0.826,
      "step": 13710
    },
    {
      "epoch": 4.07275,
      "grad_norm": 5.4426045417785645,
      "learning_rate": 1.2327374104161204e-05,
      "loss": 1.0093,
      "step": 13715
    },
    {
      "epoch": 4.073,
      "grad_norm": 5.276537895202637,
      "learning_rate": 1.2309562260337073e-05,
      "loss": 0.9445,
      "step": 13720
    },
    {
      "epoch": 4.07325,
      "grad_norm": 6.502768039703369,
      "learning_rate": 1.2291759090307486e-05,
      "loss": 0.8752,
      "step": 13725
    },
    {
      "epoch": 4.0735,
      "grad_norm": 5.306065082550049,
      "learning_rate": 1.2273964606240718e-05,
      "loss": 0.8316,
      "step": 13730
    },
    {
      "epoch": 4.07375,
      "grad_norm": 4.690301418304443,
      "learning_rate": 1.2256178820299142e-05,
      "loss": 1.0267,
      "step": 13735
    },
    {
      "epoch": 4.074,
      "grad_norm": 6.1227545738220215,
      "learning_rate": 1.2238401744639185e-05,
      "loss": 0.9047,
      "step": 13740
    },
    {
      "epoch": 4.07425,
      "grad_norm": 5.824435234069824,
      "learning_rate": 1.2220633391411294e-05,
      "loss": 0.9184,
      "step": 13745
    },
    {
      "epoch": 4.0745,
      "grad_norm": 7.224355220794678,
      "learning_rate": 1.2202873772759981e-05,
      "loss": 1.0255,
      "step": 13750
    },
    {
      "epoch": 4.07475,
      "grad_norm": 4.4223809242248535,
      "learning_rate": 1.218512290082377e-05,
      "loss": 0.8018,
      "step": 13755
    },
    {
      "epoch": 4.075,
      "grad_norm": 4.748204708099365,
      "learning_rate": 1.216738078773522e-05,
      "loss": 0.8064,
      "step": 13760
    },
    {
      "epoch": 4.07525,
      "grad_norm": 6.236766338348389,
      "learning_rate": 1.2149647445620893e-05,
      "loss": 0.9261,
      "step": 13765
    },
    {
      "epoch": 4.0755,
      "grad_norm": 5.813555717468262,
      "learning_rate": 1.2131922886601368e-05,
      "loss": 1.033,
      "step": 13770
    },
    {
      "epoch": 4.07575,
      "grad_norm": 5.892751216888428,
      "learning_rate": 1.2114207122791221e-05,
      "loss": 0.931,
      "step": 13775
    },
    {
      "epoch": 4.076,
      "grad_norm": 6.512506008148193,
      "learning_rate": 1.209650016629899e-05,
      "loss": 1.0532,
      "step": 13780
    },
    {
      "epoch": 4.07625,
      "grad_norm": 5.625589370727539,
      "learning_rate": 1.2078802029227232e-05,
      "loss": 0.9956,
      "step": 13785
    },
    {
      "epoch": 4.0765,
      "grad_norm": 5.556240558624268,
      "learning_rate": 1.2061112723672438e-05,
      "loss": 0.9301,
      "step": 13790
    },
    {
      "epoch": 4.07675,
      "grad_norm": 5.249459743499756,
      "learning_rate": 1.2043432261725091e-05,
      "loss": 0.925,
      "step": 13795
    },
    {
      "epoch": 4.077,
      "grad_norm": 5.3220319747924805,
      "learning_rate": 1.202576065546963e-05,
      "loss": 0.8619,
      "step": 13800
    },
    {
      "epoch": 4.07725,
      "grad_norm": 4.990891456604004,
      "learning_rate": 1.2008097916984409e-05,
      "loss": 0.8978,
      "step": 13805
    },
    {
      "epoch": 4.0775,
      "grad_norm": 6.774015426635742,
      "learning_rate": 1.1990444058341757e-05,
      "loss": 1.0109,
      "step": 13810
    },
    {
      "epoch": 4.07775,
      "grad_norm": 5.285280704498291,
      "learning_rate": 1.197279909160792e-05,
      "loss": 0.9098,
      "step": 13815
    },
    {
      "epoch": 4.078,
      "grad_norm": 5.647352695465088,
      "learning_rate": 1.1955163028843063e-05,
      "loss": 0.9998,
      "step": 13820
    },
    {
      "epoch": 4.07825,
      "grad_norm": 5.25407075881958,
      "learning_rate": 1.1937535882101281e-05,
      "loss": 0.9079,
      "step": 13825
    },
    {
      "epoch": 4.0785,
      "grad_norm": 6.228696346282959,
      "learning_rate": 1.1919917663430552e-05,
      "loss": 0.8375,
      "step": 13830
    },
    {
      "epoch": 4.07875,
      "grad_norm": 5.4308037757873535,
      "learning_rate": 1.1902308384872752e-05,
      "loss": 0.8816,
      "step": 13835
    },
    {
      "epoch": 4.079,
      "grad_norm": 7.839321613311768,
      "learning_rate": 1.1884708058463668e-05,
      "loss": 0.902,
      "step": 13840
    },
    {
      "epoch": 4.07925,
      "grad_norm": 6.0014142990112305,
      "learning_rate": 1.1867116696232952e-05,
      "loss": 0.9989,
      "step": 13845
    },
    {
      "epoch": 4.0795,
      "grad_norm": 5.522064208984375,
      "learning_rate": 1.1849534310204152e-05,
      "loss": 0.8488,
      "step": 13850
    },
    {
      "epoch": 4.07975,
      "grad_norm": 7.556840419769287,
      "learning_rate": 1.1831960912394641e-05,
      "loss": 0.937,
      "step": 13855
    },
    {
      "epoch": 4.08,
      "grad_norm": 4.488609313964844,
      "learning_rate": 1.1814396514815676e-05,
      "loss": 0.9332,
      "step": 13860
    },
    {
      "epoch": 4.08025,
      "grad_norm": 5.964384078979492,
      "learning_rate": 1.1796841129472361e-05,
      "loss": 1.014,
      "step": 13865
    },
    {
      "epoch": 4.0805,
      "grad_norm": 6.34658145904541,
      "learning_rate": 1.1779294768363639e-05,
      "loss": 1.0214,
      "step": 13870
    },
    {
      "epoch": 4.08075,
      "grad_norm": 7.143658638000488,
      "learning_rate": 1.1761757443482286e-05,
      "loss": 0.9905,
      "step": 13875
    },
    {
      "epoch": 4.081,
      "grad_norm": 5.003788948059082,
      "learning_rate": 1.1744229166814888e-05,
      "loss": 0.9788,
      "step": 13880
    },
    {
      "epoch": 4.08125,
      "grad_norm": 5.11972188949585,
      "learning_rate": 1.1726709950341855e-05,
      "loss": 0.9979,
      "step": 13885
    },
    {
      "epoch": 4.0815,
      "grad_norm": 4.713445663452148,
      "learning_rate": 1.170919980603741e-05,
      "loss": 0.961,
      "step": 13890
    },
    {
      "epoch": 4.08175,
      "grad_norm": 4.7365803718566895,
      "learning_rate": 1.1691698745869573e-05,
      "loss": 0.9734,
      "step": 13895
    },
    {
      "epoch": 4.082,
      "grad_norm": 5.3523125648498535,
      "learning_rate": 1.1674206781800162e-05,
      "loss": 1.034,
      "step": 13900
    },
    {
      "epoch": 4.08225,
      "grad_norm": 5.599070072174072,
      "learning_rate": 1.1656723925784752e-05,
      "loss": 0.9321,
      "step": 13905
    },
    {
      "epoch": 4.0825,
      "grad_norm": 5.672257423400879,
      "learning_rate": 1.1639250189772718e-05,
      "loss": 1.0043,
      "step": 13910
    },
    {
      "epoch": 4.08275,
      "grad_norm": 5.0971808433532715,
      "learning_rate": 1.1621785585707198e-05,
      "loss": 0.9556,
      "step": 13915
    },
    {
      "epoch": 4.083,
      "grad_norm": 4.9763875007629395,
      "learning_rate": 1.1604330125525079e-05,
      "loss": 0.9029,
      "step": 13920
    },
    {
      "epoch": 4.08325,
      "grad_norm": 6.141885280609131,
      "learning_rate": 1.1586883821157015e-05,
      "loss": 0.8703,
      "step": 13925
    },
    {
      "epoch": 4.0835,
      "grad_norm": 7.15509033203125,
      "learning_rate": 1.1569446684527383e-05,
      "loss": 1.054,
      "step": 13930
    },
    {
      "epoch": 4.08375,
      "grad_norm": 4.917302131652832,
      "learning_rate": 1.1552018727554286e-05,
      "loss": 0.8406,
      "step": 13935
    },
    {
      "epoch": 4.084,
      "grad_norm": 6.844506740570068,
      "learning_rate": 1.1534599962149587e-05,
      "loss": 0.7825,
      "step": 13940
    },
    {
      "epoch": 4.08425,
      "grad_norm": 4.181159496307373,
      "learning_rate": 1.1517190400218839e-05,
      "loss": 0.7297,
      "step": 13945
    },
    {
      "epoch": 4.0845,
      "grad_norm": 7.157927513122559,
      "learning_rate": 1.1499790053661327e-05,
      "loss": 0.9425,
      "step": 13950
    },
    {
      "epoch": 4.08475,
      "grad_norm": 4.385712146759033,
      "learning_rate": 1.1482398934370006e-05,
      "loss": 0.7522,
      "step": 13955
    },
    {
      "epoch": 4.085,
      "grad_norm": 5.774771213531494,
      "learning_rate": 1.146501705423155e-05,
      "loss": 0.8029,
      "step": 13960
    },
    {
      "epoch": 4.08525,
      "grad_norm": 4.993917465209961,
      "learning_rate": 1.1447644425126311e-05,
      "loss": 0.7981,
      "step": 13965
    },
    {
      "epoch": 4.0855,
      "grad_norm": 4.49207067489624,
      "learning_rate": 1.1430281058928324e-05,
      "loss": 0.7089,
      "step": 13970
    },
    {
      "epoch": 4.08575,
      "grad_norm": 5.473412990570068,
      "learning_rate": 1.141292696750527e-05,
      "loss": 0.8603,
      "step": 13975
    },
    {
      "epoch": 4.086,
      "grad_norm": 5.9278645515441895,
      "learning_rate": 1.1395582162718525e-05,
      "loss": 0.8952,
      "step": 13980
    },
    {
      "epoch": 4.08625,
      "grad_norm": 5.604520797729492,
      "learning_rate": 1.1378246656423078e-05,
      "loss": 0.7508,
      "step": 13985
    },
    {
      "epoch": 4.0865,
      "grad_norm": 4.832670211791992,
      "learning_rate": 1.1360920460467598e-05,
      "loss": 0.7953,
      "step": 13990
    },
    {
      "epoch": 4.08675,
      "grad_norm": 5.017831802368164,
      "learning_rate": 1.1343603586694372e-05,
      "loss": 0.808,
      "step": 13995
    },
    {
      "epoch": 4.087,
      "grad_norm": 5.701859951019287,
      "learning_rate": 1.1326296046939333e-05,
      "loss": 0.8901,
      "step": 14000
    },
    {
      "epoch": 4.087,
      "eval_loss": 2.0939228534698486,
      "eval_runtime": 5.183,
      "eval_samples_per_second": 197.568,
      "eval_steps_per_second": 24.696,
      "step": 14000
    },
    {
      "epoch": 4.08725,
      "grad_norm": 5.79272985458374,
      "learning_rate": 1.1308997853032002e-05,
      "loss": 0.8293,
      "step": 14005
    },
    {
      "epoch": 4.0875,
      "grad_norm": 5.922412872314453,
      "learning_rate": 1.129170901679554e-05,
      "loss": 0.8209,
      "step": 14010
    },
    {
      "epoch": 4.08775,
      "grad_norm": 5.046881198883057,
      "learning_rate": 1.1274429550046704e-05,
      "loss": 0.7576,
      "step": 14015
    },
    {
      "epoch": 4.088,
      "grad_norm": 6.544200897216797,
      "learning_rate": 1.1257159464595855e-05,
      "loss": 0.8176,
      "step": 14020
    },
    {
      "epoch": 4.08825,
      "grad_norm": 5.519782066345215,
      "learning_rate": 1.1239898772246914e-05,
      "loss": 0.7877,
      "step": 14025
    },
    {
      "epoch": 4.0885,
      "grad_norm": 6.087804317474365,
      "learning_rate": 1.1222647484797422e-05,
      "loss": 0.7543,
      "step": 14030
    },
    {
      "epoch": 4.08875,
      "grad_norm": 5.390783309936523,
      "learning_rate": 1.1205405614038452e-05,
      "loss": 0.8936,
      "step": 14035
    },
    {
      "epoch": 4.089,
      "grad_norm": 6.461953163146973,
      "learning_rate": 1.118817317175467e-05,
      "loss": 0.8598,
      "step": 14040
    },
    {
      "epoch": 4.08925,
      "grad_norm": 5.656116485595703,
      "learning_rate": 1.117095016972429e-05,
      "loss": 0.7816,
      "step": 14045
    },
    {
      "epoch": 4.0895,
      "grad_norm": 6.947457313537598,
      "learning_rate": 1.1153736619719077e-05,
      "loss": 0.8122,
      "step": 14050
    },
    {
      "epoch": 4.08975,
      "grad_norm": 5.3526129722595215,
      "learning_rate": 1.113653253350431e-05,
      "loss": 0.7375,
      "step": 14055
    },
    {
      "epoch": 4.09,
      "grad_norm": 7.073073387145996,
      "learning_rate": 1.1119337922838832e-05,
      "loss": 0.8752,
      "step": 14060
    },
    {
      "epoch": 4.09025,
      "grad_norm": 6.133310317993164,
      "learning_rate": 1.1102152799475007e-05,
      "loss": 0.8117,
      "step": 14065
    },
    {
      "epoch": 4.0905,
      "grad_norm": 5.941376686096191,
      "learning_rate": 1.1084977175158687e-05,
      "loss": 0.7219,
      "step": 14070
    },
    {
      "epoch": 4.09075,
      "grad_norm": 6.41966438293457,
      "learning_rate": 1.1067811061629258e-05,
      "loss": 0.6847,
      "step": 14075
    },
    {
      "epoch": 4.091,
      "grad_norm": 5.416550159454346,
      "learning_rate": 1.1050654470619601e-05,
      "loss": 0.7786,
      "step": 14080
    },
    {
      "epoch": 4.09125,
      "grad_norm": 5.86535120010376,
      "learning_rate": 1.103350741385607e-05,
      "loss": 0.8206,
      "step": 14085
    },
    {
      "epoch": 4.0915,
      "grad_norm": 6.862855434417725,
      "learning_rate": 1.1016369903058529e-05,
      "loss": 0.932,
      "step": 14090
    },
    {
      "epoch": 4.09175,
      "grad_norm": 4.657026767730713,
      "learning_rate": 1.0999241949940298e-05,
      "loss": 0.9983,
      "step": 14095
    },
    {
      "epoch": 4.092,
      "grad_norm": 5.187218189239502,
      "learning_rate": 1.0982123566208185e-05,
      "loss": 0.7766,
      "step": 14100
    },
    {
      "epoch": 4.09225,
      "grad_norm": 5.867739677429199,
      "learning_rate": 1.0965014763562425e-05,
      "loss": 0.9201,
      "step": 14105
    },
    {
      "epoch": 4.0925,
      "grad_norm": 5.992277145385742,
      "learning_rate": 1.0947915553696742e-05,
      "loss": 0.8412,
      "step": 14110
    },
    {
      "epoch": 4.09275,
      "grad_norm": 4.634513854980469,
      "learning_rate": 1.0930825948298266e-05,
      "loss": 0.9138,
      "step": 14115
    },
    {
      "epoch": 4.093,
      "grad_norm": 5.549009323120117,
      "learning_rate": 1.091374595904759e-05,
      "loss": 0.8315,
      "step": 14120
    },
    {
      "epoch": 4.09325,
      "grad_norm": 4.981576442718506,
      "learning_rate": 1.0896675597618724e-05,
      "loss": 0.886,
      "step": 14125
    },
    {
      "epoch": 4.0935,
      "grad_norm": 5.6010637283325195,
      "learning_rate": 1.0879614875679109e-05,
      "loss": 0.8896,
      "step": 14130
    },
    {
      "epoch": 4.09375,
      "grad_norm": 6.623700141906738,
      "learning_rate": 1.0862563804889572e-05,
      "loss": 1.0825,
      "step": 14135
    },
    {
      "epoch": 4.094,
      "grad_norm": 4.865601539611816,
      "learning_rate": 1.0845522396904367e-05,
      "loss": 0.8221,
      "step": 14140
    },
    {
      "epoch": 4.09425,
      "grad_norm": 5.939794540405273,
      "learning_rate": 1.0828490663371133e-05,
      "loss": 0.7823,
      "step": 14145
    },
    {
      "epoch": 4.0945,
      "grad_norm": 4.158422946929932,
      "learning_rate": 1.0811468615930911e-05,
      "loss": 0.7744,
      "step": 14150
    },
    {
      "epoch": 4.09475,
      "grad_norm": 6.053847789764404,
      "learning_rate": 1.0794456266218092e-05,
      "loss": 0.8847,
      "step": 14155
    },
    {
      "epoch": 4.095,
      "grad_norm": 6.2799811363220215,
      "learning_rate": 1.0777453625860472e-05,
      "loss": 0.8999,
      "step": 14160
    },
    {
      "epoch": 4.09525,
      "grad_norm": 5.262393474578857,
      "learning_rate": 1.076046070647918e-05,
      "loss": 0.8555,
      "step": 14165
    },
    {
      "epoch": 4.0955,
      "grad_norm": 6.323975563049316,
      "learning_rate": 1.0743477519688725e-05,
      "loss": 0.9323,
      "step": 14170
    },
    {
      "epoch": 4.09575,
      "grad_norm": 7.363605976104736,
      "learning_rate": 1.0726504077096951e-05,
      "loss": 0.9991,
      "step": 14175
    },
    {
      "epoch": 4.096,
      "grad_norm": 6.478339672088623,
      "learning_rate": 1.0709540390305061e-05,
      "loss": 1.0085,
      "step": 14180
    },
    {
      "epoch": 4.09625,
      "grad_norm": 6.3009161949157715,
      "learning_rate": 1.0692586470907557e-05,
      "loss": 0.9318,
      "step": 14185
    },
    {
      "epoch": 4.0965,
      "grad_norm": 5.594024658203125,
      "learning_rate": 1.0675642330492286e-05,
      "loss": 0.932,
      "step": 14190
    },
    {
      "epoch": 4.09675,
      "grad_norm": 6.3318986892700195,
      "learning_rate": 1.0658707980640412e-05,
      "loss": 0.9567,
      "step": 14195
    },
    {
      "epoch": 4.097,
      "grad_norm": 6.396617412567139,
      "learning_rate": 1.064178343292641e-05,
      "loss": 0.856,
      "step": 14200
    },
    {
      "epoch": 4.09725,
      "grad_norm": 5.053077697753906,
      "learning_rate": 1.0624868698918045e-05,
      "loss": 0.8399,
      "step": 14205
    },
    {
      "epoch": 4.0975,
      "grad_norm": 10.056360244750977,
      "learning_rate": 1.0607963790176365e-05,
      "loss": 0.9461,
      "step": 14210
    },
    {
      "epoch": 4.09775,
      "grad_norm": 6.956519603729248,
      "learning_rate": 1.0591068718255726e-05,
      "loss": 0.8896,
      "step": 14215
    },
    {
      "epoch": 4.098,
      "grad_norm": 6.739506721496582,
      "learning_rate": 1.0574183494703748e-05,
      "loss": 0.9636,
      "step": 14220
    },
    {
      "epoch": 4.09825,
      "grad_norm": 5.45304536819458,
      "learning_rate": 1.0557308131061325e-05,
      "loss": 0.8234,
      "step": 14225
    },
    {
      "epoch": 4.0985,
      "grad_norm": 6.330156326293945,
      "learning_rate": 1.0540442638862618e-05,
      "loss": 0.9739,
      "step": 14230
    },
    {
      "epoch": 4.09875,
      "grad_norm": 5.87249231338501,
      "learning_rate": 1.0523587029635013e-05,
      "loss": 0.9536,
      "step": 14235
    },
    {
      "epoch": 4.099,
      "grad_norm": 5.582116603851318,
      "learning_rate": 1.0506741314899166e-05,
      "loss": 0.8732,
      "step": 14240
    },
    {
      "epoch": 4.09925,
      "grad_norm": 7.029479026794434,
      "learning_rate": 1.048990550616897e-05,
      "loss": 0.9934,
      "step": 14245
    },
    {
      "epoch": 4.0995,
      "grad_norm": 4.7276129722595215,
      "learning_rate": 1.0473079614951545e-05,
      "loss": 0.9048,
      "step": 14250
    },
    {
      "epoch": 4.09975,
      "grad_norm": 5.5251970291137695,
      "learning_rate": 1.0456263652747225e-05,
      "loss": 0.802,
      "step": 14255
    },
    {
      "epoch": 4.1,
      "grad_norm": 5.774560451507568,
      "learning_rate": 1.0439457631049549e-05,
      "loss": 0.9985,
      "step": 14260
    },
    {
      "epoch": 4.10025,
      "grad_norm": 7.037224769592285,
      "learning_rate": 1.0422661561345284e-05,
      "loss": 1.0106,
      "step": 14265
    },
    {
      "epoch": 4.1005,
      "grad_norm": 5.759589672088623,
      "learning_rate": 1.0405875455114387e-05,
      "loss": 0.8034,
      "step": 14270
    },
    {
      "epoch": 4.10075,
      "grad_norm": 5.522477149963379,
      "learning_rate": 1.038909932383e-05,
      "loss": 0.8307,
      "step": 14275
    },
    {
      "epoch": 4.101,
      "grad_norm": 7.5364484786987305,
      "learning_rate": 1.0372333178958462e-05,
      "loss": 0.8897,
      "step": 14280
    },
    {
      "epoch": 4.10125,
      "grad_norm": 6.733371734619141,
      "learning_rate": 1.035557703195926e-05,
      "loss": 1.1044,
      "step": 14285
    },
    {
      "epoch": 4.1015,
      "grad_norm": 4.783966064453125,
      "learning_rate": 1.0338830894285065e-05,
      "loss": 0.8304,
      "step": 14290
    },
    {
      "epoch": 4.10175,
      "grad_norm": 4.619966983795166,
      "learning_rate": 1.0322094777381708e-05,
      "loss": 0.8109,
      "step": 14295
    },
    {
      "epoch": 4.102,
      "grad_norm": 6.118961811065674,
      "learning_rate": 1.0305368692688174e-05,
      "loss": 0.7977,
      "step": 14300
    },
    {
      "epoch": 4.10225,
      "grad_norm": 5.214703559875488,
      "learning_rate": 1.0288652651636577e-05,
      "loss": 0.8689,
      "step": 14305
    },
    {
      "epoch": 4.1025,
      "grad_norm": 4.63058614730835,
      "learning_rate": 1.0271946665652166e-05,
      "loss": 0.8005,
      "step": 14310
    },
    {
      "epoch": 4.10275,
      "grad_norm": 5.835160732269287,
      "learning_rate": 1.0255250746153327e-05,
      "loss": 0.7879,
      "step": 14315
    },
    {
      "epoch": 4.103,
      "grad_norm": 5.900935173034668,
      "learning_rate": 1.0238564904551574e-05,
      "loss": 0.9395,
      "step": 14320
    },
    {
      "epoch": 4.10325,
      "grad_norm": 5.109023571014404,
      "learning_rate": 1.0221889152251512e-05,
      "loss": 0.7009,
      "step": 14325
    },
    {
      "epoch": 4.1035,
      "grad_norm": 5.95403528213501,
      "learning_rate": 1.0205223500650876e-05,
      "loss": 0.8887,
      "step": 14330
    },
    {
      "epoch": 4.10375,
      "grad_norm": 4.526758193969727,
      "learning_rate": 1.0188567961140463e-05,
      "loss": 0.6863,
      "step": 14335
    },
    {
      "epoch": 4.104,
      "grad_norm": 4.917234420776367,
      "learning_rate": 1.0171922545104184e-05,
      "loss": 0.9313,
      "step": 14340
    },
    {
      "epoch": 4.10425,
      "grad_norm": 6.09798526763916,
      "learning_rate": 1.0155287263919036e-05,
      "loss": 0.9085,
      "step": 14345
    },
    {
      "epoch": 4.1045,
      "grad_norm": 5.404283046722412,
      "learning_rate": 1.0138662128955053e-05,
      "loss": 0.8304,
      "step": 14350
    },
    {
      "epoch": 4.10475,
      "grad_norm": 5.997710704803467,
      "learning_rate": 1.0122047151575385e-05,
      "loss": 0.7666,
      "step": 14355
    },
    {
      "epoch": 4.105,
      "grad_norm": 6.227378845214844,
      "learning_rate": 1.0105442343136184e-05,
      "loss": 0.8912,
      "step": 14360
    },
    {
      "epoch": 4.10525,
      "grad_norm": 7.12595796585083,
      "learning_rate": 1.0088847714986697e-05,
      "loss": 0.8004,
      "step": 14365
    },
    {
      "epoch": 4.1055,
      "grad_norm": 6.454041004180908,
      "learning_rate": 1.0072263278469194e-05,
      "loss": 0.7829,
      "step": 14370
    },
    {
      "epoch": 4.10575,
      "grad_norm": 7.161375999450684,
      "learning_rate": 1.0055689044918978e-05,
      "loss": 0.8115,
      "step": 14375
    },
    {
      "epoch": 4.106,
      "grad_norm": 6.12315034866333,
      "learning_rate": 1.0039125025664392e-05,
      "loss": 0.7665,
      "step": 14380
    },
    {
      "epoch": 4.10625,
      "grad_norm": 4.660430431365967,
      "learning_rate": 1.002257123202677e-05,
      "loss": 0.774,
      "step": 14385
    },
    {
      "epoch": 4.1065,
      "grad_norm": 7.423002243041992,
      "learning_rate": 1.0006027675320493e-05,
      "loss": 0.8372,
      "step": 14390
    },
    {
      "epoch": 4.10675,
      "grad_norm": 5.851858615875244,
      "learning_rate": 9.989494366852904e-06,
      "loss": 0.8376,
      "step": 14395
    },
    {
      "epoch": 4.107,
      "grad_norm": 7.173540115356445,
      "learning_rate": 9.972971317924374e-06,
      "loss": 0.9428,
      "step": 14400
    },
    {
      "epoch": 4.10725,
      "grad_norm": 5.965964317321777,
      "learning_rate": 9.956458539828262e-06,
      "loss": 0.7001,
      "step": 14405
    },
    {
      "epoch": 4.1075,
      "grad_norm": 5.154936790466309,
      "learning_rate": 9.939956043850876e-06,
      "loss": 0.8576,
      "step": 14410
    },
    {
      "epoch": 4.10775,
      "grad_norm": 6.278627872467041,
      "learning_rate": 9.923463841271527e-06,
      "loss": 0.8179,
      "step": 14415
    },
    {
      "epoch": 4.108,
      "grad_norm": 6.007789611816406,
      "learning_rate": 9.90698194336248e-06,
      "loss": 0.7822,
      "step": 14420
    },
    {
      "epoch": 4.10825,
      "grad_norm": 5.557916164398193,
      "learning_rate": 9.890510361388955e-06,
      "loss": 0.7943,
      "step": 14425
    },
    {
      "epoch": 4.1085,
      "grad_norm": 5.330063343048096,
      "learning_rate": 9.874049106609135e-06,
      "loss": 0.7609,
      "step": 14430
    },
    {
      "epoch": 4.10875,
      "grad_norm": 6.012128829956055,
      "learning_rate": 9.857598190274112e-06,
      "loss": 0.7602,
      "step": 14435
    },
    {
      "epoch": 4.109,
      "grad_norm": 4.730967044830322,
      "learning_rate": 9.841157623627947e-06,
      "loss": 0.8384,
      "step": 14440
    },
    {
      "epoch": 4.10925,
      "grad_norm": 5.7155537605285645,
      "learning_rate": 9.824727417907601e-06,
      "loss": 0.832,
      "step": 14445
    },
    {
      "epoch": 4.1095,
      "grad_norm": 6.077123165130615,
      "learning_rate": 9.808307584342971e-06,
      "loss": 0.7168,
      "step": 14450
    },
    {
      "epoch": 4.10975,
      "grad_norm": 4.248856067657471,
      "learning_rate": 9.791898134156866e-06,
      "loss": 0.726,
      "step": 14455
    },
    {
      "epoch": 4.11,
      "grad_norm": 5.247378826141357,
      "learning_rate": 9.775499078564973e-06,
      "loss": 0.8255,
      "step": 14460
    },
    {
      "epoch": 4.11025,
      "grad_norm": 6.235306739807129,
      "learning_rate": 9.759110428775903e-06,
      "loss": 0.7856,
      "step": 14465
    },
    {
      "epoch": 4.1105,
      "grad_norm": 5.721497535705566,
      "learning_rate": 9.742732195991142e-06,
      "loss": 0.8176,
      "step": 14470
    },
    {
      "epoch": 4.11075,
      "grad_norm": 6.521437168121338,
      "learning_rate": 9.726364391405055e-06,
      "loss": 1.0658,
      "step": 14475
    },
    {
      "epoch": 4.111,
      "grad_norm": 5.519550323486328,
      "learning_rate": 9.710007026204895e-06,
      "loss": 0.8753,
      "step": 14480
    },
    {
      "epoch": 4.11125,
      "grad_norm": 7.381644248962402,
      "learning_rate": 9.693660111570757e-06,
      "loss": 1.0443,
      "step": 14485
    },
    {
      "epoch": 4.1115,
      "grad_norm": 6.499785423278809,
      "learning_rate": 9.677323658675594e-06,
      "loss": 0.9433,
      "step": 14490
    },
    {
      "epoch": 4.11175,
      "grad_norm": 5.752200603485107,
      "learning_rate": 9.660997678685225e-06,
      "loss": 0.9143,
      "step": 14495
    },
    {
      "epoch": 4.112,
      "grad_norm": 6.213829040527344,
      "learning_rate": 9.644682182758306e-06,
      "loss": 1.0168,
      "step": 14500
    },
    {
      "epoch": 4.112,
      "eval_loss": 2.1153810024261475,
      "eval_runtime": 5.7076,
      "eval_samples_per_second": 179.41,
      "eval_steps_per_second": 22.426,
      "step": 14500
    },
    {
      "epoch": 4.11225,
      "grad_norm": 5.638340473175049,
      "learning_rate": 9.62837718204633e-06,
      "loss": 0.8716,
      "step": 14505
    },
    {
      "epoch": 4.1125,
      "grad_norm": 4.947880744934082,
      "learning_rate": 9.612082687693597e-06,
      "loss": 1.1717,
      "step": 14510
    },
    {
      "epoch": 4.11275,
      "grad_norm": 5.078384876251221,
      "learning_rate": 9.595798710837244e-06,
      "loss": 0.8836,
      "step": 14515
    },
    {
      "epoch": 4.113,
      "grad_norm": 5.755218982696533,
      "learning_rate": 9.579525262607226e-06,
      "loss": 0.9194,
      "step": 14520
    },
    {
      "epoch": 4.11325,
      "grad_norm": 5.279336452484131,
      "learning_rate": 9.563262354126279e-06,
      "loss": 0.9605,
      "step": 14525
    },
    {
      "epoch": 4.1135,
      "grad_norm": 5.307955265045166,
      "learning_rate": 9.547009996509964e-06,
      "loss": 0.8818,
      "step": 14530
    },
    {
      "epoch": 4.11375,
      "grad_norm": 5.672896385192871,
      "learning_rate": 9.530768200866602e-06,
      "loss": 0.8646,
      "step": 14535
    },
    {
      "epoch": 4.114,
      "grad_norm": 5.039542198181152,
      "learning_rate": 9.514536978297303e-06,
      "loss": 0.8777,
      "step": 14540
    },
    {
      "epoch": 4.11425,
      "grad_norm": 7.156979560852051,
      "learning_rate": 9.498316339895957e-06,
      "loss": 0.8801,
      "step": 14545
    },
    {
      "epoch": 4.1145,
      "grad_norm": 5.5172505378723145,
      "learning_rate": 9.482106296749221e-06,
      "loss": 1.0489,
      "step": 14550
    },
    {
      "epoch": 4.11475,
      "grad_norm": 6.000596523284912,
      "learning_rate": 9.465906859936515e-06,
      "loss": 0.8463,
      "step": 14555
    },
    {
      "epoch": 4.115,
      "grad_norm": 7.61710262298584,
      "learning_rate": 9.449718040529987e-06,
      "loss": 1.0476,
      "step": 14560
    },
    {
      "epoch": 4.11525,
      "grad_norm": 7.852176666259766,
      "learning_rate": 9.433539849594545e-06,
      "loss": 1.0157,
      "step": 14565
    },
    {
      "epoch": 4.1155,
      "grad_norm": 5.296976566314697,
      "learning_rate": 9.417372298187833e-06,
      "loss": 0.6593,
      "step": 14570
    },
    {
      "epoch": 4.11575,
      "grad_norm": 5.711462020874023,
      "learning_rate": 9.401215397360227e-06,
      "loss": 0.8108,
      "step": 14575
    },
    {
      "epoch": 4.116,
      "grad_norm": 5.418928623199463,
      "learning_rate": 9.385069158154805e-06,
      "loss": 0.9396,
      "step": 14580
    },
    {
      "epoch": 4.11625,
      "grad_norm": 6.169346332550049,
      "learning_rate": 9.368933591607378e-06,
      "loss": 0.8641,
      "step": 14585
    },
    {
      "epoch": 4.1165,
      "grad_norm": 6.172682762145996,
      "learning_rate": 9.352808708746441e-06,
      "loss": 0.8367,
      "step": 14590
    },
    {
      "epoch": 4.11675,
      "grad_norm": 5.622371673583984,
      "learning_rate": 9.336694520593209e-06,
      "loss": 0.8556,
      "step": 14595
    },
    {
      "epoch": 4.117,
      "grad_norm": 4.926814079284668,
      "learning_rate": 9.320591038161574e-06,
      "loss": 0.8849,
      "step": 14600
    },
    {
      "epoch": 4.11725,
      "grad_norm": 4.997981071472168,
      "learning_rate": 9.304498272458126e-06,
      "loss": 0.9086,
      "step": 14605
    },
    {
      "epoch": 4.1175,
      "grad_norm": 4.753137588500977,
      "learning_rate": 9.2884162344821e-06,
      "loss": 0.7916,
      "step": 14610
    },
    {
      "epoch": 4.11775,
      "grad_norm": 5.668878078460693,
      "learning_rate": 9.272344935225428e-06,
      "loss": 0.7824,
      "step": 14615
    },
    {
      "epoch": 4.118,
      "grad_norm": 6.168028354644775,
      "learning_rate": 9.25628438567269e-06,
      "loss": 0.8163,
      "step": 14620
    },
    {
      "epoch": 4.11825,
      "grad_norm": 5.75789213180542,
      "learning_rate": 9.240234596801125e-06,
      "loss": 0.8232,
      "step": 14625
    },
    {
      "epoch": 4.1185,
      "grad_norm": 4.559450626373291,
      "learning_rate": 9.224195579580602e-06,
      "loss": 0.6961,
      "step": 14630
    },
    {
      "epoch": 4.11875,
      "grad_norm": 6.207444190979004,
      "learning_rate": 9.20816734497365e-06,
      "loss": 0.8716,
      "step": 14635
    },
    {
      "epoch": 4.119,
      "grad_norm": 6.208420276641846,
      "learning_rate": 9.192149903935405e-06,
      "loss": 0.9164,
      "step": 14640
    },
    {
      "epoch": 4.11925,
      "grad_norm": 5.98881721496582,
      "learning_rate": 9.176143267413637e-06,
      "loss": 0.8561,
      "step": 14645
    },
    {
      "epoch": 4.1195,
      "grad_norm": 7.8245849609375,
      "learning_rate": 9.160147446348739e-06,
      "loss": 0.7877,
      "step": 14650
    },
    {
      "epoch": 4.11975,
      "grad_norm": 6.016700744628906,
      "learning_rate": 9.144162451673696e-06,
      "loss": 0.9029,
      "step": 14655
    },
    {
      "epoch": 4.12,
      "grad_norm": 5.21195125579834,
      "learning_rate": 9.128188294314119e-06,
      "loss": 0.8509,
      "step": 14660
    },
    {
      "epoch": 4.12025,
      "grad_norm": 5.830117225646973,
      "learning_rate": 9.11222498518817e-06,
      "loss": 0.7237,
      "step": 14665
    },
    {
      "epoch": 4.1205,
      "grad_norm": 5.632650375366211,
      "learning_rate": 9.096272535206641e-06,
      "loss": 0.8238,
      "step": 14670
    },
    {
      "epoch": 4.12075,
      "grad_norm": 7.72551155090332,
      "learning_rate": 9.080330955272859e-06,
      "loss": 0.9477,
      "step": 14675
    },
    {
      "epoch": 4.121,
      "grad_norm": 5.845317840576172,
      "learning_rate": 9.064400256282757e-06,
      "loss": 0.9217,
      "step": 14680
    },
    {
      "epoch": 4.12125,
      "grad_norm": 4.584767818450928,
      "learning_rate": 9.048480449124828e-06,
      "loss": 0.7581,
      "step": 14685
    },
    {
      "epoch": 4.1215,
      "grad_norm": 5.8022565841674805,
      "learning_rate": 9.032571544680086e-06,
      "loss": 0.9492,
      "step": 14690
    },
    {
      "epoch": 4.12175,
      "grad_norm": 5.921364784240723,
      "learning_rate": 9.01667355382213e-06,
      "loss": 0.8003,
      "step": 14695
    },
    {
      "epoch": 4.122,
      "grad_norm": 5.681756019592285,
      "learning_rate": 9.000786487417085e-06,
      "loss": 0.8954,
      "step": 14700
    },
    {
      "epoch": 4.12225,
      "grad_norm": 5.570556163787842,
      "learning_rate": 8.984910356323615e-06,
      "loss": 0.8379,
      "step": 14705
    },
    {
      "epoch": 4.1225,
      "grad_norm": 6.0085906982421875,
      "learning_rate": 8.969045171392909e-06,
      "loss": 0.8422,
      "step": 14710
    },
    {
      "epoch": 4.12275,
      "grad_norm": 6.1407856941223145,
      "learning_rate": 8.953190943468667e-06,
      "loss": 0.8564,
      "step": 14715
    },
    {
      "epoch": 4.123,
      "grad_norm": 5.44389009475708,
      "learning_rate": 8.937347683387095e-06,
      "loss": 0.7739,
      "step": 14720
    },
    {
      "epoch": 4.12325,
      "grad_norm": 5.974629878997803,
      "learning_rate": 8.921515401976917e-06,
      "loss": 0.7722,
      "step": 14725
    },
    {
      "epoch": 4.1235,
      "grad_norm": 4.851820945739746,
      "learning_rate": 8.905694110059353e-06,
      "loss": 0.8486,
      "step": 14730
    },
    {
      "epoch": 4.12375,
      "grad_norm": 4.871086120605469,
      "learning_rate": 8.889883818448114e-06,
      "loss": 0.8106,
      "step": 14735
    },
    {
      "epoch": 4.124,
      "grad_norm": 5.69083833694458,
      "learning_rate": 8.874084537949364e-06,
      "loss": 0.794,
      "step": 14740
    },
    {
      "epoch": 4.12425,
      "grad_norm": 6.106940746307373,
      "learning_rate": 8.858296279361778e-06,
      "loss": 0.7987,
      "step": 14745
    },
    {
      "epoch": 4.1245,
      "grad_norm": 5.191129684448242,
      "learning_rate": 8.842519053476476e-06,
      "loss": 0.8542,
      "step": 14750
    },
    {
      "epoch": 4.12475,
      "grad_norm": 5.966866493225098,
      "learning_rate": 8.826752871077045e-06,
      "loss": 0.721,
      "step": 14755
    },
    {
      "epoch": 4.125,
      "grad_norm": 7.932538032531738,
      "learning_rate": 8.810997742939531e-06,
      "loss": 0.9124,
      "step": 14760
    },
    {
      "epoch": 4.12525,
      "grad_norm": 4.9023637771606445,
      "learning_rate": 8.795253679832404e-06,
      "loss": 0.8501,
      "step": 14765
    },
    {
      "epoch": 4.1255,
      "grad_norm": 5.021687984466553,
      "learning_rate": 8.77952069251658e-06,
      "loss": 0.891,
      "step": 14770
    },
    {
      "epoch": 4.12575,
      "grad_norm": 6.257584095001221,
      "learning_rate": 8.763798791745411e-06,
      "loss": 0.7643,
      "step": 14775
    },
    {
      "epoch": 4.126,
      "grad_norm": 5.746357440948486,
      "learning_rate": 8.74808798826467e-06,
      "loss": 0.7948,
      "step": 14780
    },
    {
      "epoch": 4.12625,
      "grad_norm": 4.683396816253662,
      "learning_rate": 8.732388292812551e-06,
      "loss": 0.7706,
      "step": 14785
    },
    {
      "epoch": 4.1265,
      "grad_norm": 8.838385581970215,
      "learning_rate": 8.71669971611963e-06,
      "loss": 0.8156,
      "step": 14790
    },
    {
      "epoch": 4.12675,
      "grad_norm": 5.915226936340332,
      "learning_rate": 8.701022268908912e-06,
      "loss": 0.8225,
      "step": 14795
    },
    {
      "epoch": 4.127,
      "grad_norm": 4.889564514160156,
      "learning_rate": 8.685355961895784e-06,
      "loss": 0.7745,
      "step": 14800
    },
    {
      "epoch": 4.12725,
      "grad_norm": 6.756880283355713,
      "learning_rate": 8.669700805788017e-06,
      "loss": 0.7108,
      "step": 14805
    },
    {
      "epoch": 4.1275,
      "grad_norm": 5.139016628265381,
      "learning_rate": 8.654056811285772e-06,
      "loss": 0.7219,
      "step": 14810
    },
    {
      "epoch": 4.12775,
      "grad_norm": 5.539785861968994,
      "learning_rate": 8.638423989081561e-06,
      "loss": 0.8433,
      "step": 14815
    },
    {
      "epoch": 4.128,
      "grad_norm": 5.665217399597168,
      "learning_rate": 8.622802349860268e-06,
      "loss": 0.7556,
      "step": 14820
    },
    {
      "epoch": 4.12825,
      "grad_norm": 8.121825218200684,
      "learning_rate": 8.607191904299142e-06,
      "loss": 0.8391,
      "step": 14825
    },
    {
      "epoch": 4.1285,
      "grad_norm": 5.566745281219482,
      "learning_rate": 8.591592663067771e-06,
      "loss": 0.8398,
      "step": 14830
    },
    {
      "epoch": 4.12875,
      "grad_norm": 5.438380241394043,
      "learning_rate": 8.576004636828103e-06,
      "loss": 1.0395,
      "step": 14835
    },
    {
      "epoch": 4.129,
      "grad_norm": 4.663290500640869,
      "learning_rate": 8.56042783623439e-06,
      "loss": 0.6871,
      "step": 14840
    },
    {
      "epoch": 4.12925,
      "grad_norm": 4.886257171630859,
      "learning_rate": 8.544862271933232e-06,
      "loss": 0.7317,
      "step": 14845
    },
    {
      "epoch": 4.1295,
      "grad_norm": 4.352334976196289,
      "learning_rate": 8.52930795456355e-06,
      "loss": 0.7632,
      "step": 14850
    },
    {
      "epoch": 4.12975,
      "grad_norm": 6.005286693572998,
      "learning_rate": 8.513764894756579e-06,
      "loss": 0.6928,
      "step": 14855
    },
    {
      "epoch": 4.13,
      "grad_norm": 5.7608561515808105,
      "learning_rate": 8.49823310313584e-06,
      "loss": 0.8083,
      "step": 14860
    },
    {
      "epoch": 4.13025,
      "grad_norm": 5.914200782775879,
      "learning_rate": 8.48271259031718e-06,
      "loss": 0.7407,
      "step": 14865
    },
    {
      "epoch": 4.1305,
      "grad_norm": 5.367886543273926,
      "learning_rate": 8.467203366908707e-06,
      "loss": 0.8592,
      "step": 14870
    },
    {
      "epoch": 4.13075,
      "grad_norm": 6.012808322906494,
      "learning_rate": 8.451705443510838e-06,
      "loss": 0.8243,
      "step": 14875
    },
    {
      "epoch": 4.131,
      "grad_norm": 5.638576984405518,
      "learning_rate": 8.436218830716258e-06,
      "loss": 0.6874,
      "step": 14880
    },
    {
      "epoch": 4.13125,
      "grad_norm": 6.241518974304199,
      "learning_rate": 8.420743539109926e-06,
      "loss": 0.7268,
      "step": 14885
    },
    {
      "epoch": 4.1315,
      "grad_norm": 5.145242691040039,
      "learning_rate": 8.405279579269046e-06,
      "loss": 0.6691,
      "step": 14890
    },
    {
      "epoch": 4.13175,
      "grad_norm": 5.319235801696777,
      "learning_rate": 8.389826961763094e-06,
      "loss": 0.7596,
      "step": 14895
    },
    {
      "epoch": 4.132,
      "grad_norm": 4.8634443283081055,
      "learning_rate": 8.374385697153792e-06,
      "loss": 0.725,
      "step": 14900
    },
    {
      "epoch": 4.13225,
      "grad_norm": 7.885411262512207,
      "learning_rate": 8.3589557959951e-06,
      "loss": 0.7531,
      "step": 14905
    },
    {
      "epoch": 4.1325,
      "grad_norm": 5.042999267578125,
      "learning_rate": 8.343537268833199e-06,
      "loss": 0.7451,
      "step": 14910
    },
    {
      "epoch": 4.13275,
      "grad_norm": 4.996045112609863,
      "learning_rate": 8.328130126206521e-06,
      "loss": 0.7481,
      "step": 14915
    },
    {
      "epoch": 4.133,
      "grad_norm": 3.7448065280914307,
      "learning_rate": 8.31273437864569e-06,
      "loss": 0.5971,
      "step": 14920
    },
    {
      "epoch": 4.13325,
      "grad_norm": 7.218389511108398,
      "learning_rate": 8.297350036673556e-06,
      "loss": 0.7959,
      "step": 14925
    },
    {
      "epoch": 4.1335,
      "grad_norm": 4.748136520385742,
      "learning_rate": 8.281977110805177e-06,
      "loss": 0.6285,
      "step": 14930
    },
    {
      "epoch": 4.13375,
      "grad_norm": 3.688535213470459,
      "learning_rate": 8.266615611547809e-06,
      "loss": 0.5837,
      "step": 14935
    },
    {
      "epoch": 4.134,
      "grad_norm": 5.351858615875244,
      "learning_rate": 8.251265549400877e-06,
      "loss": 0.7421,
      "step": 14940
    },
    {
      "epoch": 4.13425,
      "grad_norm": 4.897543907165527,
      "learning_rate": 8.235926934856011e-06,
      "loss": 0.723,
      "step": 14945
    },
    {
      "epoch": 4.1345,
      "grad_norm": 4.700387001037598,
      "learning_rate": 8.220599778397017e-06,
      "loss": 0.738,
      "step": 14950
    },
    {
      "epoch": 4.13475,
      "grad_norm": 7.248361110687256,
      "learning_rate": 8.205284090499845e-06,
      "loss": 0.8165,
      "step": 14955
    },
    {
      "epoch": 4.135,
      "grad_norm": 6.071823596954346,
      "learning_rate": 8.189979881632634e-06,
      "loss": 0.8359,
      "step": 14960
    },
    {
      "epoch": 4.13525,
      "grad_norm": 9.064569473266602,
      "learning_rate": 8.174687162255672e-06,
      "loss": 0.8217,
      "step": 14965
    },
    {
      "epoch": 4.1355,
      "grad_norm": 5.120617389678955,
      "learning_rate": 8.159405942821375e-06,
      "loss": 0.823,
      "step": 14970
    },
    {
      "epoch": 4.13575,
      "grad_norm": 6.758677959442139,
      "learning_rate": 8.144136233774316e-06,
      "loss": 0.843,
      "step": 14975
    },
    {
      "epoch": 4.136,
      "grad_norm": 6.898040294647217,
      "learning_rate": 8.1288780455512e-06,
      "loss": 0.7368,
      "step": 14980
    },
    {
      "epoch": 4.13625,
      "grad_norm": 5.392968654632568,
      "learning_rate": 8.113631388580863e-06,
      "loss": 0.765,
      "step": 14985
    },
    {
      "epoch": 4.1365,
      "grad_norm": 4.99080753326416,
      "learning_rate": 8.098396273284236e-06,
      "loss": 0.911,
      "step": 14990
    },
    {
      "epoch": 4.13675,
      "grad_norm": 5.267343997955322,
      "learning_rate": 8.083172710074393e-06,
      "loss": 0.8064,
      "step": 14995
    },
    {
      "epoch": 4.1370000000000005,
      "grad_norm": 7.535536766052246,
      "learning_rate": 8.067960709356478e-06,
      "loss": 0.9464,
      "step": 15000
    },
    {
      "epoch": 4.1370000000000005,
      "eval_loss": 2.1259219646453857,
      "eval_runtime": 5.1592,
      "eval_samples_per_second": 198.482,
      "eval_steps_per_second": 24.81,
      "step": 15000
    },
    {
      "epoch": 4.13725,
      "grad_norm": 6.3588409423828125,
      "learning_rate": 8.052760281527757e-06,
      "loss": 0.9177,
      "step": 15005
    },
    {
      "epoch": 4.1375,
      "grad_norm": 5.965919017791748,
      "learning_rate": 8.037571436977582e-06,
      "loss": 0.6731,
      "step": 15010
    },
    {
      "epoch": 4.13775,
      "grad_norm": 6.7811503410339355,
      "learning_rate": 8.02239418608739e-06,
      "loss": 0.7807,
      "step": 15015
    },
    {
      "epoch": 4.138,
      "grad_norm": 4.676119804382324,
      "learning_rate": 8.007228539230676e-06,
      "loss": 0.8407,
      "step": 15020
    },
    {
      "epoch": 4.13825,
      "grad_norm": 6.616391181945801,
      "learning_rate": 7.992074506773022e-06,
      "loss": 0.7635,
      "step": 15025
    },
    {
      "epoch": 4.1385,
      "grad_norm": 6.884182929992676,
      "learning_rate": 7.976932099072068e-06,
      "loss": 0.9266,
      "step": 15030
    },
    {
      "epoch": 4.13875,
      "grad_norm": 6.320414066314697,
      "learning_rate": 7.961801326477514e-06,
      "loss": 0.8843,
      "step": 15035
    },
    {
      "epoch": 4.139,
      "grad_norm": 4.977715015411377,
      "learning_rate": 7.946682199331088e-06,
      "loss": 0.7723,
      "step": 15040
    },
    {
      "epoch": 4.13925,
      "grad_norm": 5.662229061126709,
      "learning_rate": 7.931574727966579e-06,
      "loss": 0.8514,
      "step": 15045
    },
    {
      "epoch": 4.1395,
      "grad_norm": 4.837284564971924,
      "learning_rate": 7.91647892270979e-06,
      "loss": 0.7064,
      "step": 15050
    },
    {
      "epoch": 4.13975,
      "grad_norm": 5.474625110626221,
      "learning_rate": 7.901394793878573e-06,
      "loss": 0.8037,
      "step": 15055
    },
    {
      "epoch": 4.14,
      "grad_norm": 7.372259616851807,
      "learning_rate": 7.886322351782783e-06,
      "loss": 0.7056,
      "step": 15060
    },
    {
      "epoch": 4.14025,
      "grad_norm": 7.766931533813477,
      "learning_rate": 7.8712616067243e-06,
      "loss": 0.8386,
      "step": 15065
    },
    {
      "epoch": 4.1405,
      "grad_norm": 5.730288982391357,
      "learning_rate": 7.856212568996987e-06,
      "loss": 0.7066,
      "step": 15070
    },
    {
      "epoch": 4.14075,
      "grad_norm": 6.524260997772217,
      "learning_rate": 7.841175248886725e-06,
      "loss": 0.8141,
      "step": 15075
    },
    {
      "epoch": 4.141,
      "grad_norm": 5.45947265625,
      "learning_rate": 7.826149656671386e-06,
      "loss": 0.7516,
      "step": 15080
    },
    {
      "epoch": 4.14125,
      "grad_norm": 6.41838264465332,
      "learning_rate": 7.811135802620822e-06,
      "loss": 0.7874,
      "step": 15085
    },
    {
      "epoch": 4.1415,
      "grad_norm": 5.751837730407715,
      "learning_rate": 7.796133696996858e-06,
      "loss": 0.7009,
      "step": 15090
    },
    {
      "epoch": 4.14175,
      "grad_norm": 5.2787766456604,
      "learning_rate": 7.781143350053279e-06,
      "loss": 0.6853,
      "step": 15095
    },
    {
      "epoch": 4.142,
      "grad_norm": 5.808896541595459,
      "learning_rate": 7.766164772035856e-06,
      "loss": 0.8268,
      "step": 15100
    },
    {
      "epoch": 4.14225,
      "grad_norm": 8.395404815673828,
      "learning_rate": 7.75119797318231e-06,
      "loss": 0.793,
      "step": 15105
    },
    {
      "epoch": 4.1425,
      "grad_norm": 4.984039306640625,
      "learning_rate": 7.736242963722299e-06,
      "loss": 0.6881,
      "step": 15110
    },
    {
      "epoch": 4.14275,
      "grad_norm": 3.9673666954040527,
      "learning_rate": 7.721299753877442e-06,
      "loss": 0.725,
      "step": 15115
    },
    {
      "epoch": 4.143,
      "grad_norm": 4.958789825439453,
      "learning_rate": 7.706368353861269e-06,
      "loss": 0.6506,
      "step": 15120
    },
    {
      "epoch": 4.14325,
      "grad_norm": 4.933674335479736,
      "learning_rate": 7.691448773879257e-06,
      "loss": 0.6929,
      "step": 15125
    },
    {
      "epoch": 4.1435,
      "grad_norm": 6.055113792419434,
      "learning_rate": 7.676541024128798e-06,
      "loss": 0.8677,
      "step": 15130
    },
    {
      "epoch": 4.14375,
      "grad_norm": 6.808400630950928,
      "learning_rate": 7.661645114799205e-06,
      "loss": 0.696,
      "step": 15135
    },
    {
      "epoch": 4.144,
      "grad_norm": 5.5715227127075195,
      "learning_rate": 7.646761056071686e-06,
      "loss": 0.6715,
      "step": 15140
    },
    {
      "epoch": 4.1442499999999995,
      "grad_norm": 4.2740888595581055,
      "learning_rate": 7.631888858119346e-06,
      "loss": 0.7708,
      "step": 15145
    },
    {
      "epoch": 4.1445,
      "grad_norm": 5.387861728668213,
      "learning_rate": 7.617028531107201e-06,
      "loss": 0.61,
      "step": 15150
    },
    {
      "epoch": 4.14475,
      "grad_norm": 4.511486053466797,
      "learning_rate": 7.602180085192143e-06,
      "loss": 0.6276,
      "step": 15155
    },
    {
      "epoch": 4.145,
      "grad_norm": 6.233462333679199,
      "learning_rate": 7.587343530522945e-06,
      "loss": 0.7289,
      "step": 15160
    },
    {
      "epoch": 4.14525,
      "grad_norm": 4.242225646972656,
      "learning_rate": 7.572518877240259e-06,
      "loss": 0.5555,
      "step": 15165
    },
    {
      "epoch": 4.1455,
      "grad_norm": 7.577666759490967,
      "learning_rate": 7.5577061354765835e-06,
      "loss": 0.6775,
      "step": 15170
    },
    {
      "epoch": 4.14575,
      "grad_norm": 4.43719482421875,
      "learning_rate": 7.542905315356291e-06,
      "loss": 0.7531,
      "step": 15175
    },
    {
      "epoch": 4.146,
      "grad_norm": 4.644114017486572,
      "learning_rate": 7.528116426995604e-06,
      "loss": 0.6199,
      "step": 15180
    },
    {
      "epoch": 4.14625,
      "grad_norm": 4.559597015380859,
      "learning_rate": 7.513339480502601e-06,
      "loss": 0.6393,
      "step": 15185
    },
    {
      "epoch": 4.1465,
      "grad_norm": 12.024209022521973,
      "learning_rate": 7.498574485977172e-06,
      "loss": 1.4757,
      "step": 15190
    },
    {
      "epoch": 4.14675,
      "grad_norm": 13.05250358581543,
      "learning_rate": 7.483821453511045e-06,
      "loss": 1.8114,
      "step": 15195
    },
    {
      "epoch": 4.147,
      "grad_norm": 11.914315223693848,
      "learning_rate": 7.469080393187786e-06,
      "loss": 1.6303,
      "step": 15200
    },
    {
      "epoch": 4.14725,
      "grad_norm": 12.973957061767578,
      "learning_rate": 7.454351315082772e-06,
      "loss": 1.47,
      "step": 15205
    },
    {
      "epoch": 4.1475,
      "grad_norm": 11.382076263427734,
      "learning_rate": 7.4396342292631895e-06,
      "loss": 1.4068,
      "step": 15210
    },
    {
      "epoch": 4.14775,
      "grad_norm": 11.3996000289917,
      "learning_rate": 7.4249291457880346e-06,
      "loss": 1.3621,
      "step": 15215
    },
    {
      "epoch": 4.148,
      "grad_norm": 10.597484588623047,
      "learning_rate": 7.410236074708077e-06,
      "loss": 1.3573,
      "step": 15220
    },
    {
      "epoch": 4.14825,
      "grad_norm": 10.182567596435547,
      "learning_rate": 7.395555026065901e-06,
      "loss": 1.2877,
      "step": 15225
    },
    {
      "epoch": 4.1485,
      "grad_norm": 8.095968246459961,
      "learning_rate": 7.380886009895874e-06,
      "loss": 1.3549,
      "step": 15230
    },
    {
      "epoch": 4.14875,
      "grad_norm": 14.199520111083984,
      "learning_rate": 7.366229036224112e-06,
      "loss": 1.3863,
      "step": 15235
    },
    {
      "epoch": 4.149,
      "grad_norm": 8.536603927612305,
      "learning_rate": 7.351584115068535e-06,
      "loss": 1.3496,
      "step": 15240
    },
    {
      "epoch": 4.14925,
      "grad_norm": 7.805700302124023,
      "learning_rate": 7.336951256438792e-06,
      "loss": 1.2667,
      "step": 15245
    },
    {
      "epoch": 4.1495,
      "grad_norm": 9.362156867980957,
      "learning_rate": 7.3223304703363135e-06,
      "loss": 1.3125,
      "step": 15250
    },
    {
      "epoch": 4.14975,
      "grad_norm": 7.836684226989746,
      "learning_rate": 7.307721766754269e-06,
      "loss": 1.2179,
      "step": 15255
    },
    {
      "epoch": 4.15,
      "grad_norm": 8.334290504455566,
      "learning_rate": 7.293125155677566e-06,
      "loss": 1.2221,
      "step": 15260
    },
    {
      "epoch": 4.15025,
      "grad_norm": 7.728600978851318,
      "learning_rate": 7.278540647082862e-06,
      "loss": 1.2035,
      "step": 15265
    },
    {
      "epoch": 4.1505,
      "grad_norm": 10.509142875671387,
      "learning_rate": 7.263968250938516e-06,
      "loss": 1.3842,
      "step": 15270
    },
    {
      "epoch": 4.15075,
      "grad_norm": 11.941290855407715,
      "learning_rate": 7.249407977204639e-06,
      "loss": 1.2772,
      "step": 15275
    },
    {
      "epoch": 4.151,
      "grad_norm": 8.926901817321777,
      "learning_rate": 7.234859835833021e-06,
      "loss": 1.3007,
      "step": 15280
    },
    {
      "epoch": 4.15125,
      "grad_norm": 8.15247631072998,
      "learning_rate": 7.22032383676719e-06,
      "loss": 1.45,
      "step": 15285
    },
    {
      "epoch": 4.1515,
      "grad_norm": 7.034982204437256,
      "learning_rate": 7.205799989942372e-06,
      "loss": 1.2754,
      "step": 15290
    },
    {
      "epoch": 4.15175,
      "grad_norm": 9.511775016784668,
      "learning_rate": 7.191288305285465e-06,
      "loss": 1.2611,
      "step": 15295
    },
    {
      "epoch": 4.152,
      "grad_norm": 11.38945198059082,
      "learning_rate": 7.176788792715075e-06,
      "loss": 1.3458,
      "step": 15300
    },
    {
      "epoch": 4.15225,
      "grad_norm": 15.650866508483887,
      "learning_rate": 7.162301462141482e-06,
      "loss": 1.2677,
      "step": 15305
    },
    {
      "epoch": 4.1525,
      "grad_norm": 17.02803611755371,
      "learning_rate": 7.147826323466638e-06,
      "loss": 1.2387,
      "step": 15310
    },
    {
      "epoch": 4.15275,
      "grad_norm": 10.867952346801758,
      "learning_rate": 7.133363386584177e-06,
      "loss": 1.4034,
      "step": 15315
    },
    {
      "epoch": 4.153,
      "grad_norm": 10.397071838378906,
      "learning_rate": 7.118912661379368e-06,
      "loss": 1.7214,
      "step": 15320
    },
    {
      "epoch": 4.15325,
      "grad_norm": 8.56502914428711,
      "learning_rate": 7.104474157729138e-06,
      "loss": 1.0503,
      "step": 15325
    },
    {
      "epoch": 5.00025,
      "grad_norm": 8.440587997436523,
      "learning_rate": 7.090047885502077e-06,
      "loss": 0.8389,
      "step": 15330
    },
    {
      "epoch": 5.0005,
      "grad_norm": 7.384639739990234,
      "learning_rate": 7.0756338545584055e-06,
      "loss": 0.8278,
      "step": 15335
    },
    {
      "epoch": 5.00075,
      "grad_norm": 6.351109504699707,
      "learning_rate": 7.061232074749985e-06,
      "loss": 0.8325,
      "step": 15340
    },
    {
      "epoch": 5.001,
      "grad_norm": 7.288653373718262,
      "learning_rate": 7.046842555920283e-06,
      "loss": 0.7694,
      "step": 15345
    },
    {
      "epoch": 5.00125,
      "grad_norm": 6.746788501739502,
      "learning_rate": 7.032465307904404e-06,
      "loss": 0.8533,
      "step": 15350
    },
    {
      "epoch": 5.0015,
      "grad_norm": 7.343639850616455,
      "learning_rate": 7.018100340529063e-06,
      "loss": 0.8623,
      "step": 15355
    },
    {
      "epoch": 5.00175,
      "grad_norm": 5.718675136566162,
      "learning_rate": 7.003747663612581e-06,
      "loss": 0.709,
      "step": 15360
    },
    {
      "epoch": 5.002,
      "grad_norm": 6.547310829162598,
      "learning_rate": 6.989407286964886e-06,
      "loss": 0.7496,
      "step": 15365
    },
    {
      "epoch": 5.00225,
      "grad_norm": 6.482365131378174,
      "learning_rate": 6.9750792203874785e-06,
      "loss": 0.7866,
      "step": 15370
    },
    {
      "epoch": 5.0025,
      "grad_norm": 10.943218231201172,
      "learning_rate": 6.960763473673451e-06,
      "loss": 0.9357,
      "step": 15375
    },
    {
      "epoch": 5.00275,
      "grad_norm": 10.862380027770996,
      "learning_rate": 6.94646005660749e-06,
      "loss": 0.911,
      "step": 15380
    },
    {
      "epoch": 5.003,
      "grad_norm": 9.226468086242676,
      "learning_rate": 6.932168978965845e-06,
      "loss": 0.9301,
      "step": 15385
    },
    {
      "epoch": 5.00325,
      "grad_norm": 8.65825366973877,
      "learning_rate": 6.91789025051634e-06,
      "loss": 0.9319,
      "step": 15390
    },
    {
      "epoch": 5.0035,
      "grad_norm": 7.13484001159668,
      "learning_rate": 6.90362388101834e-06,
      "loss": 0.8367,
      "step": 15395
    },
    {
      "epoch": 5.00375,
      "grad_norm": 5.905579090118408,
      "learning_rate": 6.889369880222776e-06,
      "loss": 0.7481,
      "step": 15400
    },
    {
      "epoch": 5.004,
      "grad_norm": 9.713722229003906,
      "learning_rate": 6.87512825787213e-06,
      "loss": 0.8454,
      "step": 15405
    },
    {
      "epoch": 5.00425,
      "grad_norm": 12.625256538391113,
      "learning_rate": 6.860899023700407e-06,
      "loss": 0.9257,
      "step": 15410
    },
    {
      "epoch": 5.0045,
      "grad_norm": 8.812359809875488,
      "learning_rate": 6.846682187433171e-06,
      "loss": 0.8853,
      "step": 15415
    },
    {
      "epoch": 5.00475,
      "grad_norm": 11.353218078613281,
      "learning_rate": 6.832477758787484e-06,
      "loss": 0.9829,
      "step": 15420
    },
    {
      "epoch": 5.005,
      "grad_norm": 9.853745460510254,
      "learning_rate": 6.818285747471931e-06,
      "loss": 0.9777,
      "step": 15425
    },
    {
      "epoch": 5.00525,
      "grad_norm": 8.41620922088623,
      "learning_rate": 6.8041061631866245e-06,
      "loss": 0.9729,
      "step": 15430
    },
    {
      "epoch": 5.0055,
      "grad_norm": 9.423831939697266,
      "learning_rate": 6.789939015623181e-06,
      "loss": 1.0239,
      "step": 15435
    },
    {
      "epoch": 5.00575,
      "grad_norm": 9.466975212097168,
      "learning_rate": 6.775784314464717e-06,
      "loss": 0.9246,
      "step": 15440
    },
    {
      "epoch": 5.006,
      "grad_norm": 9.261757850646973,
      "learning_rate": 6.761642069385821e-06,
      "loss": 0.9814,
      "step": 15445
    },
    {
      "epoch": 5.00625,
      "grad_norm": 8.417393684387207,
      "learning_rate": 6.747512290052596e-06,
      "loss": 0.9364,
      "step": 15450
    },
    {
      "epoch": 5.0065,
      "grad_norm": 9.759966850280762,
      "learning_rate": 6.733394986122607e-06,
      "loss": 1.0141,
      "step": 15455
    },
    {
      "epoch": 5.00675,
      "grad_norm": 8.46446704864502,
      "learning_rate": 6.71929016724491e-06,
      "loss": 0.8688,
      "step": 15460
    },
    {
      "epoch": 5.007,
      "grad_norm": 9.188328742980957,
      "learning_rate": 6.705197843059998e-06,
      "loss": 0.8434,
      "step": 15465
    },
    {
      "epoch": 5.00725,
      "grad_norm": 8.822552680969238,
      "learning_rate": 6.691118023199861e-06,
      "loss": 0.893,
      "step": 15470
    },
    {
      "epoch": 5.0075,
      "grad_norm": 7.479889869689941,
      "learning_rate": 6.677050717287903e-06,
      "loss": 0.9654,
      "step": 15475
    },
    {
      "epoch": 5.00775,
      "grad_norm": 7.928954601287842,
      "learning_rate": 6.662995934939007e-06,
      "loss": 0.8841,
      "step": 15480
    },
    {
      "epoch": 5.008,
      "grad_norm": 7.634003162384033,
      "learning_rate": 6.648953685759479e-06,
      "loss": 0.8781,
      "step": 15485
    },
    {
      "epoch": 5.00825,
      "grad_norm": 8.392423629760742,
      "learning_rate": 6.634923979347074e-06,
      "loss": 0.9045,
      "step": 15490
    },
    {
      "epoch": 5.0085,
      "grad_norm": 9.846030235290527,
      "learning_rate": 6.620906825290951e-06,
      "loss": 0.8245,
      "step": 15495
    },
    {
      "epoch": 5.00875,
      "grad_norm": 9.075581550598145,
      "learning_rate": 6.606902233171711e-06,
      "loss": 0.8132,
      "step": 15500
    },
    {
      "epoch": 5.00875,
      "eval_loss": 2.0132994651794434,
      "eval_runtime": 5.0286,
      "eval_samples_per_second": 203.634,
      "eval_steps_per_second": 25.454,
      "step": 15500
    },
    {
      "epoch": 5.009,
      "grad_norm": 10.387080192565918,
      "learning_rate": 6.592910212561354e-06,
      "loss": 0.9021,
      "step": 15505
    },
    {
      "epoch": 5.00925,
      "grad_norm": 7.428893566131592,
      "learning_rate": 6.5789307730233065e-06,
      "loss": 0.8066,
      "step": 15510
    },
    {
      "epoch": 5.0095,
      "grad_norm": 8.63119125366211,
      "learning_rate": 6.564963924112369e-06,
      "loss": 0.7916,
      "step": 15515
    },
    {
      "epoch": 5.00975,
      "grad_norm": 10.219520568847656,
      "learning_rate": 6.551009675374764e-06,
      "loss": 0.9124,
      "step": 15520
    },
    {
      "epoch": 5.01,
      "grad_norm": 7.479497909545898,
      "learning_rate": 6.537068036348074e-06,
      "loss": 0.8686,
      "step": 15525
    },
    {
      "epoch": 5.01025,
      "grad_norm": 8.249850273132324,
      "learning_rate": 6.5231390165612884e-06,
      "loss": 0.8785,
      "step": 15530
    },
    {
      "epoch": 5.0105,
      "grad_norm": 7.11909818649292,
      "learning_rate": 6.509222625534755e-06,
      "loss": 0.8667,
      "step": 15535
    },
    {
      "epoch": 5.01075,
      "grad_norm": 9.624767303466797,
      "learning_rate": 6.49531887278021e-06,
      "loss": 0.7952,
      "step": 15540
    },
    {
      "epoch": 5.011,
      "grad_norm": 7.973142147064209,
      "learning_rate": 6.481427767800719e-06,
      "loss": 0.7902,
      "step": 15545
    },
    {
      "epoch": 5.01125,
      "grad_norm": 6.838888168334961,
      "learning_rate": 6.46754932009073e-06,
      "loss": 0.802,
      "step": 15550
    },
    {
      "epoch": 5.0115,
      "grad_norm": 7.6594109535217285,
      "learning_rate": 6.4536835391360354e-06,
      "loss": 0.8084,
      "step": 15555
    },
    {
      "epoch": 5.01175,
      "grad_norm": 8.212817192077637,
      "learning_rate": 6.439830434413754e-06,
      "loss": 0.8904,
      "step": 15560
    },
    {
      "epoch": 5.012,
      "grad_norm": 7.413678169250488,
      "learning_rate": 6.425990015392358e-06,
      "loss": 0.8701,
      "step": 15565
    },
    {
      "epoch": 5.01225,
      "grad_norm": 8.216541290283203,
      "learning_rate": 6.412162291531651e-06,
      "loss": 1.0067,
      "step": 15570
    },
    {
      "epoch": 5.0125,
      "grad_norm": 8.196913719177246,
      "learning_rate": 6.39834727228274e-06,
      "loss": 0.8809,
      "step": 15575
    },
    {
      "epoch": 5.01275,
      "grad_norm": 7.674752235412598,
      "learning_rate": 6.384544967088063e-06,
      "loss": 0.7908,
      "step": 15580
    },
    {
      "epoch": 5.013,
      "grad_norm": 8.646846771240234,
      "learning_rate": 6.370755385381369e-06,
      "loss": 0.8618,
      "step": 15585
    },
    {
      "epoch": 5.01325,
      "grad_norm": 8.826744079589844,
      "learning_rate": 6.3569785365877125e-06,
      "loss": 0.862,
      "step": 15590
    },
    {
      "epoch": 5.0135,
      "grad_norm": 8.013054847717285,
      "learning_rate": 6.343214430123426e-06,
      "loss": 0.7606,
      "step": 15595
    },
    {
      "epoch": 5.01375,
      "grad_norm": 6.304926872253418,
      "learning_rate": 6.329463075396161e-06,
      "loss": 0.7262,
      "step": 15600
    },
    {
      "epoch": 5.014,
      "grad_norm": 9.068923950195312,
      "learning_rate": 6.315724481804822e-06,
      "loss": 0.6637,
      "step": 15605
    },
    {
      "epoch": 5.01425,
      "grad_norm": 6.111093997955322,
      "learning_rate": 6.301998658739619e-06,
      "loss": 0.6411,
      "step": 15610
    },
    {
      "epoch": 5.0145,
      "grad_norm": 4.8722004890441895,
      "learning_rate": 6.288285615582024e-06,
      "loss": 0.5639,
      "step": 15615
    },
    {
      "epoch": 5.01475,
      "grad_norm": 5.542845726013184,
      "learning_rate": 6.274585361704774e-06,
      "loss": 0.5746,
      "step": 15620
    },
    {
      "epoch": 5.015,
      "grad_norm": 3.1815803050994873,
      "learning_rate": 6.260897906471852e-06,
      "loss": 0.502,
      "step": 15625
    },
    {
      "epoch": 5.01525,
      "grad_norm": 3.268813133239746,
      "learning_rate": 6.247223259238511e-06,
      "loss": 0.5645,
      "step": 15630
    },
    {
      "epoch": 5.0155,
      "grad_norm": 4.7472405433654785,
      "learning_rate": 6.233561429351245e-06,
      "loss": 0.4802,
      "step": 15635
    },
    {
      "epoch": 5.01575,
      "grad_norm": 2.9902520179748535,
      "learning_rate": 6.219912426147795e-06,
      "loss": 0.4044,
      "step": 15640
    },
    {
      "epoch": 5.016,
      "grad_norm": 2.6650612354278564,
      "learning_rate": 6.206276258957105e-06,
      "loss": 0.4281,
      "step": 15645
    },
    {
      "epoch": 5.01625,
      "grad_norm": 2.6289727687835693,
      "learning_rate": 6.192652937099388e-06,
      "loss": 0.4308,
      "step": 15650
    },
    {
      "epoch": 5.0165,
      "grad_norm": 10.214287757873535,
      "learning_rate": 6.179042469886037e-06,
      "loss": 0.5184,
      "step": 15655
    },
    {
      "epoch": 5.01675,
      "grad_norm": 9.05864429473877,
      "learning_rate": 6.165444866619685e-06,
      "loss": 0.9156,
      "step": 15660
    },
    {
      "epoch": 5.017,
      "grad_norm": 11.784917831420898,
      "learning_rate": 6.1518601365941705e-06,
      "loss": 0.9865,
      "step": 15665
    },
    {
      "epoch": 5.01725,
      "grad_norm": 11.292189598083496,
      "learning_rate": 6.138288289094532e-06,
      "loss": 1.0454,
      "step": 15670
    },
    {
      "epoch": 5.0175,
      "grad_norm": 12.49211311340332,
      "learning_rate": 6.124729333396984e-06,
      "loss": 0.9258,
      "step": 15675
    },
    {
      "epoch": 5.01775,
      "grad_norm": 12.207798957824707,
      "learning_rate": 6.111183278768956e-06,
      "loss": 0.8837,
      "step": 15680
    },
    {
      "epoch": 5.018,
      "grad_norm": 13.004081726074219,
      "learning_rate": 6.0976501344690435e-06,
      "loss": 0.9486,
      "step": 15685
    },
    {
      "epoch": 5.01825,
      "grad_norm": 15.59027099609375,
      "learning_rate": 6.084129909747033e-06,
      "loss": 1.01,
      "step": 15690
    },
    {
      "epoch": 5.0185,
      "grad_norm": 9.157259941101074,
      "learning_rate": 6.070622613843866e-06,
      "loss": 0.9549,
      "step": 15695
    },
    {
      "epoch": 5.01875,
      "grad_norm": 9.981303215026855,
      "learning_rate": 6.057128255991637e-06,
      "loss": 0.8339,
      "step": 15700
    },
    {
      "epoch": 5.019,
      "grad_norm": 10.229202270507812,
      "learning_rate": 6.043646845413628e-06,
      "loss": 0.8802,
      "step": 15705
    },
    {
      "epoch": 5.01925,
      "grad_norm": 7.418000221252441,
      "learning_rate": 6.030178391324251e-06,
      "loss": 0.8446,
      "step": 15710
    },
    {
      "epoch": 5.0195,
      "grad_norm": 8.686454772949219,
      "learning_rate": 6.01672290292907e-06,
      "loss": 0.8688,
      "step": 15715
    },
    {
      "epoch": 5.01975,
      "grad_norm": 8.158666610717773,
      "learning_rate": 6.003280389424789e-06,
      "loss": 0.7568,
      "step": 15720
    },
    {
      "epoch": 5.02,
      "grad_norm": 8.873159408569336,
      "learning_rate": 5.989850859999227e-06,
      "loss": 0.8576,
      "step": 15725
    },
    {
      "epoch": 5.02025,
      "grad_norm": 11.220451354980469,
      "learning_rate": 5.976434323831348e-06,
      "loss": 0.9535,
      "step": 15730
    },
    {
      "epoch": 5.0205,
      "grad_norm": 7.606923580169678,
      "learning_rate": 5.963030790091228e-06,
      "loss": 0.913,
      "step": 15735
    },
    {
      "epoch": 5.02075,
      "grad_norm": 8.734381675720215,
      "learning_rate": 5.9496402679400594e-06,
      "loss": 0.8129,
      "step": 15740
    },
    {
      "epoch": 5.021,
      "grad_norm": 11.847264289855957,
      "learning_rate": 5.936262766530134e-06,
      "loss": 0.9606,
      "step": 15745
    },
    {
      "epoch": 5.02125,
      "grad_norm": 7.196724891662598,
      "learning_rate": 5.9228982950048416e-06,
      "loss": 0.8174,
      "step": 15750
    },
    {
      "epoch": 5.0215,
      "grad_norm": 9.902702331542969,
      "learning_rate": 5.90954686249868e-06,
      "loss": 0.8595,
      "step": 15755
    },
    {
      "epoch": 5.02175,
      "grad_norm": 11.978011131286621,
      "learning_rate": 5.896208478137222e-06,
      "loss": 0.8937,
      "step": 15760
    },
    {
      "epoch": 5.022,
      "grad_norm": 9.249470710754395,
      "learning_rate": 5.882883151037133e-06,
      "loss": 0.869,
      "step": 15765
    },
    {
      "epoch": 5.02225,
      "grad_norm": 11.998498916625977,
      "learning_rate": 5.869570890306153e-06,
      "loss": 0.9694,
      "step": 15770
    },
    {
      "epoch": 5.0225,
      "grad_norm": 7.795031547546387,
      "learning_rate": 5.856271705043073e-06,
      "loss": 1.0102,
      "step": 15775
    },
    {
      "epoch": 5.02275,
      "grad_norm": 8.445634841918945,
      "learning_rate": 5.842985604337769e-06,
      "loss": 0.8788,
      "step": 15780
    },
    {
      "epoch": 5.023,
      "grad_norm": 9.078828811645508,
      "learning_rate": 5.829712597271164e-06,
      "loss": 0.8826,
      "step": 15785
    },
    {
      "epoch": 5.02325,
      "grad_norm": 8.147439002990723,
      "learning_rate": 5.816452692915242e-06,
      "loss": 0.7623,
      "step": 15790
    },
    {
      "epoch": 5.0235,
      "grad_norm": 7.528433322906494,
      "learning_rate": 5.803205900333014e-06,
      "loss": 0.887,
      "step": 15795
    },
    {
      "epoch": 5.02375,
      "grad_norm": 7.8301262855529785,
      "learning_rate": 5.78997222857853e-06,
      "loss": 0.7655,
      "step": 15800
    },
    {
      "epoch": 5.024,
      "grad_norm": 6.69188928604126,
      "learning_rate": 5.776751686696888e-06,
      "loss": 0.8511,
      "step": 15805
    },
    {
      "epoch": 5.02425,
      "grad_norm": 6.241703987121582,
      "learning_rate": 5.763544283724204e-06,
      "loss": 0.7484,
      "step": 15810
    },
    {
      "epoch": 5.0245,
      "grad_norm": 9.045999526977539,
      "learning_rate": 5.750350028687615e-06,
      "loss": 0.9936,
      "step": 15815
    },
    {
      "epoch": 5.02475,
      "grad_norm": 8.941946983337402,
      "learning_rate": 5.737168930605272e-06,
      "loss": 0.8005,
      "step": 15820
    },
    {
      "epoch": 5.025,
      "grad_norm": 10.135168075561523,
      "learning_rate": 5.724000998486323e-06,
      "loss": 0.8382,
      "step": 15825
    },
    {
      "epoch": 5.02525,
      "grad_norm": 5.739830493927002,
      "learning_rate": 5.710846241330928e-06,
      "loss": 0.8472,
      "step": 15830
    },
    {
      "epoch": 5.0255,
      "grad_norm": 11.65388011932373,
      "learning_rate": 5.697704668130249e-06,
      "loss": 0.9422,
      "step": 15835
    },
    {
      "epoch": 5.02575,
      "grad_norm": 10.250743865966797,
      "learning_rate": 5.684576287866411e-06,
      "loss": 0.9211,
      "step": 15840
    },
    {
      "epoch": 5.026,
      "grad_norm": 8.956857681274414,
      "learning_rate": 5.671461109512555e-06,
      "loss": 0.8294,
      "step": 15845
    },
    {
      "epoch": 5.02625,
      "grad_norm": 7.593855857849121,
      "learning_rate": 5.6583591420327684e-06,
      "loss": 1.0204,
      "step": 15850
    },
    {
      "epoch": 5.0265,
      "grad_norm": 8.331216812133789,
      "learning_rate": 5.645270394382124e-06,
      "loss": 0.7797,
      "step": 15855
    },
    {
      "epoch": 5.02675,
      "grad_norm": 8.386004447937012,
      "learning_rate": 5.632194875506663e-06,
      "loss": 0.9421,
      "step": 15860
    },
    {
      "epoch": 5.027,
      "grad_norm": 8.078126907348633,
      "learning_rate": 5.6191325943433766e-06,
      "loss": 0.85,
      "step": 15865
    },
    {
      "epoch": 5.02725,
      "grad_norm": 7.721714973449707,
      "learning_rate": 5.606083559820219e-06,
      "loss": 0.8441,
      "step": 15870
    },
    {
      "epoch": 5.0275,
      "grad_norm": 8.423078536987305,
      "learning_rate": 5.593047780856065e-06,
      "loss": 0.7926,
      "step": 15875
    },
    {
      "epoch": 5.02775,
      "grad_norm": 8.35044002532959,
      "learning_rate": 5.580025266360764e-06,
      "loss": 0.8827,
      "step": 15880
    },
    {
      "epoch": 5.028,
      "grad_norm": 10.34783935546875,
      "learning_rate": 5.56701602523507e-06,
      "loss": 0.8719,
      "step": 15885
    },
    {
      "epoch": 5.02825,
      "grad_norm": 11.029546737670898,
      "learning_rate": 5.554020066370677e-06,
      "loss": 0.9472,
      "step": 15890
    },
    {
      "epoch": 5.0285,
      "grad_norm": 6.92081880569458,
      "learning_rate": 5.5410373986502065e-06,
      "loss": 0.7789,
      "step": 15895
    },
    {
      "epoch": 5.02875,
      "grad_norm": 10.88403606414795,
      "learning_rate": 5.528068030947192e-06,
      "loss": 0.8949,
      "step": 15900
    },
    {
      "epoch": 5.029,
      "grad_norm": 9.97661304473877,
      "learning_rate": 5.515111972126064e-06,
      "loss": 0.8489,
      "step": 15905
    },
    {
      "epoch": 5.02925,
      "grad_norm": 8.168497085571289,
      "learning_rate": 5.50216923104217e-06,
      "loss": 0.8635,
      "step": 15910
    },
    {
      "epoch": 5.0295,
      "grad_norm": 5.696160316467285,
      "learning_rate": 5.489239816541755e-06,
      "loss": 0.7446,
      "step": 15915
    },
    {
      "epoch": 5.02975,
      "grad_norm": 10.404682159423828,
      "learning_rate": 5.476323737461955e-06,
      "loss": 0.8363,
      "step": 15920
    },
    {
      "epoch": 5.03,
      "grad_norm": 7.059110164642334,
      "learning_rate": 5.463421002630775e-06,
      "loss": 0.7906,
      "step": 15925
    },
    {
      "epoch": 5.03025,
      "grad_norm": 8.70118236541748,
      "learning_rate": 5.45053162086713e-06,
      "loss": 0.8555,
      "step": 15930
    },
    {
      "epoch": 5.0305,
      "grad_norm": 7.3166422843933105,
      "learning_rate": 5.437655600980776e-06,
      "loss": 0.8626,
      "step": 15935
    },
    {
      "epoch": 5.03075,
      "grad_norm": 8.203767776489258,
      "learning_rate": 5.424792951772353e-06,
      "loss": 0.8792,
      "step": 15940
    },
    {
      "epoch": 5.031,
      "grad_norm": 6.190170764923096,
      "learning_rate": 5.4119436820333685e-06,
      "loss": 0.8022,
      "step": 15945
    },
    {
      "epoch": 5.03125,
      "grad_norm": 8.455924034118652,
      "learning_rate": 5.399107800546177e-06,
      "loss": 0.9091,
      "step": 15950
    },
    {
      "epoch": 5.0315,
      "grad_norm": 11.084806442260742,
      "learning_rate": 5.386285316083972e-06,
      "loss": 0.8502,
      "step": 15955
    },
    {
      "epoch": 5.03175,
      "grad_norm": 7.234230041503906,
      "learning_rate": 5.373476237410807e-06,
      "loss": 0.8642,
      "step": 15960
    },
    {
      "epoch": 5.032,
      "grad_norm": 9.264094352722168,
      "learning_rate": 5.360680573281568e-06,
      "loss": 0.7704,
      "step": 15965
    },
    {
      "epoch": 5.03225,
      "grad_norm": 8.361604690551758,
      "learning_rate": 5.347898332441975e-06,
      "loss": 0.7777,
      "step": 15970
    },
    {
      "epoch": 5.0325,
      "grad_norm": 9.443828582763672,
      "learning_rate": 5.335129523628565e-06,
      "loss": 0.785,
      "step": 15975
    },
    {
      "epoch": 5.03275,
      "grad_norm": 10.066217422485352,
      "learning_rate": 5.322374155568688e-06,
      "loss": 0.7819,
      "step": 15980
    },
    {
      "epoch": 5.033,
      "grad_norm": 8.891524314880371,
      "learning_rate": 5.3096322369805275e-06,
      "loss": 0.844,
      "step": 15985
    },
    {
      "epoch": 5.03325,
      "grad_norm": 6.32938814163208,
      "learning_rate": 5.296903776573065e-06,
      "loss": 0.8537,
      "step": 15990
    },
    {
      "epoch": 5.0335,
      "grad_norm": 7.388665199279785,
      "learning_rate": 5.284188783046082e-06,
      "loss": 0.8427,
      "step": 15995
    },
    {
      "epoch": 5.03375,
      "grad_norm": 10.764161109924316,
      "learning_rate": 5.271487265090163e-06,
      "loss": 0.8565,
      "step": 16000
    },
    {
      "epoch": 5.03375,
      "eval_loss": 2.0215871334075928,
      "eval_runtime": 5.741,
      "eval_samples_per_second": 178.366,
      "eval_steps_per_second": 22.296,
      "step": 16000
    },
    {
      "epoch": 5.034,
      "grad_norm": 8.391594886779785,
      "learning_rate": 5.258799231386663e-06,
      "loss": 1.007,
      "step": 16005
    },
    {
      "epoch": 5.03425,
      "grad_norm": 7.189497470855713,
      "learning_rate": 5.24612469060774e-06,
      "loss": 0.7705,
      "step": 16010
    },
    {
      "epoch": 5.0345,
      "grad_norm": 8.571442604064941,
      "learning_rate": 5.233463651416323e-06,
      "loss": 0.8803,
      "step": 16015
    },
    {
      "epoch": 5.03475,
      "grad_norm": 6.356936454772949,
      "learning_rate": 5.220816122466119e-06,
      "loss": 0.9376,
      "step": 16020
    },
    {
      "epoch": 5.035,
      "grad_norm": 8.177764892578125,
      "learning_rate": 5.208182112401591e-06,
      "loss": 1.0244,
      "step": 16025
    },
    {
      "epoch": 5.03525,
      "grad_norm": 7.343258857727051,
      "learning_rate": 5.195561629857953e-06,
      "loss": 0.9553,
      "step": 16030
    },
    {
      "epoch": 5.0355,
      "grad_norm": 7.891157627105713,
      "learning_rate": 5.1829546834611995e-06,
      "loss": 0.885,
      "step": 16035
    },
    {
      "epoch": 5.03575,
      "grad_norm": 7.780008316040039,
      "learning_rate": 5.170361281828054e-06,
      "loss": 0.8976,
      "step": 16040
    },
    {
      "epoch": 5.036,
      "grad_norm": 10.373163223266602,
      "learning_rate": 5.1577814335659915e-06,
      "loss": 1.071,
      "step": 16045
    },
    {
      "epoch": 5.03625,
      "grad_norm": 7.635514736175537,
      "learning_rate": 5.145215147273224e-06,
      "loss": 0.8685,
      "step": 16050
    },
    {
      "epoch": 5.0365,
      "grad_norm": 6.567434787750244,
      "learning_rate": 5.132662431538679e-06,
      "loss": 0.9373,
      "step": 16055
    },
    {
      "epoch": 5.03675,
      "grad_norm": 7.730531692504883,
      "learning_rate": 5.120123294942022e-06,
      "loss": 0.9008,
      "step": 16060
    },
    {
      "epoch": 5.037,
      "grad_norm": 7.388699054718018,
      "learning_rate": 5.107597746053647e-06,
      "loss": 0.9836,
      "step": 16065
    },
    {
      "epoch": 5.03725,
      "grad_norm": 7.6478190422058105,
      "learning_rate": 5.095085793434629e-06,
      "loss": 0.9364,
      "step": 16070
    },
    {
      "epoch": 5.0375,
      "grad_norm": 9.65626335144043,
      "learning_rate": 5.082587445636785e-06,
      "loss": 1.1537,
      "step": 16075
    },
    {
      "epoch": 5.03775,
      "grad_norm": 8.090446472167969,
      "learning_rate": 5.070102711202607e-06,
      "loss": 0.9438,
      "step": 16080
    },
    {
      "epoch": 5.038,
      "grad_norm": 7.635491847991943,
      "learning_rate": 5.057631598665297e-06,
      "loss": 0.9337,
      "step": 16085
    },
    {
      "epoch": 5.03825,
      "grad_norm": 10.207597732543945,
      "learning_rate": 5.045174116548745e-06,
      "loss": 0.9421,
      "step": 16090
    },
    {
      "epoch": 5.0385,
      "grad_norm": 9.196142196655273,
      "learning_rate": 5.032730273367523e-06,
      "loss": 0.9507,
      "step": 16095
    },
    {
      "epoch": 5.03875,
      "grad_norm": 7.294220447540283,
      "learning_rate": 5.0203000776268825e-06,
      "loss": 1.0401,
      "step": 16100
    },
    {
      "epoch": 5.039,
      "grad_norm": 5.888222694396973,
      "learning_rate": 5.007883537822736e-06,
      "loss": 0.9538,
      "step": 16105
    },
    {
      "epoch": 5.03925,
      "grad_norm": 8.646650314331055,
      "learning_rate": 4.995480662441679e-06,
      "loss": 0.9382,
      "step": 16110
    },
    {
      "epoch": 5.0395,
      "grad_norm": 8.66949462890625,
      "learning_rate": 4.983091459960962e-06,
      "loss": 0.9264,
      "step": 16115
    },
    {
      "epoch": 5.03975,
      "grad_norm": 6.627948760986328,
      "learning_rate": 4.970715938848478e-06,
      "loss": 0.8719,
      "step": 16120
    },
    {
      "epoch": 5.04,
      "grad_norm": 7.737814903259277,
      "learning_rate": 4.9583541075627936e-06,
      "loss": 0.8873,
      "step": 16125
    },
    {
      "epoch": 5.04025,
      "grad_norm": 5.680334091186523,
      "learning_rate": 4.946005974553086e-06,
      "loss": 0.9504,
      "step": 16130
    },
    {
      "epoch": 5.0405,
      "grad_norm": 7.845219612121582,
      "learning_rate": 4.933671548259198e-06,
      "loss": 0.8663,
      "step": 16135
    },
    {
      "epoch": 5.04075,
      "grad_norm": 6.400284290313721,
      "learning_rate": 4.9213508371115935e-06,
      "loss": 0.8021,
      "step": 16140
    },
    {
      "epoch": 5.041,
      "grad_norm": 8.602691650390625,
      "learning_rate": 4.909043849531358e-06,
      "loss": 0.9839,
      "step": 16145
    },
    {
      "epoch": 5.04125,
      "grad_norm": 8.594334602355957,
      "learning_rate": 4.896750593930216e-06,
      "loss": 0.8478,
      "step": 16150
    },
    {
      "epoch": 5.0415,
      "grad_norm": 7.820384979248047,
      "learning_rate": 4.88447107871047e-06,
      "loss": 0.9346,
      "step": 16155
    },
    {
      "epoch": 5.04175,
      "grad_norm": 7.930933475494385,
      "learning_rate": 4.872205312265074e-06,
      "loss": 0.9638,
      "step": 16160
    },
    {
      "epoch": 5.042,
      "grad_norm": 8.77163028717041,
      "learning_rate": 4.859953302977543e-06,
      "loss": 0.9199,
      "step": 16165
    },
    {
      "epoch": 5.04225,
      "grad_norm": 9.635538101196289,
      "learning_rate": 4.847715059222024e-06,
      "loss": 0.9164,
      "step": 16170
    },
    {
      "epoch": 5.0425,
      "grad_norm": 8.362881660461426,
      "learning_rate": 4.835490589363243e-06,
      "loss": 0.9491,
      "step": 16175
    },
    {
      "epoch": 5.04275,
      "grad_norm": 7.858004570007324,
      "learning_rate": 4.823279901756497e-06,
      "loss": 0.9363,
      "step": 16180
    },
    {
      "epoch": 5.043,
      "grad_norm": 10.508609771728516,
      "learning_rate": 4.811083004747682e-06,
      "loss": 0.9255,
      "step": 16185
    },
    {
      "epoch": 5.04325,
      "grad_norm": 7.4310383796691895,
      "learning_rate": 4.798899906673263e-06,
      "loss": 1.0077,
      "step": 16190
    },
    {
      "epoch": 5.0435,
      "grad_norm": 9.010799407958984,
      "learning_rate": 4.786730615860275e-06,
      "loss": 1.0863,
      "step": 16195
    },
    {
      "epoch": 5.04375,
      "grad_norm": 6.992740154266357,
      "learning_rate": 4.7745751406263165e-06,
      "loss": 0.8334,
      "step": 16200
    },
    {
      "epoch": 5.044,
      "grad_norm": 8.587845802307129,
      "learning_rate": 4.7624334892795354e-06,
      "loss": 0.897,
      "step": 16205
    },
    {
      "epoch": 5.04425,
      "grad_norm": 5.5008063316345215,
      "learning_rate": 4.750305670118629e-06,
      "loss": 0.882,
      "step": 16210
    },
    {
      "epoch": 5.0445,
      "grad_norm": 7.211568355560303,
      "learning_rate": 4.738191691432853e-06,
      "loss": 0.8763,
      "step": 16215
    },
    {
      "epoch": 5.04475,
      "grad_norm": 8.963027000427246,
      "learning_rate": 4.726091561502e-06,
      "loss": 0.9504,
      "step": 16220
    },
    {
      "epoch": 5.045,
      "grad_norm": 7.434919357299805,
      "learning_rate": 4.714005288596399e-06,
      "loss": 0.9029,
      "step": 16225
    },
    {
      "epoch": 5.04525,
      "grad_norm": 7.065093040466309,
      "learning_rate": 4.7019328809768895e-06,
      "loss": 0.9211,
      "step": 16230
    },
    {
      "epoch": 5.0455,
      "grad_norm": 7.742000102996826,
      "learning_rate": 4.689874346894857e-06,
      "loss": 0.876,
      "step": 16235
    },
    {
      "epoch": 5.04575,
      "grad_norm": 6.685351848602295,
      "learning_rate": 4.677829694592198e-06,
      "loss": 0.9089,
      "step": 16240
    },
    {
      "epoch": 5.046,
      "grad_norm": 7.664890766143799,
      "learning_rate": 4.665798932301316e-06,
      "loss": 0.8969,
      "step": 16245
    },
    {
      "epoch": 5.04625,
      "grad_norm": 9.429596900939941,
      "learning_rate": 4.653782068245127e-06,
      "loss": 1.0503,
      "step": 16250
    },
    {
      "epoch": 5.0465,
      "grad_norm": 7.677981853485107,
      "learning_rate": 4.6417791106370425e-06,
      "loss": 0.8479,
      "step": 16255
    },
    {
      "epoch": 5.04675,
      "grad_norm": 7.017207622528076,
      "learning_rate": 4.629790067680964e-06,
      "loss": 0.8867,
      "step": 16260
    },
    {
      "epoch": 5.047,
      "grad_norm": 8.133485794067383,
      "learning_rate": 4.617814947571294e-06,
      "loss": 0.9063,
      "step": 16265
    },
    {
      "epoch": 5.04725,
      "grad_norm": 7.605924129486084,
      "learning_rate": 4.605853758492914e-06,
      "loss": 0.927,
      "step": 16270
    },
    {
      "epoch": 5.0475,
      "grad_norm": 7.504216194152832,
      "learning_rate": 4.593906508621193e-06,
      "loss": 0.831,
      "step": 16275
    },
    {
      "epoch": 5.04775,
      "grad_norm": 8.001718521118164,
      "learning_rate": 4.581973206121948e-06,
      "loss": 0.9513,
      "step": 16280
    },
    {
      "epoch": 5.048,
      "grad_norm": 8.010095596313477,
      "learning_rate": 4.570053859151485e-06,
      "loss": 1.003,
      "step": 16285
    },
    {
      "epoch": 5.04825,
      "grad_norm": 8.66942310333252,
      "learning_rate": 4.5581484758565665e-06,
      "loss": 0.9992,
      "step": 16290
    },
    {
      "epoch": 5.0485,
      "grad_norm": 7.2330641746521,
      "learning_rate": 4.54625706437441e-06,
      "loss": 0.9788,
      "step": 16295
    },
    {
      "epoch": 5.04875,
      "grad_norm": 7.575327396392822,
      "learning_rate": 4.534379632832692e-06,
      "loss": 1.0325,
      "step": 16300
    },
    {
      "epoch": 5.049,
      "grad_norm": 8.63147258758545,
      "learning_rate": 4.5225161893495125e-06,
      "loss": 0.9723,
      "step": 16305
    },
    {
      "epoch": 5.04925,
      "grad_norm": 7.510953903198242,
      "learning_rate": 4.51066674203342e-06,
      "loss": 1.0291,
      "step": 16310
    },
    {
      "epoch": 5.0495,
      "grad_norm": 12.670531272888184,
      "learning_rate": 4.498831298983408e-06,
      "loss": 0.9846,
      "step": 16315
    },
    {
      "epoch": 5.04975,
      "grad_norm": 6.138369083404541,
      "learning_rate": 4.487009868288888e-06,
      "loss": 0.8799,
      "step": 16320
    },
    {
      "epoch": 5.05,
      "grad_norm": 7.968297004699707,
      "learning_rate": 4.475202458029704e-06,
      "loss": 0.9063,
      "step": 16325
    },
    {
      "epoch": 5.05025,
      "grad_norm": 7.792324542999268,
      "learning_rate": 4.463409076276095e-06,
      "loss": 0.9583,
      "step": 16330
    },
    {
      "epoch": 5.0505,
      "grad_norm": 7.8346052169799805,
      "learning_rate": 4.451629731088733e-06,
      "loss": 0.9762,
      "step": 16335
    },
    {
      "epoch": 5.05075,
      "grad_norm": 8.408238410949707,
      "learning_rate": 4.439864430518692e-06,
      "loss": 1.0439,
      "step": 16340
    },
    {
      "epoch": 5.051,
      "grad_norm": 6.094757556915283,
      "learning_rate": 4.428113182607449e-06,
      "loss": 0.8574,
      "step": 16345
    },
    {
      "epoch": 5.05125,
      "grad_norm": 7.027182102203369,
      "learning_rate": 4.416375995386857e-06,
      "loss": 0.9325,
      "step": 16350
    },
    {
      "epoch": 5.0515,
      "grad_norm": 5.931296348571777,
      "learning_rate": 4.404652876879186e-06,
      "loss": 0.7984,
      "step": 16355
    },
    {
      "epoch": 5.05175,
      "grad_norm": 8.743104934692383,
      "learning_rate": 4.392943835097069e-06,
      "loss": 0.9609,
      "step": 16360
    },
    {
      "epoch": 5.052,
      "grad_norm": 6.2683186531066895,
      "learning_rate": 4.381248878043523e-06,
      "loss": 0.8539,
      "step": 16365
    },
    {
      "epoch": 5.05225,
      "grad_norm": 7.44014310836792,
      "learning_rate": 4.369568013711947e-06,
      "loss": 0.8529,
      "step": 16370
    },
    {
      "epoch": 5.0525,
      "grad_norm": 8.325207710266113,
      "learning_rate": 4.357901250086108e-06,
      "loss": 0.9046,
      "step": 16375
    },
    {
      "epoch": 5.05275,
      "grad_norm": 7.518643856048584,
      "learning_rate": 4.346248595140112e-06,
      "loss": 0.849,
      "step": 16380
    },
    {
      "epoch": 5.053,
      "grad_norm": 7.798617839813232,
      "learning_rate": 4.334610056838451e-06,
      "loss": 0.8644,
      "step": 16385
    },
    {
      "epoch": 5.05325,
      "grad_norm": 7.444234848022461,
      "learning_rate": 4.322985643135952e-06,
      "loss": 0.921,
      "step": 16390
    },
    {
      "epoch": 5.0535,
      "grad_norm": 8.38049030303955,
      "learning_rate": 4.3113753619777985e-06,
      "loss": 0.8098,
      "step": 16395
    },
    {
      "epoch": 5.05375,
      "grad_norm": 7.028459072113037,
      "learning_rate": 4.299779221299499e-06,
      "loss": 0.8179,
      "step": 16400
    },
    {
      "epoch": 5.054,
      "grad_norm": 8.744501113891602,
      "learning_rate": 4.288197229026916e-06,
      "loss": 0.8236,
      "step": 16405
    },
    {
      "epoch": 5.05425,
      "grad_norm": 8.39387321472168,
      "learning_rate": 4.27662939307622e-06,
      "loss": 0.838,
      "step": 16410
    },
    {
      "epoch": 5.0545,
      "grad_norm": 8.81919002532959,
      "learning_rate": 4.265075721353923e-06,
      "loss": 1.0579,
      "step": 16415
    },
    {
      "epoch": 5.05475,
      "grad_norm": 7.231634140014648,
      "learning_rate": 4.253536221756851e-06,
      "loss": 0.9543,
      "step": 16420
    },
    {
      "epoch": 5.055,
      "grad_norm": 9.481066703796387,
      "learning_rate": 4.242010902172153e-06,
      "loss": 0.8886,
      "step": 16425
    },
    {
      "epoch": 5.05525,
      "grad_norm": 6.715954780578613,
      "learning_rate": 4.230499770477258e-06,
      "loss": 0.9073,
      "step": 16430
    },
    {
      "epoch": 5.0555,
      "grad_norm": 7.387124538421631,
      "learning_rate": 4.219002834539928e-06,
      "loss": 0.8441,
      "step": 16435
    },
    {
      "epoch": 5.05575,
      "grad_norm": 8.992151260375977,
      "learning_rate": 4.207520102218213e-06,
      "loss": 0.9439,
      "step": 16440
    },
    {
      "epoch": 5.056,
      "grad_norm": 7.700400352478027,
      "learning_rate": 4.196051581360441e-06,
      "loss": 0.9545,
      "step": 16445
    },
    {
      "epoch": 5.05625,
      "grad_norm": 9.432923316955566,
      "learning_rate": 4.184597279805241e-06,
      "loss": 0.928,
      "step": 16450
    },
    {
      "epoch": 5.0565,
      "grad_norm": 5.725581645965576,
      "learning_rate": 4.173157205381531e-06,
      "loss": 0.7889,
      "step": 16455
    },
    {
      "epoch": 5.05675,
      "grad_norm": 10.048924446105957,
      "learning_rate": 4.161731365908481e-06,
      "loss": 0.8817,
      "step": 16460
    },
    {
      "epoch": 5.057,
      "grad_norm": 5.830347537994385,
      "learning_rate": 4.150319769195546e-06,
      "loss": 0.7851,
      "step": 16465
    },
    {
      "epoch": 5.05725,
      "grad_norm": 5.439744472503662,
      "learning_rate": 4.138922423042449e-06,
      "loss": 0.8986,
      "step": 16470
    },
    {
      "epoch": 5.0575,
      "grad_norm": 8.734332084655762,
      "learning_rate": 4.127539335239175e-06,
      "loss": 0.9229,
      "step": 16475
    },
    {
      "epoch": 5.05775,
      "grad_norm": 7.85120964050293,
      "learning_rate": 4.116170513565942e-06,
      "loss": 0.7766,
      "step": 16480
    },
    {
      "epoch": 5.058,
      "grad_norm": 6.584659099578857,
      "learning_rate": 4.104815965793249e-06,
      "loss": 0.7518,
      "step": 16485
    },
    {
      "epoch": 5.05825,
      "grad_norm": 6.853999614715576,
      "learning_rate": 4.093475699681806e-06,
      "loss": 0.7869,
      "step": 16490
    },
    {
      "epoch": 5.0585,
      "grad_norm": 6.405792713165283,
      "learning_rate": 4.082149722982584e-06,
      "loss": 0.8538,
      "step": 16495
    },
    {
      "epoch": 5.05875,
      "grad_norm": 8.294998168945312,
      "learning_rate": 4.070838043436786e-06,
      "loss": 0.8414,
      "step": 16500
    },
    {
      "epoch": 5.05875,
      "eval_loss": 2.0077295303344727,
      "eval_runtime": 5.1887,
      "eval_samples_per_second": 197.351,
      "eval_steps_per_second": 24.669,
      "step": 16500
    },
    {
      "epoch": 5.059,
      "grad_norm": 10.280072212219238,
      "learning_rate": 4.059540668775838e-06,
      "loss": 1.0312,
      "step": 16505
    },
    {
      "epoch": 5.05925,
      "grad_norm": 5.467247009277344,
      "learning_rate": 4.048257606721381e-06,
      "loss": 0.8642,
      "step": 16510
    },
    {
      "epoch": 5.0595,
      "grad_norm": 8.11107063293457,
      "learning_rate": 4.036988864985289e-06,
      "loss": 0.9608,
      "step": 16515
    },
    {
      "epoch": 5.05975,
      "grad_norm": 7.280838966369629,
      "learning_rate": 4.025734451269636e-06,
      "loss": 0.9513,
      "step": 16520
    },
    {
      "epoch": 5.06,
      "grad_norm": 7.9816365242004395,
      "learning_rate": 4.014494373266716e-06,
      "loss": 1.0818,
      "step": 16525
    },
    {
      "epoch": 5.06025,
      "grad_norm": 7.978598594665527,
      "learning_rate": 4.003268638659005e-06,
      "loss": 0.9006,
      "step": 16530
    },
    {
      "epoch": 5.0605,
      "grad_norm": 10.586069107055664,
      "learning_rate": 3.9920572551191995e-06,
      "loss": 1.0307,
      "step": 16535
    },
    {
      "epoch": 5.06075,
      "grad_norm": 8.288312911987305,
      "learning_rate": 3.98086023031016e-06,
      "loss": 0.89,
      "step": 16540
    },
    {
      "epoch": 5.061,
      "grad_norm": 8.473093032836914,
      "learning_rate": 3.9696775718849524e-06,
      "loss": 0.8913,
      "step": 16545
    },
    {
      "epoch": 5.06125,
      "grad_norm": 9.467466354370117,
      "learning_rate": 3.958509287486823e-06,
      "loss": 0.8455,
      "step": 16550
    },
    {
      "epoch": 5.0615,
      "grad_norm": 7.372671127319336,
      "learning_rate": 3.947355384749191e-06,
      "loss": 0.9247,
      "step": 16555
    },
    {
      "epoch": 5.06175,
      "grad_norm": 6.526168346405029,
      "learning_rate": 3.936215871295634e-06,
      "loss": 0.8655,
      "step": 16560
    },
    {
      "epoch": 5.062,
      "grad_norm": 6.245975971221924,
      "learning_rate": 3.925090754739907e-06,
      "loss": 0.9136,
      "step": 16565
    },
    {
      "epoch": 5.06225,
      "grad_norm": 9.777900695800781,
      "learning_rate": 3.913980042685928e-06,
      "loss": 0.9282,
      "step": 16570
    },
    {
      "epoch": 5.0625,
      "grad_norm": 6.011490821838379,
      "learning_rate": 3.902883742727764e-06,
      "loss": 0.7833,
      "step": 16575
    },
    {
      "epoch": 5.06275,
      "grad_norm": 8.652953147888184,
      "learning_rate": 3.891801862449629e-06,
      "loss": 0.7924,
      "step": 16580
    },
    {
      "epoch": 5.063,
      "grad_norm": 8.47527027130127,
      "learning_rate": 3.880734409425876e-06,
      "loss": 0.9306,
      "step": 16585
    },
    {
      "epoch": 5.06325,
      "grad_norm": 8.909669876098633,
      "learning_rate": 3.869681391221011e-06,
      "loss": 1.0687,
      "step": 16590
    },
    {
      "epoch": 5.0635,
      "grad_norm": 6.025149345397949,
      "learning_rate": 3.8586428153896705e-06,
      "loss": 0.7879,
      "step": 16595
    },
    {
      "epoch": 5.06375,
      "grad_norm": 7.013577938079834,
      "learning_rate": 3.847618689476612e-06,
      "loss": 0.9168,
      "step": 16600
    },
    {
      "epoch": 5.064,
      "grad_norm": 8.855332374572754,
      "learning_rate": 3.8366090210167325e-06,
      "loss": 0.8636,
      "step": 16605
    },
    {
      "epoch": 5.06425,
      "grad_norm": 9.206230163574219,
      "learning_rate": 3.825613817535021e-06,
      "loss": 0.932,
      "step": 16610
    },
    {
      "epoch": 5.0645,
      "grad_norm": 7.192416191101074,
      "learning_rate": 3.814633086546601e-06,
      "loss": 0.8188,
      "step": 16615
    },
    {
      "epoch": 5.06475,
      "grad_norm": 8.468381881713867,
      "learning_rate": 3.8036668355567045e-06,
      "loss": 0.9487,
      "step": 16620
    },
    {
      "epoch": 5.065,
      "grad_norm": 9.549971580505371,
      "learning_rate": 3.7927150720606596e-06,
      "loss": 1.0131,
      "step": 16625
    },
    {
      "epoch": 5.06525,
      "grad_norm": 9.72547435760498,
      "learning_rate": 3.78177780354389e-06,
      "loss": 1.0273,
      "step": 16630
    },
    {
      "epoch": 5.0655,
      "grad_norm": 7.641841888427734,
      "learning_rate": 3.77085503748191e-06,
      "loss": 0.9053,
      "step": 16635
    },
    {
      "epoch": 5.06575,
      "grad_norm": 7.533236503601074,
      "learning_rate": 3.7599467813403315e-06,
      "loss": 0.8468,
      "step": 16640
    },
    {
      "epoch": 5.066,
      "grad_norm": 7.172464370727539,
      "learning_rate": 3.7490530425748486e-06,
      "loss": 0.9217,
      "step": 16645
    },
    {
      "epoch": 5.06625,
      "grad_norm": 11.037247657775879,
      "learning_rate": 3.738173828631228e-06,
      "loss": 1.0902,
      "step": 16650
    },
    {
      "epoch": 5.0665,
      "grad_norm": 8.460025787353516,
      "learning_rate": 3.7273091469453127e-06,
      "loss": 0.8689,
      "step": 16655
    },
    {
      "epoch": 5.06675,
      "grad_norm": 9.00009536743164,
      "learning_rate": 3.7164590049429987e-06,
      "loss": 0.8666,
      "step": 16660
    },
    {
      "epoch": 5.067,
      "grad_norm": 6.203631401062012,
      "learning_rate": 3.7056234100402656e-06,
      "loss": 0.8301,
      "step": 16665
    },
    {
      "epoch": 5.06725,
      "grad_norm": 5.671107769012451,
      "learning_rate": 3.6948023696431354e-06,
      "loss": 0.7898,
      "step": 16670
    },
    {
      "epoch": 5.0675,
      "grad_norm": 6.702484607696533,
      "learning_rate": 3.6839958911476957e-06,
      "loss": 0.7736,
      "step": 16675
    },
    {
      "epoch": 5.06775,
      "grad_norm": 6.82905387878418,
      "learning_rate": 3.6732039819400683e-06,
      "loss": 0.7228,
      "step": 16680
    },
    {
      "epoch": 5.068,
      "grad_norm": 6.524406433105469,
      "learning_rate": 3.662426649396411e-06,
      "loss": 1.0323,
      "step": 16685
    },
    {
      "epoch": 5.06825,
      "grad_norm": 8.69007396697998,
      "learning_rate": 3.65166390088294e-06,
      "loss": 0.9581,
      "step": 16690
    },
    {
      "epoch": 5.0685,
      "grad_norm": 8.433958053588867,
      "learning_rate": 3.6409157437558877e-06,
      "loss": 0.9477,
      "step": 16695
    },
    {
      "epoch": 5.06875,
      "grad_norm": 7.169497966766357,
      "learning_rate": 3.630182185361522e-06,
      "loss": 0.8619,
      "step": 16700
    },
    {
      "epoch": 5.069,
      "grad_norm": 6.274602890014648,
      "learning_rate": 3.6194632330361354e-06,
      "loss": 0.8611,
      "step": 16705
    },
    {
      "epoch": 5.06925,
      "grad_norm": 8.254382133483887,
      "learning_rate": 3.6087588941060124e-06,
      "loss": 0.8499,
      "step": 16710
    },
    {
      "epoch": 5.0695,
      "grad_norm": 5.91442346572876,
      "learning_rate": 3.598069175887481e-06,
      "loss": 0.8715,
      "step": 16715
    },
    {
      "epoch": 5.06975,
      "grad_norm": 5.605077266693115,
      "learning_rate": 3.5873940856868656e-06,
      "loss": 0.8887,
      "step": 16720
    },
    {
      "epoch": 5.07,
      "grad_norm": 6.741292476654053,
      "learning_rate": 3.5767336308004743e-06,
      "loss": 0.9281,
      "step": 16725
    },
    {
      "epoch": 5.07025,
      "grad_norm": 6.280573844909668,
      "learning_rate": 3.5660878185146463e-06,
      "loss": 0.8205,
      "step": 16730
    },
    {
      "epoch": 5.0705,
      "grad_norm": 4.947798252105713,
      "learning_rate": 3.5554566561056767e-06,
      "loss": 0.9067,
      "step": 16735
    },
    {
      "epoch": 5.07075,
      "grad_norm": 6.0692524909973145,
      "learning_rate": 3.544840150839876e-06,
      "loss": 0.8182,
      "step": 16740
    },
    {
      "epoch": 5.071,
      "grad_norm": 6.2982707023620605,
      "learning_rate": 3.53423830997352e-06,
      "loss": 0.7839,
      "step": 16745
    },
    {
      "epoch": 5.07125,
      "grad_norm": 5.238400936126709,
      "learning_rate": 3.523651140752868e-06,
      "loss": 0.769,
      "step": 16750
    },
    {
      "epoch": 5.0715,
      "grad_norm": 6.065570831298828,
      "learning_rate": 3.513078650414159e-06,
      "loss": 0.8201,
      "step": 16755
    },
    {
      "epoch": 5.07175,
      "grad_norm": 7.057132244110107,
      "learning_rate": 3.502520846183577e-06,
      "loss": 1.0533,
      "step": 16760
    },
    {
      "epoch": 5.072,
      "grad_norm": 5.884148597717285,
      "learning_rate": 3.491977735277291e-06,
      "loss": 0.878,
      "step": 16765
    },
    {
      "epoch": 5.07225,
      "grad_norm": 6.235851764678955,
      "learning_rate": 3.4814493249014116e-06,
      "loss": 0.8,
      "step": 16770
    },
    {
      "epoch": 5.0725,
      "grad_norm": 5.920417308807373,
      "learning_rate": 3.4709356222520083e-06,
      "loss": 0.7018,
      "step": 16775
    },
    {
      "epoch": 5.07275,
      "grad_norm": 5.5794758796691895,
      "learning_rate": 3.46043663451511e-06,
      "loss": 0.8743,
      "step": 16780
    },
    {
      "epoch": 5.073,
      "grad_norm": 5.2404022216796875,
      "learning_rate": 3.4499523688666574e-06,
      "loss": 0.8004,
      "step": 16785
    },
    {
      "epoch": 5.07325,
      "grad_norm": 6.374990940093994,
      "learning_rate": 3.439482832472554e-06,
      "loss": 0.7374,
      "step": 16790
    },
    {
      "epoch": 5.0735,
      "grad_norm": 5.537233829498291,
      "learning_rate": 3.429028032488635e-06,
      "loss": 0.7233,
      "step": 16795
    },
    {
      "epoch": 5.07375,
      "grad_norm": 4.744968414306641,
      "learning_rate": 3.418587976060653e-06,
      "loss": 0.8853,
      "step": 16800
    },
    {
      "epoch": 5.074,
      "grad_norm": 6.30434513092041,
      "learning_rate": 3.4081626703242914e-06,
      "loss": 0.7845,
      "step": 16805
    },
    {
      "epoch": 5.07425,
      "grad_norm": 5.815616607666016,
      "learning_rate": 3.3977521224051427e-06,
      "loss": 0.7903,
      "step": 16810
    },
    {
      "epoch": 5.0745,
      "grad_norm": 7.238647937774658,
      "learning_rate": 3.387356339418726e-06,
      "loss": 0.8874,
      "step": 16815
    },
    {
      "epoch": 5.07475,
      "grad_norm": 4.6468186378479,
      "learning_rate": 3.3769753284704526e-06,
      "loss": 0.6906,
      "step": 16820
    },
    {
      "epoch": 5.075,
      "grad_norm": 4.778502464294434,
      "learning_rate": 3.366609096655646e-06,
      "loss": 0.69,
      "step": 16825
    },
    {
      "epoch": 5.07525,
      "grad_norm": 6.430379390716553,
      "learning_rate": 3.3562576510595385e-06,
      "loss": 0.7846,
      "step": 16830
    },
    {
      "epoch": 5.0755,
      "grad_norm": 6.171014308929443,
      "learning_rate": 3.345920998757232e-06,
      "loss": 0.8783,
      "step": 16835
    },
    {
      "epoch": 5.07575,
      "grad_norm": 5.648627758026123,
      "learning_rate": 3.3355991468137394e-06,
      "loss": 0.7819,
      "step": 16840
    },
    {
      "epoch": 5.076,
      "grad_norm": 6.322666645050049,
      "learning_rate": 3.3252921022839446e-06,
      "loss": 0.9025,
      "step": 16845
    },
    {
      "epoch": 5.07625,
      "grad_norm": 5.899440765380859,
      "learning_rate": 3.314999872212618e-06,
      "loss": 0.8569,
      "step": 16850
    },
    {
      "epoch": 5.0765,
      "grad_norm": 6.311447620391846,
      "learning_rate": 3.3047224636344075e-06,
      "loss": 0.8011,
      "step": 16855
    },
    {
      "epoch": 5.07675,
      "grad_norm": 5.363535404205322,
      "learning_rate": 3.2944598835738193e-06,
      "loss": 0.8005,
      "step": 16860
    },
    {
      "epoch": 5.077,
      "grad_norm": 5.416820049285889,
      "learning_rate": 3.284212139045223e-06,
      "loss": 0.7355,
      "step": 16865
    },
    {
      "epoch": 5.07725,
      "grad_norm": 5.320718288421631,
      "learning_rate": 3.2739792370528628e-06,
      "loss": 0.7665,
      "step": 16870
    },
    {
      "epoch": 5.0775,
      "grad_norm": 7.062039852142334,
      "learning_rate": 3.2637611845908273e-06,
      "loss": 0.883,
      "step": 16875
    },
    {
      "epoch": 5.07775,
      "grad_norm": 5.309371471405029,
      "learning_rate": 3.2535579886430718e-06,
      "loss": 0.7926,
      "step": 16880
    },
    {
      "epoch": 5.078,
      "grad_norm": 6.158384799957275,
      "learning_rate": 3.243369656183365e-06,
      "loss": 0.8744,
      "step": 16885
    },
    {
      "epoch": 5.07825,
      "grad_norm": 5.717171669006348,
      "learning_rate": 3.2331961941753474e-06,
      "loss": 0.7872,
      "step": 16890
    },
    {
      "epoch": 5.0785,
      "grad_norm": 6.318353652954102,
      "learning_rate": 3.2230376095724823e-06,
      "loss": 0.7145,
      "step": 16895
    },
    {
      "epoch": 5.07875,
      "grad_norm": 5.660789966583252,
      "learning_rate": 3.2128939093180655e-06,
      "loss": 0.7633,
      "step": 16900
    },
    {
      "epoch": 5.079,
      "grad_norm": 7.358546257019043,
      "learning_rate": 3.2027651003452287e-06,
      "loss": 0.7824,
      "step": 16905
    },
    {
      "epoch": 5.07925,
      "grad_norm": 6.041713237762451,
      "learning_rate": 3.192651189576909e-06,
      "loss": 0.8709,
      "step": 16910
    },
    {
      "epoch": 5.0795,
      "grad_norm": 6.0583062171936035,
      "learning_rate": 3.182552183925863e-06,
      "loss": 0.7259,
      "step": 16915
    },
    {
      "epoch": 5.07975,
      "grad_norm": 7.552787780761719,
      "learning_rate": 3.1724680902946753e-06,
      "loss": 0.8007,
      "step": 16920
    },
    {
      "epoch": 5.08,
      "grad_norm": 5.119357585906982,
      "learning_rate": 3.162398915575726e-06,
      "loss": 0.8132,
      "step": 16925
    },
    {
      "epoch": 5.08025,
      "grad_norm": 6.558386325836182,
      "learning_rate": 3.152344666651208e-06,
      "loss": 0.8752,
      "step": 16930
    },
    {
      "epoch": 5.0805,
      "grad_norm": 7.041929721832275,
      "learning_rate": 3.1423053503930933e-06,
      "loss": 0.9128,
      "step": 16935
    },
    {
      "epoch": 5.08075,
      "grad_norm": 6.8376359939575195,
      "learning_rate": 3.1322809736631654e-06,
      "loss": 0.8568,
      "step": 16940
    },
    {
      "epoch": 5.081,
      "grad_norm": 5.448782444000244,
      "learning_rate": 3.1222715433129934e-06,
      "loss": 0.8408,
      "step": 16945
    },
    {
      "epoch": 5.08125,
      "grad_norm": 5.553840637207031,
      "learning_rate": 3.11227706618393e-06,
      "loss": 0.8465,
      "step": 16950
    },
    {
      "epoch": 5.0815,
      "grad_norm": 4.414390563964844,
      "learning_rate": 3.1022975491071e-06,
      "loss": 0.8263,
      "step": 16955
    },
    {
      "epoch": 5.08175,
      "grad_norm": 5.076400279998779,
      "learning_rate": 3.092332998903416e-06,
      "loss": 0.8339,
      "step": 16960
    },
    {
      "epoch": 5.082,
      "grad_norm": 5.644068717956543,
      "learning_rate": 3.0823834223835447e-06,
      "loss": 0.9012,
      "step": 16965
    },
    {
      "epoch": 5.08225,
      "grad_norm": 5.649202823638916,
      "learning_rate": 3.072448826347932e-06,
      "loss": 0.793,
      "step": 16970
    },
    {
      "epoch": 5.0825,
      "grad_norm": 5.671756744384766,
      "learning_rate": 3.062529217586785e-06,
      "loss": 0.8689,
      "step": 16975
    },
    {
      "epoch": 5.08275,
      "grad_norm": 5.7113165855407715,
      "learning_rate": 3.0526246028800637e-06,
      "loss": 0.8372,
      "step": 16980
    },
    {
      "epoch": 5.083,
      "grad_norm": 5.514028549194336,
      "learning_rate": 3.0427349889974698e-06,
      "loss": 0.7678,
      "step": 16985
    },
    {
      "epoch": 5.08325,
      "grad_norm": 6.007273197174072,
      "learning_rate": 3.0328603826984658e-06,
      "loss": 0.739,
      "step": 16990
    },
    {
      "epoch": 5.0835,
      "grad_norm": 6.876797199249268,
      "learning_rate": 3.0230007907322526e-06,
      "loss": 0.8992,
      "step": 16995
    },
    {
      "epoch": 5.08375,
      "grad_norm": 5.089462757110596,
      "learning_rate": 3.013156219837776e-06,
      "loss": 0.7108,
      "step": 17000
    },
    {
      "epoch": 5.08375,
      "eval_loss": 2.076079845428467,
      "eval_runtime": 5.2079,
      "eval_samples_per_second": 196.624,
      "eval_steps_per_second": 24.578,
      "step": 17000
    },
    {
      "epoch": 5.084,
      "grad_norm": 6.553872585296631,
      "learning_rate": 3.0033266767436923e-06,
      "loss": 0.66,
      "step": 17005
    },
    {
      "epoch": 5.08425,
      "grad_norm": 4.546783924102783,
      "learning_rate": 2.9935121681684138e-06,
      "loss": 0.6225,
      "step": 17010
    },
    {
      "epoch": 5.0845,
      "grad_norm": 7.011285781860352,
      "learning_rate": 2.9837127008200543e-06,
      "loss": 0.8002,
      "step": 17015
    },
    {
      "epoch": 5.08475,
      "grad_norm": 4.411685943603516,
      "learning_rate": 2.9739282813964627e-06,
      "loss": 0.6386,
      "step": 17020
    },
    {
      "epoch": 5.085,
      "grad_norm": 5.977591514587402,
      "learning_rate": 2.964158916585197e-06,
      "loss": 0.6873,
      "step": 17025
    },
    {
      "epoch": 5.08525,
      "grad_norm": 5.169394016265869,
      "learning_rate": 2.954404613063527e-06,
      "loss": 0.6745,
      "step": 17030
    },
    {
      "epoch": 5.0855,
      "grad_norm": 4.275820255279541,
      "learning_rate": 2.944665377498432e-06,
      "loss": 0.6023,
      "step": 17035
    },
    {
      "epoch": 5.08575,
      "grad_norm": 5.512986183166504,
      "learning_rate": 2.9349412165465773e-06,
      "loss": 0.7389,
      "step": 17040
    },
    {
      "epoch": 5.086,
      "grad_norm": 5.884683132171631,
      "learning_rate": 2.9252321368543446e-06,
      "loss": 0.762,
      "step": 17045
    },
    {
      "epoch": 5.08625,
      "grad_norm": 5.794618129730225,
      "learning_rate": 2.9155381450577863e-06,
      "loss": 0.6424,
      "step": 17050
    },
    {
      "epoch": 5.0865,
      "grad_norm": 4.940450668334961,
      "learning_rate": 2.9058592477826636e-06,
      "loss": 0.6795,
      "step": 17055
    },
    {
      "epoch": 5.08675,
      "grad_norm": 5.2802414894104,
      "learning_rate": 2.896195451644415e-06,
      "loss": 0.6922,
      "step": 17060
    },
    {
      "epoch": 5.087,
      "grad_norm": 5.0555315017700195,
      "learning_rate": 2.8865467632481465e-06,
      "loss": 0.7609,
      "step": 17065
    },
    {
      "epoch": 5.08725,
      "grad_norm": 5.589709758758545,
      "learning_rate": 2.876913189188643e-06,
      "loss": 0.7103,
      "step": 17070
    },
    {
      "epoch": 5.0875,
      "grad_norm": 6.411716461181641,
      "learning_rate": 2.867294736050369e-06,
      "loss": 0.6875,
      "step": 17075
    },
    {
      "epoch": 5.08775,
      "grad_norm": 4.69037389755249,
      "learning_rate": 2.8576914104074425e-06,
      "loss": 0.6521,
      "step": 17080
    },
    {
      "epoch": 5.088,
      "grad_norm": 6.666329860687256,
      "learning_rate": 2.8481032188236556e-06,
      "loss": 0.7145,
      "step": 17085
    },
    {
      "epoch": 5.08825,
      "grad_norm": 5.624305725097656,
      "learning_rate": 2.838530167852435e-06,
      "loss": 0.6638,
      "step": 17090
    },
    {
      "epoch": 5.0885,
      "grad_norm": 6.135804176330566,
      "learning_rate": 2.8289722640368723e-06,
      "loss": 0.6499,
      "step": 17095
    },
    {
      "epoch": 5.08875,
      "grad_norm": 5.294589996337891,
      "learning_rate": 2.8194295139097048e-06,
      "loss": 0.7638,
      "step": 17100
    },
    {
      "epoch": 5.089,
      "grad_norm": 5.996596813201904,
      "learning_rate": 2.8099019239933162e-06,
      "loss": 0.7459,
      "step": 17105
    },
    {
      "epoch": 5.08925,
      "grad_norm": 5.5697407722473145,
      "learning_rate": 2.8003895007997274e-06,
      "loss": 0.6548,
      "step": 17110
    },
    {
      "epoch": 5.0895,
      "grad_norm": 6.929229259490967,
      "learning_rate": 2.790892250830579e-06,
      "loss": 0.6964,
      "step": 17115
    },
    {
      "epoch": 5.08975,
      "grad_norm": 4.960193157196045,
      "learning_rate": 2.781410180577157e-06,
      "loss": 0.6324,
      "step": 17120
    },
    {
      "epoch": 5.09,
      "grad_norm": 7.1414794921875,
      "learning_rate": 2.7719432965203684e-06,
      "loss": 0.7517,
      "step": 17125
    },
    {
      "epoch": 5.09025,
      "grad_norm": 6.0587592124938965,
      "learning_rate": 2.7624916051307405e-06,
      "loss": 0.6881,
      "step": 17130
    },
    {
      "epoch": 5.0905,
      "grad_norm": 5.739351749420166,
      "learning_rate": 2.753055112868416e-06,
      "loss": 0.6128,
      "step": 17135
    },
    {
      "epoch": 5.09075,
      "grad_norm": 6.223283767700195,
      "learning_rate": 2.743633826183145e-06,
      "loss": 0.5902,
      "step": 17140
    },
    {
      "epoch": 5.091,
      "grad_norm": 5.257467269897461,
      "learning_rate": 2.734227751514287e-06,
      "loss": 0.6605,
      "step": 17145
    },
    {
      "epoch": 5.09125,
      "grad_norm": 5.752057075500488,
      "learning_rate": 2.7248368952908053e-06,
      "loss": 0.696,
      "step": 17150
    },
    {
      "epoch": 5.0915,
      "grad_norm": 6.885556697845459,
      "learning_rate": 2.7154612639312626e-06,
      "loss": 0.7957,
      "step": 17155
    },
    {
      "epoch": 5.09175,
      "grad_norm": 4.646285057067871,
      "learning_rate": 2.706100863843822e-06,
      "loss": 0.8501,
      "step": 17160
    },
    {
      "epoch": 5.092,
      "grad_norm": 5.419910907745361,
      "learning_rate": 2.696755701426215e-06,
      "loss": 0.6561,
      "step": 17165
    },
    {
      "epoch": 5.09225,
      "grad_norm": 5.864901065826416,
      "learning_rate": 2.6874257830657805e-06,
      "loss": 0.7831,
      "step": 17170
    },
    {
      "epoch": 5.0925,
      "grad_norm": 6.377039432525635,
      "learning_rate": 2.6781111151394284e-06,
      "loss": 0.7178,
      "step": 17175
    },
    {
      "epoch": 5.09275,
      "grad_norm": 4.568442344665527,
      "learning_rate": 2.6688117040136464e-06,
      "loss": 0.7819,
      "step": 17180
    },
    {
      "epoch": 5.093,
      "grad_norm": 5.490466117858887,
      "learning_rate": 2.6595275560445e-06,
      "loss": 0.7093,
      "step": 17185
    },
    {
      "epoch": 5.09325,
      "grad_norm": 5.088672637939453,
      "learning_rate": 2.6502586775776076e-06,
      "loss": 0.7453,
      "step": 17190
    },
    {
      "epoch": 5.0935,
      "grad_norm": 5.228175163269043,
      "learning_rate": 2.6410050749481634e-06,
      "loss": 0.7412,
      "step": 17195
    },
    {
      "epoch": 5.09375,
      "grad_norm": 6.748433589935303,
      "learning_rate": 2.6317667544809134e-06,
      "loss": 0.9389,
      "step": 17200
    },
    {
      "epoch": 5.094,
      "grad_norm": 4.512606620788574,
      "learning_rate": 2.62254372249017e-06,
      "loss": 0.6981,
      "step": 17205
    },
    {
      "epoch": 5.09425,
      "grad_norm": 5.5538225173950195,
      "learning_rate": 2.6133359852797886e-06,
      "loss": 0.6468,
      "step": 17210
    },
    {
      "epoch": 5.0945,
      "grad_norm": 4.231688499450684,
      "learning_rate": 2.604143549143162e-06,
      "loss": 0.6514,
      "step": 17215
    },
    {
      "epoch": 5.09475,
      "grad_norm": 5.816915988922119,
      "learning_rate": 2.5949664203632428e-06,
      "loss": 0.7397,
      "step": 17220
    },
    {
      "epoch": 5.095,
      "grad_norm": 5.751967906951904,
      "learning_rate": 2.5858046052125053e-06,
      "loss": 0.7648,
      "step": 17225
    },
    {
      "epoch": 5.09525,
      "grad_norm": 5.043658256530762,
      "learning_rate": 2.576658109952973e-06,
      "loss": 0.7194,
      "step": 17230
    },
    {
      "epoch": 5.0955,
      "grad_norm": 6.042143821716309,
      "learning_rate": 2.5675269408361764e-06,
      "loss": 0.7975,
      "step": 17235
    },
    {
      "epoch": 5.09575,
      "grad_norm": 7.743052005767822,
      "learning_rate": 2.558411104103198e-06,
      "loss": 0.8661,
      "step": 17240
    },
    {
      "epoch": 5.096,
      "grad_norm": 6.672250270843506,
      "learning_rate": 2.5493106059846116e-06,
      "loss": 0.8922,
      "step": 17245
    },
    {
      "epoch": 5.09625,
      "grad_norm": 6.5657148361206055,
      "learning_rate": 2.5402254527005287e-06,
      "loss": 0.8224,
      "step": 17250
    },
    {
      "epoch": 5.0965,
      "grad_norm": 5.914855003356934,
      "learning_rate": 2.5311556504605677e-06,
      "loss": 0.8253,
      "step": 17255
    },
    {
      "epoch": 5.09675,
      "grad_norm": 6.437039375305176,
      "learning_rate": 2.522101205463853e-06,
      "loss": 0.8511,
      "step": 17260
    },
    {
      "epoch": 5.097,
      "grad_norm": 6.817801475524902,
      "learning_rate": 2.513062123899007e-06,
      "loss": 0.748,
      "step": 17265
    },
    {
      "epoch": 5.09725,
      "grad_norm": 4.8773698806762695,
      "learning_rate": 2.5040384119441594e-06,
      "loss": 0.739,
      "step": 17270
    },
    {
      "epoch": 5.0975,
      "grad_norm": 10.5072603225708,
      "learning_rate": 2.4950300757669356e-06,
      "loss": 0.8486,
      "step": 17275
    },
    {
      "epoch": 5.09775,
      "grad_norm": 7.249462604522705,
      "learning_rate": 2.4860371215244484e-06,
      "loss": 0.782,
      "step": 17280
    },
    {
      "epoch": 5.098,
      "grad_norm": 6.738054275512695,
      "learning_rate": 2.4770595553632898e-06,
      "loss": 0.8568,
      "step": 17285
    },
    {
      "epoch": 5.09825,
      "grad_norm": 4.943020820617676,
      "learning_rate": 2.4680973834195516e-06,
      "loss": 0.7156,
      "step": 17290
    },
    {
      "epoch": 5.0985,
      "grad_norm": 6.275191307067871,
      "learning_rate": 2.4591506118187863e-06,
      "loss": 0.8538,
      "step": 17295
    },
    {
      "epoch": 5.09875,
      "grad_norm": 5.5760016441345215,
      "learning_rate": 2.4502192466760276e-06,
      "loss": 0.8245,
      "step": 17300
    },
    {
      "epoch": 5.099,
      "grad_norm": 5.686965465545654,
      "learning_rate": 2.4413032940957813e-06,
      "loss": 0.76,
      "step": 17305
    },
    {
      "epoch": 5.09925,
      "grad_norm": 6.987112045288086,
      "learning_rate": 2.4324027601720257e-06,
      "loss": 0.8505,
      "step": 17310
    },
    {
      "epoch": 5.0995,
      "grad_norm": 5.0720295906066895,
      "learning_rate": 2.4235176509881745e-06,
      "loss": 0.7798,
      "step": 17315
    },
    {
      "epoch": 5.09975,
      "grad_norm": 5.592240810394287,
      "learning_rate": 2.414647972617129e-06,
      "loss": 0.6849,
      "step": 17320
    },
    {
      "epoch": 5.1,
      "grad_norm": 5.656553268432617,
      "learning_rate": 2.405793731121231e-06,
      "loss": 0.8728,
      "step": 17325
    },
    {
      "epoch": 5.10025,
      "grad_norm": 7.434001445770264,
      "learning_rate": 2.3969549325522618e-06,
      "loss": 0.8752,
      "step": 17330
    },
    {
      "epoch": 5.1005,
      "grad_norm": 6.402585506439209,
      "learning_rate": 2.3881315829514637e-06,
      "loss": 0.6793,
      "step": 17335
    },
    {
      "epoch": 5.10075,
      "grad_norm": 5.469504356384277,
      "learning_rate": 2.379323688349516e-06,
      "loss": 0.7005,
      "step": 17340
    },
    {
      "epoch": 5.101,
      "grad_norm": 7.976531982421875,
      "learning_rate": 2.37053125476652e-06,
      "loss": 0.7568,
      "step": 17345
    },
    {
      "epoch": 5.10125,
      "grad_norm": 7.012404441833496,
      "learning_rate": 2.361754288212031e-06,
      "loss": 0.9642,
      "step": 17350
    },
    {
      "epoch": 5.1015,
      "grad_norm": 4.8815412521362305,
      "learning_rate": 2.352992794685019e-06,
      "loss": 0.7093,
      "step": 17355
    },
    {
      "epoch": 5.10175,
      "grad_norm": 4.545533657073975,
      "learning_rate": 2.3442467801738863e-06,
      "loss": 0.686,
      "step": 17360
    },
    {
      "epoch": 5.102,
      "grad_norm": 6.045492172241211,
      "learning_rate": 2.335516250656447e-06,
      "loss": 0.6774,
      "step": 17365
    },
    {
      "epoch": 5.10225,
      "grad_norm": 5.455305576324463,
      "learning_rate": 2.326801212099938e-06,
      "loss": 0.7455,
      "step": 17370
    },
    {
      "epoch": 5.1025,
      "grad_norm": 4.635796546936035,
      "learning_rate": 2.318101670461004e-06,
      "loss": 0.6836,
      "step": 17375
    },
    {
      "epoch": 5.10275,
      "grad_norm": 5.715941429138184,
      "learning_rate": 2.309417631685698e-06,
      "loss": 0.6696,
      "step": 17380
    },
    {
      "epoch": 5.103,
      "grad_norm": 6.186241149902344,
      "learning_rate": 2.3007491017094845e-06,
      "loss": 0.8047,
      "step": 17385
    },
    {
      "epoch": 5.10325,
      "grad_norm": 4.95375394821167,
      "learning_rate": 2.2920960864572212e-06,
      "loss": 0.5999,
      "step": 17390
    },
    {
      "epoch": 5.1035,
      "grad_norm": 5.7842183113098145,
      "learning_rate": 2.2834585918431544e-06,
      "loss": 0.767,
      "step": 17395
    },
    {
      "epoch": 5.10375,
      "grad_norm": 4.5057597160339355,
      "learning_rate": 2.2748366237709374e-06,
      "loss": 0.594,
      "step": 17400
    },
    {
      "epoch": 5.104,
      "grad_norm": 4.861064910888672,
      "learning_rate": 2.2662301881336027e-06,
      "loss": 0.7934,
      "step": 17405
    },
    {
      "epoch": 5.10425,
      "grad_norm": 5.462155818939209,
      "learning_rate": 2.2576392908135707e-06,
      "loss": 0.7798,
      "step": 17410
    },
    {
      "epoch": 5.1045,
      "grad_norm": 5.143224716186523,
      "learning_rate": 2.249063937682633e-06,
      "loss": 0.7144,
      "step": 17415
    },
    {
      "epoch": 5.10475,
      "grad_norm": 6.087251663208008,
      "learning_rate": 2.24050413460197e-06,
      "loss": 0.6517,
      "step": 17420
    },
    {
      "epoch": 5.105,
      "grad_norm": 6.235806465148926,
      "learning_rate": 2.2319598874221166e-06,
      "loss": 0.769,
      "step": 17425
    },
    {
      "epoch": 5.10525,
      "grad_norm": 7.010229110717773,
      "learning_rate": 2.223431201982992e-06,
      "loss": 0.6817,
      "step": 17430
    },
    {
      "epoch": 5.1055,
      "grad_norm": 6.116497993469238,
      "learning_rate": 2.2149180841138676e-06,
      "loss": 0.6609,
      "step": 17435
    },
    {
      "epoch": 5.10575,
      "grad_norm": 6.673498630523682,
      "learning_rate": 2.2064205396333886e-06,
      "loss": 0.6915,
      "step": 17440
    },
    {
      "epoch": 5.106,
      "grad_norm": 5.99310302734375,
      "learning_rate": 2.1979385743495367e-06,
      "loss": 0.6635,
      "step": 17445
    },
    {
      "epoch": 5.10625,
      "grad_norm": 4.94598388671875,
      "learning_rate": 2.1894721940596554e-06,
      "loss": 0.6603,
      "step": 17450
    },
    {
      "epoch": 5.1065,
      "grad_norm": 7.1227827072143555,
      "learning_rate": 2.1810214045504428e-06,
      "loss": 0.7114,
      "step": 17455
    },
    {
      "epoch": 5.10675,
      "grad_norm": 5.574146270751953,
      "learning_rate": 2.1725862115979322e-06,
      "loss": 0.7111,
      "step": 17460
    },
    {
      "epoch": 5.107,
      "grad_norm": 7.099775314331055,
      "learning_rate": 2.1641666209674976e-06,
      "loss": 0.8165,
      "step": 17465
    },
    {
      "epoch": 5.10725,
      "grad_norm": 5.532434940338135,
      "learning_rate": 2.155762638413841e-06,
      "loss": 0.5901,
      "step": 17470
    },
    {
      "epoch": 5.1075,
      "grad_norm": 5.032836437225342,
      "learning_rate": 2.1473742696810155e-06,
      "loss": 0.7241,
      "step": 17475
    },
    {
      "epoch": 5.10775,
      "grad_norm": 5.492195129394531,
      "learning_rate": 2.13900152050239e-06,
      "loss": 0.6984,
      "step": 17480
    },
    {
      "epoch": 5.108,
      "grad_norm": 6.033013343811035,
      "learning_rate": 2.130644396600656e-06,
      "loss": 0.6715,
      "step": 17485
    },
    {
      "epoch": 5.10825,
      "grad_norm": 5.217286586761475,
      "learning_rate": 2.1223029036878395e-06,
      "loss": 0.672,
      "step": 17490
    },
    {
      "epoch": 5.1085,
      "grad_norm": 5.218234062194824,
      "learning_rate": 2.11397704746526e-06,
      "loss": 0.6579,
      "step": 17495
    },
    {
      "epoch": 5.10875,
      "grad_norm": 5.820460796356201,
      "learning_rate": 2.1056668336235622e-06,
      "loss": 0.6511,
      "step": 17500
    },
    {
      "epoch": 5.10875,
      "eval_loss": 2.123927116394043,
      "eval_runtime": 5.0536,
      "eval_samples_per_second": 202.629,
      "eval_steps_per_second": 25.329,
      "step": 17500
    }
  ],
  "logging_steps": 5,
  "max_steps": 20000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 2500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.9968035697904845e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
